{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit testy v Pythonu\n",
    "## Proč psát testy\n",
    "Představme si, že jsme napsali nějaký kód, dejme tomu funkci provádějící určitý výpočet. Chceme-li vědět, zda funguje, obvykle ho ručně otestujeme. Tj. danou funkci provoláme s určitými parametry a poté zkontrolujeme, zda výsledek odpovídá našim očekáváním. Pakliže ano, tak jsme šťastní, že nemusíme nic řešit. Pokud ale na výstupu ufnkce obdržíme nesmysl, musíme provést opravu.  \n",
    "Představme si nyní, že bychom naši funkci otestovali v rámci několika scénářů. Například bychom implementovali dělení a tudíž bychom chtěli vědět, zda náš kód dává očekávané výsledky při stejných znaménkách děleného a dělitele, při odlišných znaménkách a za situace, kdy je dělitel roven nule. Jeden ze scénářů nefunguje, tudíž upravíme funkci a scénář znovu vyzkoušíme. Nicméně vyzkoušet i scénáře ostatní - nemůžeme si být totiž jisti, zda jsme naší opravou nerozbili jinou funkčnost.  \n",
    "Nyní si představme, že máme v projektu mnoho funkcí a každá z nich se musí ověřit ve více než třech scénářích. Za takovýchto podmínek už na ruční testování není čas nemluvě o tom, že bychom mohli omylem na některý ze scnénářů zapomenout. Proto by bylo vhodné, kdyby existovala předpřipravená množina scénářů, které bychom po každé změně mohli najednou pustit a ověřit, že se nám nic nepodařilo rozbít. Tímto opouštíme hájemství manuálního testování a dostáváme se k tesotvání automatickému.  \n",
    "Testů existuje několikero druhů. My v kontextu tohoto povídání budeme řešit pouze testy jednotkové (unit testy). Jedná se o testy, které se omezují na krátký segment kódu - typicky funkce. V konstrastu k tomu lze postavit testy integrační, které testují celý běh programu/servisy.  \n",
    "Testy krom svého primárního smyslu přinášejí i pár dalších benefitů. Jejich psaní nutí programátora, aby testované funkce byly co možná nejmenší a nejjednodušší, ideálně bez vedlejších produktů, čímž roste přehlednost kódu. Z pohledu na test člověk také pozná, jak vlastně vypadá vstup a výstup funkce, testy tak fungují jako doplněk dokumentece.  \n",
    "V Pythonu existuje několik frameworků na psaní testů. Ačkoli jeden z nich - unittest- je součástí základní instalace Pythonu, my si zde ukážeme práci s pytestem. Ten je totiž snazší na použití a hádám že i na porozumnění."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# První testy\n",
    "Mějme následující skript (k nalezení v adresáří first_script):\n",
    "```python\n",
    "# dir first_tests\n",
    "\n",
    "def get_sum_of_two_numbers(first_number:int, second_number:int)->int:\n",
    "    return first_number + second_number\n",
    "\n",
    "def get_difference_of_two_numbers(first_number:int, second_number:int)->int:\n",
    "    return first_number - second_number\n",
    "```\n",
    "Jak bychom otestovali jeho první funkci *get_sum_of_two_numbers*? Neprve si vytvoříme adresář, kde budeme mít testy umístěné. Na jméně z hlediska pytestu nezáleží, ale bývá zvykem, že nese jméno *tests* (v našem případě first_tests\\test). V tomto adresáři vytvoříme soubor *test_get_sum_of_two_numbers.py*, v němž budou testy spojené s danou funkcí. Soubor by měl začínat s prefixem test\\_ (resp. se sufixem \\_test), aby byl pytestem při spouštění více testů najednou nalezen.  \n",
    "Soubor s jedním jednoduchým testem bude vypadat takto:\n",
    "```python\n",
    "import math_script\n",
    "\n",
    "def test_expected_sum_returned():\n",
    "    first_number = 10\n",
    "    second_number = 32\n",
    "    expected_result = 42\n",
    "    actual_result = math_script.get_sum_of_two_numbers(first_number, second_number)\n",
    "    assert expected_result == actual_result\n",
    "```\n",
    "Nejprve si importujeme testovaný skript. Následně se objeví testovací funkce mající v názvu prefix *test\\_* (bez toho by pytest nebral funkci jako testovací). V této funci specifikujeme pro zadané vstupní parametry očekávaný výstup testované funkce (proměnná *expected_result*). Dále pak funkci s oněmi parametry provoláme a tak získáme výstup faktický (proměnná actual_result). Očekávaný a faktický výstup nakonec porovnáme v *assert* konstrukci. Tato konstrukce v případě, že je podmínka v ní platná, nedělá nic. Pokud je ale podmínka neplatná, vyvolá assert chybu (AssertionError). \n",
    "\n",
    "Test máme tedy napsaný a nyní bychom ho rádi pustili. Aby to fungovalo (aby byl test-skript test_get_sum_of_two_numbers.py schopen nalézt testovaný skript), musíme být v adresáři s testovaným skriptem - do něj se dostaneme s pomocí příkazu *cd*. Poté v konzoli spustíme\n",
    "```\n",
    "python -m pytest tests\\test_get_sum_of_two_numbers.py\n",
    "```\n",
    "Zde pythonu parametrem **-m** říkáme, že má balíček pytest pustit jako obyčejný skript. Poslední parametr pak představuje jméno testu.\n",
    "Test by měl úspěšně proběhnout, tj. měli bychom vidět hlášku typu\n",
    "```\n",
    "================================================= test session starts =================================================\n",
    "platform win32 -- Python 3.7.4, pytest-7.1.2, pluggy-1.0.0\n",
    "rootdir: C:\\vs\\programovani\\python\\workshopy\\repozitar\\pytest\\first_tests\n",
    "plugins: mock-3.7.0\n",
    "collected 1 item\n",
    "\n",
    "tests\\test_get_sum_of_two_numbers.py .                                                                           [100%]\n",
    "\n",
    "================================================== 1 passed in 0.03s ==================================================\n",
    "```\n",
    "Obvykle ale chceme spustit více testů naráz. V konzolovém příkazu tak jako poslední parametr nezadáme jméno testu, ale jméno adresáře s testy:\n",
    "```\n",
    "python -m pytest tests\n",
    "```\n",
    "Po spuštění výše zmíněného uvidíme výstup, který už není tak optimistický jako výstup předešlý:\n",
    "```\n",
    "================================================= test session starts =================================================\n",
    "platform win32 -- Python 3.7.4, pytest-7.1.2, pluggy-1.0.0\n",
    "rootdir: C:\\vs\\programovani\\python\\workshopy\\repozitar\\pytest\\first_tests\n",
    "plugins: mock-3.7.0\n",
    "collected 3 items\n",
    "\n",
    "tests\\test_get_difference_of_two_numbers.py .F                                                                   [ 66%]\n",
    "tests\\test_get_sum_of_two_numbers.py .                                                                           [100%]\n",
    "\n",
    "====================================================== FAILURES =======================================================\n",
    "_________________________________________________ test_this_fill_fail _________________________________________________\n",
    "\n",
    "    def test_this_fill_fail():\n",
    ">       assert 1 == 2\n",
    "E       assert 1 == 2\n",
    "\n",
    "tests\\test_get_difference_of_two_numbers.py:11: AssertionError\n",
    "=============================================== short test summary info ===============================================\n",
    "FAILED tests/test_get_difference_of_two_numbers.py::test_this_fill_fail - assert 1 == 2\n",
    "============================================= 1 failed, 2 passed in 0.37s =============================================\n",
    "```\n",
    "To je dané tím, že v jednom z testů bylo natvrdo napsáno **assert 1 == 2**, což automaticky vedlo k selhání testu. V první části reportu vidíme, u kterého souboru s testy nastaly problémy a v kolika testech, v druhé části jsou pak ony prolbémy explicitně ukázané.  \n",
    "Je možné, že při spuštění testů se něco nepovede. Následující výpis uvidíte v případě, že ve Vámi specifikovaném adresáři nejsou testy žádné, resp. zapomněli jste na prefix *test\\_* u testových souborů:\n",
    "```\n",
    "(environment) C:\\workshopy\\repozitar\\pytest\\first_tests>python -m pytest tests\n",
    "================================================= test session starts =================================================\n",
    "platform win32 -- Python 3.7.4, pytest-7.1.2, pluggy-1.0.0\n",
    "rootdir: C:\\vs\\programovani\\python\\workshopy\\repozitar\\pytest\\first_tests\n",
    "plugins: mock-3.7.0\n",
    "collected 0 items\n",
    "\n",
    "================================================ no tests ran in 0.00s ================================================\n",
    "```\n",
    "Za situace, kdy se budete snažit pouštět testy z adresáře, kde nejsou testované skripty, uvidíte hlášení\n",
    "```\n",
    "(environment) C:\\workshopy\\repozitar\\pytest>python -m pytest first_tests\\tests\\test_get_sum_of_two_numbers.py\n",
    "================================================= test session starts =================================================\n",
    "platform win32 -- Python 3.7.4, pytest-7.1.2, pluggy-1.0.0\n",
    "rootdir: C:\\workshopy\\repozitar\\pytest\n",
    "plugins: mock-3.7.0\n",
    "collected 0 items / 1 error\n",
    "\n",
    "======================================================= ERRORS ========================================================\n",
    "__________________________ ERROR collecting first_tests/tests/test_get_sum_of_two_numbers.py __________________________\n",
    "ImportError while importing test module 'C:workshopy\\repozitar\\pytest\\first_tests\\tests\\test_get_sum_of_two_numbers.py'.\n",
    "Hint: make sure your test modules/packages have valid Python names.\n",
    "Traceback:\n",
    "C:\\Python\\Python37\\lib\\importlib\\__init__.py:127: in import_module\n",
    "    return _bootstrap._gcd_import(name[level:], package, level)\n",
    "first_tests\\tests\\test_get_sum_of_two_numbers.py:1: in <module>\n",
    "    import math_script\n",
    "E   ModuleNotFoundError: No module named 'math_script'\n",
    "=============================================== short test summary info ===============================================\n",
    "ERROR first_tests/tests/test_get_sum_of_two_numbers.py\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "================================================== 1 error in 0.08s ===================================================\n",
    "```\n",
    "Testování balíčků je principiálně stejné, jen si člověk musí dát pozor na to, aby se testy dostaly k testovaným funkcím. Ukázku nalezneme v adresáři *module_tests*.  \n",
    "Nakonec zmiňme tu největší zradu. Může se stát, že se nám při puštění testů spustí i část testovaného skriptu. K tomu dojde v tom případě, kdy v onom skriptu máme volně položený kód, tj. kód, který není ve funkci či třídě. Faktick je tot chování dané importěním, které se musí v každém testovacím srkitpu objevit. Řešení spočívá v umístění těchto \"volných\" příkazů do konstrukce *if \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\"*. V proměnné \\_\\_name\\_\\_ se totiž objeví jméno skriptu, pokud byl onen skript importován, anebo \"\\_\\_main\\_\\_\", pokud byl skript spuštěn napřímo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mírně složitější testy\n",
    "Kontrola na rovnost celých čísel či textových řetězců patří k tomu nejjednoduššímu, co se dá testovat. V běžném provozu ale budeme muset být schopni ošetřit i komplikovanější případy. Těm se věnuje právě tato kapitola.  \n",
    "Typickým problémem je ověření toho, zda funkce vracející reálné číslo dělá to, co by dělat měla.\n",
    "```python\n",
    "def get_slightly_increased_number(orig_number):\n",
    "    increment = 0.001\n",
    "    return orig_number + increment\n",
    "```\n",
    "Pomiňme nyní skutečnost, že u této funkce je cifra vyčíslitelná a tak bychom si vystačili s rovností (ale ani toto neni samospásné - zkusme si spustit *assert 0.1 + 0.2 == 0.3*). Představme si namísto toho, že výsledek známe jen přibližně (jako by se dejme tomu jednalo o výpočet funkce sinus). Byli bychom spokojení, kdyby se výstup funkce rovnal očekávanému výstupu plus mínus nějaká malá hodnota. To bychom mohli v testu zakódovat jako dvojici assertů. Nicméně vhodnější (čti elegantnější) bude použít pytestovou funkci *approx*:\n",
    "```python\n",
    "import slightly_complicated\n",
    "import pytest\n",
    "\n",
    "def test_incrase_works():\n",
    "    orig_number = 5\n",
    "    expected_result = 5.001\n",
    "    actual_result = slightly_complicated.get_slightly_increased_number(orig_number)\n",
    "    \n",
    "    assert actual_result == pytest.approx(expected_result, abs=0.0005)\n",
    "\n",
    "def test_this_will_fail():\n",
    "    orig_number = 5\n",
    "    expected_result = 5.002\n",
    "    actual_result = slightly_complicated.get_slightly_increased_number(orig_number)\n",
    "    \n",
    "    assert actual_result == pytest.approx(expected_result, abs=0.0005)\n",
    "```\n",
    "Vidíme, že krom importu testovaného skriptu se musí importovat i samotný pytest. V testech samotných se obvyklým způsobem získá výstup testované funkce. V rámci assertu se ale tento výstup neporovnává s očekávaným výstupem, ale s výstupem funkce pytest.approx. Ta je krmena jednak očekávaným výstupem, jednak (volitelně) velikostí tolerance v parametru *abs*.  \n",
    "\n",
    "Někdy je vhodné netestovat hodnotu výstupu, ale jeho datový typ. To se provede pomocí funkce *isinstance*:\n",
    "```python\n",
    "import slightly_complicated\n",
    "\n",
    "def test_increased_number_is_float():\n",
    "    orig_number = 5\n",
    "    actual_result = slightly_complicated.get_slightly_increased_number(orig_number)\n",
    "    assert isinstance(actual_result, float)\n",
    "    \n",
    "def test_increased_number_is_integer():\n",
    "    orig_number = 5\n",
    "    actual_result = slightly_complicated.get_slightly_increased_number(orig_number)\n",
    "    assert isinstance(actual_result, int)\n",
    "```\n",
    "\n",
    "Když ccheme otestovat, zda funkce vrací správný list či slovník, použijeme assertování a rovnosti, jako jsme aplikovali například u celých čísel. U dataframů to tak jednoduše nepůjde, tehdy pro test\n",
    "```python\n",
    "def test_naive_expected_frame():\n",
    "    expected_result = pd.DataFrame({\n",
    "        \"column_1\": [10, 20, 30],\n",
    "        \"column_2\": [100, 200, 300]\n",
    "    })\n",
    "    actual_result = slightly_complicated.get_some_frame()\n",
    "    assert expected_result == actual_result\n",
    "```\n",
    "obdržíme výstup\n",
    "```\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
    "\n",
    "self =    column_1  column_2\n",
    "0      True      True\n",
    "1      True      True\n",
    "2      True      True\n",
    "\n",
    "    def __nonzero__(self):\n",
    "        raise ValueError(\n",
    ">           f\"The truth value of a {type(self).__name__} is ambiguous. \"\n",
    "            \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\n",
    "        )\n",
    "E       ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
    "\n",
    "..\\..\\..\\environment\\lib\\site-packages\\pandas\\core\\generic.py:1330: ValueError\n",
    "```\n",
    "V takovémto případě se musí použít funkce *assert_frame_equal* z *pandas.testing*. Konkrétně se výstup této funkce musí assertovat s předpokladem, že je rovna None:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def test_expected_frame():\n",
    "    expected_result = pd.DataFrame({\n",
    "        \"column_1\": [10, 20, 30],\n",
    "        \"column_2\": [100, 200, 300]\n",
    "    })\n",
    "    actual_result = slightly_complicated.get_some_frame()\n",
    "    frames_differences = pd.testing.assert_frame_equal(expected_result, actual_result)\n",
    "    assert frames_differences is None\n",
    "```\n",
    "\n",
    "Za určitých okolností bývá užitečné ověřit, že jsou vytvořeny výjimky, když vytvořeny být mají. Tehdy musíme provolání testované funkce umístit do with konstrukce. V té bude namísto typického *open* funkce *pytest.raises*, která bude mít v argumentu výjimku, která by měla být vytvořena.\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "def test_exception_raised():\n",
    "    first_number = 10\n",
    "    second_number = 0\n",
    "    with pytest.raises(slightly_complicated.UselessZeroDivisionException):\n",
    "        slightly_complicated.get_division_result(first_number, second_number)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokročilé možnosti operativy s pytestem\n",
    "Při defaultní puštění testů pomocí \n",
    "```\n",
    "python -m pytest tests\n",
    "```\n",
    "obdržíme v případě úspěšně proběhlých testů pouze informaci o tom, že z testového skriptu X úspěšně doběhlo Y testů\n",
    "```\n",
    "tests\\test_get_increment_by_five.py .......                                                                      [100%]\n",
    "```\n",
    "Níže budeme určité testy vyřazovat a tehdy by se hodilo vědět, které testy fakticky proběhly. To uvidíme jen tehdy, když budeme vyžadovat verbose výstup, což se zařídí přepínačem *-v*.\n",
    "```\n",
    "python -m pytest tests -v\n",
    "```\n",
    "Výstup pak bude mít podobu \n",
    "```\n",
    "tests/test_get_increment_by_five.py::test_simple_example_1 PASSED                                                [ 14%]\n",
    "tests/test_get_increment_by_five.py::test_simple_example_2 PASSED                                                [ 28%]\n",
    "tests/test_get_increment_by_five.py::test_simple_exercise PASSED                                                 [ 42%]\n",
    "tests/test_get_increment_by_five.py::test_trivial_exercise PASSED                                                [ 57%]\n",
    "tests/test_get_increment_by_five.py::test_marked_as_computation PASSED                                           [ 71%]\n",
    "tests/test_get_increment_by_five.py::test_marked_as_something PASSED                                             [ 85%]\n",
    "tests/test_get_increment_by_five.py::test_marked_as_computation_too PASSED                                       [100%]\n",
    "```\n",
    "Ještě důležitější může být verbosita u zfailovaných testů. Pro neverbózní provolání dostaneme nap59klad\n",
    "```\n",
    "_________________________________________________ test_this_will_fail _________________________________________________\n",
    "\n",
    "    def test_this_will_fail():\n",
    "        expected_result =  [\"three\"]\n",
    "        actual_result = some_tested_script.get_some_list()\n",
    "\n",
    ">       assert expected_result == actual_result\n",
    "E       AssertionError: assert ['three'] == ['one', 'two', 'three']\n",
    "E         At index 0 diff: 'three' != 'one'\n",
    "E         Right contains 2 more items, first extra item: 'two'\n",
    "E         Use -v to get more diff\n",
    "\n",
    "tests\\test_get_some_list.py:7: AssertionError\n",
    "```\n",
    "Při verbózním provoláním už ale vidíme\n",
    "```\n",
    "_________________________________________________ test_this_will_fail _________________________________________________\n",
    "\n",
    "    def test_this_will_fail():\n",
    "        expected_result =  [\"three\"]\n",
    "        actual_result = some_tested_script.get_some_list()\n",
    "\n",
    ">       assert expected_result == actual_result\n",
    "E       AssertionError: assert ['three'] == ['one', 'two', 'three']\n",
    "E         At index 0 diff: 'three' != 'one'\n",
    "E         Right contains 2 more items, first extra item: 'two'\n",
    "E         Full diff:\n",
    "E         - ['one', 'two', 'three']\n",
    "E         + ['three']\n",
    "\n",
    "tests\\test_get_some_list.py:7: AssertionError\n",
    "```\n",
    "Pro komplikovanější případy lze použít i very verbose režím, kdy se použije přepínač *-vv*. Tehdy už není schována opravdu žádná část výytupu.\n",
    "\n",
    "\n",
    "Výše jsme viděli, jak spouštět testy buď explicitně po jednom, anebo všechny najednou. Občas se ale hodí mít něco mezi tím. Dejme tomu při větší změně programu rozbijeme několik funkcionalit. V rámci testů ale chceme napřed ověřit, že funguje featura A, přičemž nechceme ztrácet čas testováním věcí, o kterých víme, že automaticky zfailují.  \n",
    "Přeskočme do adresáře *pytest_operative*. Pakliže chceme spustit pouze testy obsahující v názvu nějaké slovo, předáme toto slovo jako doplněk k parametru *-k*. Tj. například pokud chceme spustit testy obsahující \"example\", spustíme v konzoli\n",
    "```\n",
    "python -m pytest -v -k example tests\n",
    "```\n",
    "Všimněte si, že na konci konzolového výstupu bude napsáno\n",
    "```\n",
    "================== X passed, Y deselected in 0.19s ==========\n",
    "```\n",
    "Tj. explicitně vidíme, kolik testů bylo přeskočeno.  \n",
    "S podmínkami na (ne)přítomnost slov si můžeme pohrát i více. Můžeme například chtít pustit všechny testy, které zvolené slovo v názvu *neobsahují*. Pro to musíme vložit do příkazu před ono slovo *not*, avšak současně musíme celou kosntrukci umístit do uvozovek:\n",
    "```\n",
    "python -m pytest -v -k \"not example\" tests\n",
    "```\n",
    "Dále může požadovat přítomnost více slov, kteréžto v podmínce spojíme pomocí *and*:\n",
    "```\n",
    "python -m pytest -v -k \"simple and exercise\" tests\n",
    "```\n",
    "Případně můžeme použít i logiku typu *or*:\n",
    "```\n",
    "python -m pytest -v -k \"simple or exercise\" tests\n",
    "```\n",
    "Testy můžeme už v testovacím skriptu sdružovat do kategorií a to prostřednictvím custom markerů (fakticky se jedná o dekorátory). Zdůrazněme, že v takomém případě je opět nutné importovat v testovacím skriptu pytest:\n",
    "```\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.computation\n",
    "def test_marked_as_computation():\n",
    "    orig_number = 1\n",
    "    expected_result = 6\n",
    "    actual_result = some_tested_script.get_increment_by_five(orig_number)\n",
    "    assert expected_result == actual_result\n",
    "```\n",
    "Spuštění testů s daným markerem se poté zařídí parametrem m následovaným názvem markeru\n",
    "```\n",
    "python -m pytest -v -m computation\n",
    "```\n",
    "Opět lze aplikovat rudimentální and/or/not logiku:\n",
    "```\n",
    "python -m pytest -v -m \"not computation\"\n",
    "```\n",
    "Pokud jsme k=ody nestáhli z repozitáře, můžeme si všimnout, že se nám objevují warningy spojené s tím, že custom markery nejsou registrované:\n",
    "```\n",
    "PytestUnknownMarkWarning: Unknown pytest.mark.computation - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n",
    "```\n",
    "Pokud bychom chtěli warningy potlačit, použijeme parametr *-disable-warnings*\n",
    "```\n",
    "python -m pytest -v -m computation --disable-warnings\n",
    "```\n",
    "Nicméně vhodnější bude se s warningy vypořádat. V tomto kontextu to znamená custom markery zaregistrovat. To v praxi znamená, že v adresáři, ze kterého testy spouštíme, vyrobíme soubor *pytest.ini* o následujícím obsahu:\n",
    "```\n",
    "[pytest]\n",
    "markers =\n",
    "    computation: some label\n",
    "    something\n",
    "```\n",
    "Sekce za dvojtečkou je nepovinný popisek daného markeru.  \n",
    "\n",
    "Doposud jsme mluvili o custom markerech, existují ale i \"normální\" markery. Například *skip* způsobí vynechání testu.  Marker \"xfail\" způsobí, že test sice proběhne, ale i pokud selže, nedostane se do výsledných statistik jako \"nomrálně\" zfailnuté testy.\n",
    "```\n",
    "@pytest.mark.skip    \n",
    "def test_to_skip():\n",
    "    orig_number = 1\n",
    "    expected_result = 6\n",
    "    actual_result = some_tested_script.get_increment_by_five(orig_number)\n",
    "    assert expected_result == actual_result\n",
    "\n",
    "@pytest.mark.xfail\n",
    "def test_to_maybe_fail():\n",
    "    orig_number = 1\n",
    "    expected_result = 6\n",
    "    actual_result = some_tested_script.get_increment_by_five(orig_number)\n",
    "    assert expected_result == actual_result    \n",
    "    \n",
    "@pytest.mark.xfail\n",
    "def test_to_fail():\n",
    "    orig_number = 1\n",
    "    expected_result = 7\n",
    "    actual_result = some_tested_script.get_increment_by_five(orig_number)\n",
    "    assert expected_result == actual_result\n",
    "```\n",
    "Na výstupu totiž uvidíme\n",
    "```\n",
    "tests/test_get_increment_by_five.py::test_to_skip SKIPPED (unconditional skip)                                   [ 72%]\n",
    "tests/test_get_increment_by_five.py::test_to_maybe_fail XPASS                                                    [ 81%]\n",
    "tests/test_get_increment_by_five.py::test_to_fail XFAIL                                                          [ 90%]\n",
    "```\n",
    "a\n",
    "```\n",
    "=========== 2 failed, 6 passed, 1 skipped, 1 xfailed, 1 xpassed in 0.92s ===========\n",
    "```\n",
    "Asi nejzajímavější z out-of-the-box markerů je ale *parametrize*. Ten dovoluje efektivně v rámci jedné definice testu vytvořit několik testů naráz, kteréžto testy se ale v rámci vyhodnocení berou jako samostatné jednotky. Jako v předchozích případech se před testovací funkci napíše dekorátor markeru. Ten bude ale tentorkát následován kulatými závorkami s parametry. Prvním parametremem bude textový řetězec, ve kterém budou čárkou odděleny názvy proměnných, kterými bude testovací funkce krmena. Druhým parametrem bude list tuplů. Ty budou odpovídat názvům proměnným z parametru prvního. Samotná testovací funkce pak musí parametry přebírat a ve svých vnitřnostech je nějak zpracovávat. Výsledný produkt tedy vypadá takto:\n",
    "```\n",
    "@pytest.mark.parametrize(\"some_input, expected_result\", [(11, 16), (20, 25), (20, 26)])   \n",
    "def test_parametrized(some_input, expected_result):\n",
    "    actual_result = some_tested_script.get_increment_by_five(some_input)\n",
    "    assert expected_result == actual_result\n",
    "```\n",
    "Ve výstupu pytestu je orpavdu tato jedna testovací funkce reprezentována, jako by šlo o tři nezávislé testy:\n",
    "```\n",
    "tests/test_get_increment_by_five.py::test_parametrized[11-16] PASSED                                             [ 78%]\n",
    "tests/test_get_increment_by_five.py::test_parametrized[20-25] PASSED                                             [ 85%]\n",
    "tests/test_get_increment_by_five.py::test_parametrized[20-26] FAILED                                             [ 92%]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mocky\n",
    "Občas se do testované funkce předává nějaký objekt. Na něm by se ve funkci měli provést určité operace, u kterých chceme otestovat, že k nim opravdu dojde. Jenže co když není reálné, abychom v rámci testu reálný objekt vytvořili, například poněvadž se jedná o connectionu do produkční databáze? Tehdy se hodí použít mocky, tj. fakeové objekty, které namísto původní funkčnosti dokážou sledovat, jak často a s jamými parametry na nich byla ta která matoda provolána.  \n",
    "Nechť testovaná funkce přebírá pandí dataframe a dvakrát do něj přidá sloupec pomocí metody insert\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def do_something_with_frame(orig_frame:pd.DataFrame)->None:\n",
    "    orig_frame.insert(1, \"some_column\", 42)\n",
    "    orig_frame.insert(1, \"another_column\", 142)\n",
    "```\n",
    "Nyní v testu nebudeme do testované funkce vkládat reálný dataframe, nýbrž mock. Ten získáme z \"původního\" pythoního testovacího balíčku *unittest*, nikoli z pytestu. Vytvoříme ho provolání třídy *Mock* a následně zavoláme testovanou funkci. Ta nám sice dataframe/mock nevrací zpátky, ale to nevadí. Změny objektu vlivem provolání inserty se totiž díky předávání reference a nikoli dat dostanou ven z funkce.  \n",
    "Chtějme nejprve otestovat, že metoda insert byla zavolána dvakrát. K tomu se dostaneme tak, že na mockovaném objektu se skrz tečkovou notaci zeptáme na *insert* (vytvořené v okamžik provolání stejnojmenou metodou) a u něj na parametr *call_count*. Následuje už obyčejné assertění\n",
    "```python\n",
    "def test_insert_called_two_times():\n",
    "    mocked_object = Mock()\n",
    "    script_for_mocks.do_something_with_frame(mocked_object)\n",
    "    expected_insert_calls = 2\n",
    "    actual_insert_calls = mocked_object.insert.call_count\n",
    "    \n",
    "    assert expected_insert_calls == actual_insert_calls\n",
    "```\n",
    "Častokrát se určitá metoda provolá jen jednou. Proto byla na mockovacím objektu vytvořena metoda *assert_called_one*. V našem připadě jsme metodu provolali dvakrát, tudíž následující test failne.\n",
    "```python\n",
    "def test_insert_called_once():\n",
    "    mocked_object = Mock()\n",
    "    script_for_mocks.do_something_with_frame(mocked_object)\n",
    "    \n",
    "    mocked_object.insert.assert_called_once()\n",
    "```\n",
    "Pokud potřebujeme pouze zkontrolovat, zda metoda provolaná byla (a je nám jedno kolikrát), použijeme *assert_called*.\n",
    "```python\n",
    "def test_insert_called():\n",
    "    mocked_object = Mock()\n",
    "    script_for_mocks.do_something_with_frame(mocked_object)\n",
    "    \n",
    "    mocked_object.insert.assert_called()\n",
    "    \n",
    "def test_drop_called():\n",
    "    mocked_object = Mock()\n",
    "    script_for_mocks.do_something_with_frame(mocked_object)\n",
    "    \n",
    "    mocked_object.drop.assert_called()\n",
    "```\n",
    "Občas bývá potřeba ověřit, že byla metoda provolaná s očekávanými parametry. Pokud nám jde jen o parametry posledního provolání (resp. pokud si jsme jistí, že více než jedno provolání nebude), použijeme *call_args*. Jedná se o call objekt (pro naše obvyklé účely efektivně tuple), který má dvě složky. V prnví se ukládají args, v druhé kwargs.\n",
    "```python\n",
    "def test_insert_called_last_time_with_expected_params():\n",
    "    mocked_object = Mock()\n",
    "    script_for_mocks.do_something_with_frame(mocked_object)\n",
    "    expected_params = (1, \"another_column\", 142)\n",
    "    #because call_args is a call object which have args tuple at index 0\n",
    "    actual_params = mocked_object.insert.call_args[0]\n",
    "    assert expected_params == actual_params\n",
    "```\n",
    "Pokud je nutné prověřit argumenty všech volání, musí se sáhnout po *call_args_list*, což je list call objektů.\n",
    "```python\n",
    "def test_insert_called_both_times_with_expected_params():\n",
    "    mocked_object = Mock()\n",
    "    script_for_mocks.do_something_with_frame(mocked_object)\n",
    "    \n",
    "    first_expected_params = (1, \"some_column\", 42)\n",
    "    second_expected_params = (1, \"another_column\", 142)\n",
    "\n",
    "    first_call_params, second_call_params = mocked_object.insert.call_args_list\n",
    "    first_actual_params = first_call_params[0]\n",
    "    second_actual_params = second_call_params[0]\n",
    "    assert first_expected_params == first_actual_params\n",
    "    assert second_expected_params == second_actual_params\n",
    "```\n",
    "V případě, že chceme ověřit provolání args i kwargs, tj. namísto původní testované funkce máme třeba\n",
    "```python\n",
    "def do_something_with_frame_args_kwargs(orig_frame:pd.DataFrame)->None:\n",
    "    orig_frame.insert(1, \"some_column\", value=42)\n",
    "    orig_frame.insert(1, \"another_column\", value=142)\n",
    "```\n",
    "budeme využívat i druhou složku call_args, tj. test se bude nést v následujícím duchu:\n",
    "```python\n",
    "import script_for_mocks\n",
    "from unittest.mock import Mock\n",
    "\n",
    "def test_insert_called_last_time_with_expected_params():\n",
    "    mocked_object = Mock()\n",
    "    script_for_mocks.do_something_with_frame_args_kwargs(mocked_object)\n",
    "    expected_args = (1, \"another_column\")\n",
    "    expected_kwargs = {\"value\":142}\n",
    "    \n",
    "    actual_args = mocked_object.insert.call_args[0]\n",
    "    actual_kwargs = mocked_object.insert.call_args[1]\n",
    "    \n",
    "    assert expected_args == actual_args\n",
    "    assert expected_kwargs == actual_kwargs\n",
    "```\n",
    "Výše jsme mocky použily jako svého druhu sondu do funkce. Nicméně mockům lze i říci, že se mají nějak chovat. Například lze zařídit, aby jejich metody vracely věci, které chceme. Mějme testovanou funkci \n",
    "```python\n",
    "def get_frame_without_col(orig_frame:pd.DataFrame, col_name:str)->pd.DataFrame:\n",
    "    something = orig_frame.drop(column=col_name)\n",
    "    return something\n",
    "```\n",
    "Normálně by *drop* v této funkci vracel dataframe. Můžeme ale zařídit, aby v rámci testu vracel string a to sice pomocí *mocked_object.drop.return_value*:\n",
    "```python\n",
    "def test_insert_in_mock_returns_something():\n",
    "    mocked_object = Mock()\n",
    "    mocked_object.drop.return_value = \"there should be a frame\"\n",
    "    returned_value = script_for_mocks.get_frame_without_col(mocked_object, \"some_col\")\n",
    "    \n",
    "    assert returned_value == \"there should be a frame\"\n",
    "```\n",
    "\n",
    "Pro úplnost dodejme, že krom třídy Mock existuje i třída MagicMock. Ta se od svého předchodce liší tím, že má zadefinované základní magické (dunder; podtržítkové) metody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<MagicMock name='mock.__getitem__()' id='2265866571144'>\n",
      "[]\n",
      "True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'Mock' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d9fef771ea94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#operations using dunder methods lead to errors on simple Mock objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_mock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'Mock' has no len()"
     ]
    }
   ],
   "source": [
    "from unittest.mock import Mock, MagicMock\n",
    "\n",
    "simple_mock = Mock()\n",
    "magical_mock = MagicMock()\n",
    "\n",
    "#operations using dunder methods work on MagicMock objects\n",
    "print(len(magical_mock))\n",
    "print(magical_mock[0])\n",
    "print(list(magical_mock))\n",
    "print(magical_mock != 2)\n",
    "\n",
    "#operations using dunder methods lead to errors on simple Mock objects\n",
    "len(simple_mock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freezegun\n",
    "Práce s datumem a časem bývá obvykle problematická a testování není výjimkou. Namockování datumových objektů, zejména používá-li se timedelta, není úplně triviální. Proto se hodí, že byl pro tyto účely vyvinut speciální balíček - freezegun.\n",
    "Mějme testovanou funkci, která vrací datum sedm dní před svým spuštěním. zdůrazněme, že aktuální datum do funkce jako parametr nevstupuje, nýbrž se určuje v jejím vnitřku.\n",
    "```python\n",
    "import datetime\n",
    "\n",
    "def get_date_week_ago():\n",
    "    today = datetime.date.today()\n",
    "    week_ago = today - datetime.timedelta(days=7)\n",
    "    return week_ago\n",
    "```\n",
    "Při testování by byl nyní problém, jak zafixovat funkci *today* na jeden konkrétní den. No a právě to nám zajistí freezegun. Co se samotné realizace v testu, existuje několik do výsledku ekvivaletních přístupů. V prvním z nich nastavíme aktuální datum a čas pomocí *freezegun.freeze_time*. Nicméně čas bude za/nastaven až když se zavolá na odpovídajícím objektu metoda *start*. Reálný čas se vrátí po následném provoální metody *stop*.\n",
    "```python\n",
    "import freezegun\n",
    "import datetime\n",
    "import script_for_freezegun\n",
    "\n",
    "def test_raw_use_freezer():\n",
    "    expected_result = datetime.date(2022, 1, 21)\n",
    "    \n",
    "    freezer = freezegun.freeze_time(\"2022-01-28 12:00:01\")\n",
    "    freezer.start()\n",
    "    actual_result = script_for_freezegun.get_date_week_ago()\n",
    "    freezer.stop()\n",
    "    \n",
    "    assert expected_result == actual_result\n",
    "```\n",
    "Druhý přístup využívá kontextového manažeru (with konstrukce) - čas je zamrzlý jen v jeho rámci:\n",
    "```python\n",
    "def test_freezer_context_manager():\n",
    "    expected_result = datetime.date(2022, 1, 21)\n",
    "    \n",
    "    with freezegun.freeze_time(\"2022-01-28 12:00:01\"):\n",
    "        actual_result = script_for_freezegun.get_date_week_ago()\n",
    "    \n",
    "    assert expected_result == actual_result\n",
    "```\n",
    "Nakonec přístup třetí používá dekorátor, přičemž v čase je zamrzlá celá testovací funkce:\n",
    "```python\n",
    "@freezegun.freeze_time(\"2022-01-28 12:00:01\")\n",
    "def test_freezer_decorator():\n",
    "    expected_result = datetime.date(2022, 1, 21)\n",
    "    \n",
    "    actual_result = script_for_freezegun.get_date_week_ago()\n",
    "    \n",
    "    assert expected_result == actual_result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monkeypatching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testování kontextových managerů\n",
    "Kontextvoé managery (typicky with open kosntrukce) stojí na \\_\\_enter\\_\\_ a \\_\\_exit\\_\\_ funkcích. Když se použije *with*, je zavolán \\_\\_enter\\_\\_, který vrací objekt použitý v kontextu. Pak se spustí vnitřní (odsazený) blok kódu. Metoda \\_\\_exit\\_\\_ se na konec zavolá a to nezávisle na tom, jaký je výstup výše zmíněného bloku kódu. Tj. je ekvivalentní toto:\n",
    "```python\n",
    "with Context(something) as anything:\n",
    "    do_some_magic(anything)\n",
    "```\n",
    "s tímto:\n",
    "```python\n",
    "cont = Context(something)\n",
    "anything = cont.__enter__()\n",
    "try:\n",
    "    do_some_magic(anything)\n",
    "finally:\n",
    "    cont.__exit__(None, None, None)\n",
    "```\n",
    "\n",
    "Z hlediska psaná testů pro open funkci je třeba vědět, že její definice vypadá následovně:\n",
    "```python\n",
    "def open(path):\n",
    "    f = builtins.open(path, \"r\")\n",
    "    return f\n",
    "```\n",
    "Tj. jedná se o funkci vracející objekt.\n",
    "\n",
    "Nnyí se podívejme na reálný příklad. Mějme testovanou funkci\n",
    "```python\n",
    "def create_html_page():\n",
    "    page_text = \"<b>Hello world</b>\"\n",
    "    \n",
    "    with open(\"index.html\", \"w+\", encoding=\"utf-8\") as file:\n",
    "        file.write(page_text)\n",
    "```\n",
    "Pak bude test toho, že byla funkce open provolána, vypadat takto(pro jednoduchost je tu spláclých více testů do jednoho):\n",
    "```python\n",
    "from unittest.mock import MagicMock\n",
    "import script_for_context\n",
    "\n",
    "def test_open_called_correctly(monkeypatch):\n",
    "    object_from_context = MagicMock()\n",
    "    \n",
    "    def fake_open(*args, **kwargs):\n",
    "        context_object = MagicMock()\n",
    "        context_object.__enter__.return_value = object_from_context\n",
    "        return context_object\n",
    "    \n",
    "    monkeypatch.setattr(\"builtins.open\", fake_open)\n",
    "    script_for_context.create_html_page()\n",
    "    \n",
    "    expected_html_string = \"<b>Hello world</b>\"\n",
    "    \n",
    "    assert 1 == object_from_context.write.call_count\n",
    "    args, _ = object_from_context.write.call_args\n",
    "    assert expected_html_string == args[0]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixtures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
