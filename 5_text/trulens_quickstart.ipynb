{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwEG0xDtsP7o"
      },
      "source": [
        "# üìì TruLens Quickstart\n",
        "\n",
        "In this quickstart you will create a RAG from scratch and learn how to log it and get feedback on an LLM response.\n",
        "\n",
        "For evaluation, we will leverage the \"hallucination triad\" of groundedness, context relevance and answer relevance.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/quickstart/quickstart.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5GD-PlgsP7w"
      },
      "outputs": [],
      "source": [
        "# !pip install trulens trulens-providers-openai chromadb openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gE2XL2oasP7w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "import openai\n",
        "\n",
        "dotenv.load_dotenv(\"/Users/michaelmateju/Documents/Data Science/PycharmProjects/.env\")\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "llm_model_name = \"gpt-4o-mini\" #jmeno modelu, ktery se bude pouzivat napric celym notebookem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Uah2DPQsP7x"
      },
      "source": [
        "## Get Data\n",
        "\n",
        "In this case, we'll just initialize some simple text in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tm2TYSZTsP7x"
      },
      "outputs": [],
      "source": [
        "uw_info = \"\"\"\n",
        "The University of Washington, founded in 1861 in Seattle, is a public research university\n",
        "with over 45,000 students across three campuses in Seattle, Tacoma, and Bothell.\n",
        "As the flagship institution of the six public universities in Washington state,\n",
        "UW encompasses over 500 buildings and 20 million square feet of space,\n",
        "including one of the largest library systems in the world.\n",
        "\"\"\"\n",
        "\n",
        "wsu_info = \"\"\"\n",
        "Washington State University, commonly known as WSU, founded in 1890, is a public research university in Pullman, Washington.\n",
        "With multiple campuses across the state, it is the state's second largest institution of higher education.\n",
        "WSU is known for its programs in veterinary medicine, agriculture, engineering, architecture, and pharmacy.\n",
        "\"\"\"\n",
        "\n",
        "seattle_info = \"\"\"\n",
        "Seattle, a city on Puget Sound in the Pacific Northwest, is surrounded by water, mountains and evergreen forests, and contains thousands of acres of parkland.\n",
        "It's home to a large tech industry, with Microsoft and Amazon headquartered in its metropolitan area.\n",
        "The futuristic Space Needle, a legacy of the 1962 World's Fair, is its most iconic landmark.\n",
        "\"\"\"\n",
        "\n",
        "starbucks_info = \"\"\"\n",
        "Starbucks Corporation is an American multinational chain of coffeehouses and roastery reserves headquartered in Seattle, Washington.\n",
        "As the world's largest coffeehouse chain, Starbucks is seen to be the main representation of the United States' second wave of coffee culture.\n",
        "\"\"\"\n",
        "\n",
        "newzealand_info = \"\"\"\n",
        "New Zealand is an island country located in the southwestern Pacific Ocean. It comprises two main landmasses‚Äîthe North Island and the South Island‚Äîand over 700 smaller islands.\n",
        "The country is known for its stunning landscapes, ranging from lush forests and mountains to beaches and lakes. New Zealand has a rich cultural heritage, with influences from\n",
        "both the indigenous MƒÅori people and European settlers. The capital city is Wellington, while the largest city is Auckland. New Zealand is also famous for its adventure tourism,\n",
        "including activities like bungee jumping, skiing, and hiking.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv6YbmPXsP7x"
      },
      "source": [
        "## Create Vector Store\n",
        "\n",
        "Create a chromadb vector store in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "40sMUcPBsP7x"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
        "\n",
        "embedding_function = OpenAIEmbeddingFunction(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    model_name=\"text-embedding-ada-002\",\n",
        ")\n",
        "\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "vector_store = chroma_client.get_or_create_collection(\n",
        "    name=\"Washington\", embedding_function=embedding_function\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHJ038n7sP7x"
      },
      "source": [
        "Populate the vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QKVLyatcsP7y"
      },
      "outputs": [],
      "source": [
        "vector_store.add(\"uw_info\", documents=uw_info)\n",
        "vector_store.add(\"wsu_info\", documents=wsu_info)\n",
        "vector_store.add(\"seattle_info\", documents=seattle_info)\n",
        "vector_store.add(\"starbucks_info\", documents=starbucks_info)\n",
        "vector_store.add(\"newzealand_info\", documents=newzealand_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtLUfzahsP7y"
      },
      "source": [
        "## Build RAG from scratch\n",
        "\n",
        "Build a custom RAG from scratch, and add TruLens custom instrumentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oUfDNoPCsP7y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü¶ë Initialized with db url sqlite:///default.sqlite .\n",
            "üõë Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
            "Updating app_id in records table: 0it [00:00, ?it/s]\n",
            "Updating app_json in apps table: 0it [00:00, ?it/s]\n",
            "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
            "Updating app_id in records table: 0it [00:00, ?it/s]\n",
            "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "from trulens.apps.custom import instrument\n",
        "from trulens.core import TruSession\n",
        "\n",
        "session = TruSession()\n",
        "session.reset_database()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z0IzfNJWsP7y"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "oai_client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6ehlN4TdsP7y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decorating <function RAG.retrieve at 0x151447f40>\n",
            "decorating <function RAG.generate_completion at 0x151498160>\n",
            "decorating <function RAG.query at 0x1514981f0>\n",
            "adding method <class '__main__.RAG'> retrieve __main__\n",
            "adding method <class '__main__.RAG'> generate_completion __main__\n",
            "adding method <class '__main__.RAG'> query __main__\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "oai_client = OpenAI()\n",
        "\n",
        "\n",
        "class RAG:\n",
        "    @instrument\n",
        "    def retrieve(self, query: str) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from vector store.\n",
        "        \"\"\"\n",
        "        results = vector_store.query(query_texts=query, n_results=4)\n",
        "        # Flatten the list of lists into a single list\n",
        "        return [doc for sublist in results[\"documents\"] for doc in sublist]\n",
        "\n",
        "    @instrument\n",
        "    def generate_completion(self, query: str, context_str: list) -> str:\n",
        "        \"\"\"\n",
        "        Generate answer from context.\n",
        "        \"\"\"\n",
        "        if len(context_str) == 0:\n",
        "            return \"Sorry, I couldn't find an answer to your question.\"\n",
        "\n",
        "        completion = (\n",
        "            oai_client.chat.completions.create(\n",
        "                model=llm_model_name,\n",
        "                temperature=0,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"We have provided context information below. \\n\"\n",
        "                        f\"---------------------\\n\"\n",
        "                        f\"{context_str}\"\n",
        "                        f\"\\n---------------------\\n\"\n",
        "                        f\"First, say hello and that you're happy to help. \\n\"\n",
        "                        f\"\\n---------------------\\n\"\n",
        "                        f\"Then, given this information, please answer the question: {query}\",\n",
        "                    }\n",
        "                ],\n",
        "            )\n",
        "            .choices[0]\n",
        "            .message.content\n",
        "        )\n",
        "        if completion:\n",
        "            return completion\n",
        "        else:\n",
        "            return \"Did not find an answer.\"\n",
        "\n",
        "    @instrument\n",
        "    def query(self, query: str) -> str:\n",
        "        context_str = self.retrieve(query=query)\n",
        "        completion = self.generate_completion(\n",
        "            query=query, context_str=context_str\n",
        "        )\n",
        "        return completion\n",
        "\n",
        "\n",
        "rag = RAG()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a0kFh0NsP7y"
      },
      "source": [
        "## Set up feedback functions.\n",
        "\n",
        "Here we'll use groundedness, answer relevance and context relevance to detect hallucination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0mlr1ZjKsP7z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
            "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
            "‚úÖ In Context Relevance, input context will be set to __record__.app.retrieve.rets[:] .\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from trulens.core import Feedback\n",
        "from trulens.core import Select\n",
        "from trulens.providers.openai import OpenAI\n",
        "\n",
        "provider = OpenAI(model_engine=\"gpt-4\")\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(\n",
        "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
        "    )\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .on_output()\n",
        ")\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_answer_relevance = (\n",
        "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
        "    .on_input()\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "# Context relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(\n",
        "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
        "    )\n",
        "    .on_input()\n",
        "    .on(Select.RecordCalls.retrieve.rets[:])\n",
        "    .aggregate(np.mean)  # choose a different aggregation method if you wish\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LGMPmvnsP7z"
      },
      "source": [
        "## Construct the app\n",
        "Wrap the custom RAG with TruCustomApp, add list of feedbacks for eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b1uY1dUVsP7z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "instrumenting <class '__main__.RAG'> for base <class '__main__.RAG'>\n",
            "\tinstrumenting retrieve\n",
            "\tinstrumenting generate_completion\n",
            "\tinstrumenting query\n",
            "skipping base <class 'object'> because of class\n"
          ]
        }
      ],
      "source": [
        "from trulens.apps.custom import TruCustomApp\n",
        "\n",
        "tru_rag = TruCustomApp(\n",
        "    rag,\n",
        "    app_name=\"RAG\",\n",
        "    app_version=\"base\",\n",
        "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ectcGw-lsP7z"
      },
      "source": [
        "## Run the app\n",
        "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YQtCSQlCsP7z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calling <function RAG.query at 0x1514981f0> with (<__main__.RAG object at 0x151487a90>, 'What wave of coffee culture is Starbucks seen to represent in the United States?')\n",
            "calling <function RAG.retrieve at 0x151447f40> with (<__main__.RAG object at 0x151487a90>,)\n",
            "calling <function RAG.generate_completion at 0x151498160> with (<__main__.RAG object at 0x151487a90>,)\n",
            "calling <function RAG.query at 0x1514981f0> with (<__main__.RAG object at 0x151487a90>, 'What wave of coffee culture is Starbucks seen to represent in the New Zealand?')\n",
            "calling <function RAG.retrieve at 0x151447f40> with (<__main__.RAG object at 0x151487a90>,)\n",
            "calling <function RAG.generate_completion at 0x151498160> with (<__main__.RAG object at 0x151487a90>,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/michaelmateju/miniconda3/envs/trulens/lib/python3.10/site-packages/trulens/feedback/llm_provider.py:224: UserWarning: No supporting evidence provided. Returning score only.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calling <function RAG.query at 0x1514981f0> with (<__main__.RAG object at 0x151487a90>, 'Does Washington State have Starbucks on campus?')\n",
            "calling <function RAG.retrieve at 0x151447f40> with (<__main__.RAG object at 0x151487a90>,)\n",
            "calling <function RAG.generate_completion at 0x151498160> with (<__main__.RAG object at 0x151487a90>,)\n"
          ]
        }
      ],
      "source": [
        "with tru_rag as recording:\n",
        "    rag.query(\n",
        "        \"What wave of coffee culture is Starbucks seen to represent in the United States?\"\n",
        "    )\n",
        "    rag.query(\n",
        "        \"What wave of coffee culture is Starbucks seen to represent in the New Zealand?\"\n",
        "    )\n",
        "    rag.query(\"Does Washington State have Starbucks on campus?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klA4s9oAsP7z"
      },
      "source": [
        "## Check results\n",
        "\n",
        "We can view results in the leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QUv6peQGsP7z"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_name</th>\n",
              "      <th>app_version</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RAG</th>\n",
              "      <th>base</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>2.637857</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Answer Relevance  Context Relevance  Groundedness  \\\n",
              "app_name app_version                                                      \n",
              "RAG      base                 0.833333                0.1      0.416667   \n",
              "\n",
              "                       latency  total_cost  \n",
              "app_name app_version                        \n",
              "RAG      base         2.637857    0.000079  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "session.get_leaderboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDSFqodLsP7z"
      },
      "source": [
        "## Use guardrails\n",
        "\n",
        "In addition to making informed iteration, we can also directly use feedback results as guardrails at inference time. In particular, here we show how to use the context relevance score as a guardrail to filter out irrelevant context before it gets passed to the LLM. This both reduces hallucination and improves efficiency.\n",
        "\n",
        "To do so, we'll rebuild our RAG using the @context-filter decorator on the method we want to filter, and pass in the feedback function and threshold to use for guardrailing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jOIulSdXsP70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decorating <function context_filter.__call__.<locals>.wrapper at 0x3081663b0>\n",
            "adding method <class '__main__.FilteredRAG'> retrieve __main__\n"
          ]
        }
      ],
      "source": [
        "from trulens.core.guardrails.base import context_filter\n",
        "\n",
        "# note: feedback function used for guardrail must only return a score, not also reasons\n",
        "f_context_relevance_score = Feedback(\n",
        "    provider.context_relevance, name=\"Context Relevance\"\n",
        ")\n",
        "\n",
        "\n",
        "class FilteredRAG(RAG):\n",
        "    @instrument\n",
        "    @context_filter(\n",
        "        feedback=f_context_relevance_score,\n",
        "        threshold=0.75,\n",
        "        keyword_for_prompt=\"query\",\n",
        "    )\n",
        "    def retrieve(self, query: str) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from vector store.\n",
        "        \"\"\"\n",
        "        results = vector_store.query(query_texts=query, n_results=4)\n",
        "        if \"documents\" in results and results[\"documents\"]:\n",
        "            return [doc for sublist in results[\"documents\"] for doc in sublist]\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "\n",
        "filtered_rag = FilteredRAG()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bk3u3oTsP70"
      },
      "source": [
        "## Record and operate as normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EU26wgwNsP70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "instrumenting <class '__main__.FilteredRAG'> for base <class '__main__.FilteredRAG'>\n",
            "\tinstrumenting retrieve\n",
            "\tinstrumenting generate_completion\n",
            "\tinstrumenting query\n",
            "\tinstrumenting retrieve\n",
            "instrumenting <class '__main__.FilteredRAG'> for base <class '__main__.RAG'>\n",
            "\tinstrumenting retrieve\n",
            "\tinstrumenting generate_completion\n",
            "\tinstrumenting query\n",
            "\tinstrumenting retrieve\n",
            "skipping base <class 'object'> because of class\n",
            "calling <function RAG.query at 0x1514981f0> with (<__main__.FilteredRAG object at 0x308119900>,)\n",
            "calling <function context_filter.__call__.<locals>.wrapper at 0x3081663b0> with (<__main__.FilteredRAG object at 0x308119900>,)\n",
            "calling <function RAG.generate_completion at 0x151498160> with (<__main__.FilteredRAG object at 0x308119900>,)\n",
            "calling <function RAG.query at 0x1514981f0> with (<__main__.FilteredRAG object at 0x308119900>, 'What wave of coffee culture is Starbucks seen to represent in the New Zealand?')\n",
            "calling <function context_filter.__call__.<locals>.wrapper at 0x3081663b0> with (<__main__.FilteredRAG object at 0x308119900>,)\n",
            "calling <function RAG.generate_completion at 0x151498160> with (<__main__.FilteredRAG object at 0x308119900>,)\n",
            "calling <function RAG.query at 0x1514981f0> with (<__main__.FilteredRAG object at 0x308119900>, 'Does Washington State have Starbucks on campus?')\n",
            "calling <function context_filter.__call__.<locals>.wrapper at 0x3081663b0> with (<__main__.FilteredRAG object at 0x308119900>,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/michaelmateju/miniconda3/envs/trulens/lib/python3.10/site-packages/trulens/core/feedback/feedback.py:1035: UserWarning: Feedback function Context Relevance with aggregation <function mean at 0x1166a9240> had no inputs.\n",
            "  warnings.warn(\n",
            "/Users/michaelmateju/miniconda3/envs/trulens/lib/python3.10/site-packages/trulens/feedback/llm_provider.py:224: UserWarning: No supporting evidence provided. Returning score only.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calling <function RAG.generate_completion at 0x151498160> with (<__main__.FilteredRAG object at 0x308119900>,)\n"
          ]
        }
      ],
      "source": [
        "from trulens.apps.custom import TruCustomApp\n",
        "\n",
        "filtered_tru_rag = TruCustomApp(\n",
        "    filtered_rag,\n",
        "    app_name=\"RAG\",\n",
        "    app_version=\"filtered\",\n",
        "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
        ")\n",
        "\n",
        "with filtered_tru_rag as recording:\n",
        "    filtered_rag.query(\n",
        "        query=\"What wave of coffee culture is Starbucks seen to represent in the United States?\"\n",
        "    )\n",
        "    filtered_rag.query(\n",
        "        \"What wave of coffee culture is Starbucks seen to represent in the New Zealand?\"\n",
        "    )\n",
        "    filtered_rag.query(\"Does Washington State have Starbucks on campus?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2SSvv_z2sP70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_name</th>\n",
              "      <th>app_version</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">RAG</th>\n",
              "      <th>base</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>2.637857</td>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filtered</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.159674</td>\n",
              "      <td>0.120860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Answer Relevance  Context Relevance  Groundedness  \\\n",
              "app_name app_version                                                      \n",
              "RAG      base                 0.833333           0.083333      0.416667   \n",
              "         filtered             0.333333           1.000000      1.000000   \n",
              "\n",
              "                       latency  total_cost  \n",
              "app_name app_version                        \n",
              "RAG      base         2.637857    0.000079  \n",
              "         filtered     2.159674    0.120860  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "session.get_leaderboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CLGPZK93sP70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting dashboard ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f08082553e3e4b11acaa4fe123ed6897",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dashboard started at http://localhost:51838 .\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from trulens.dashboard import run_dashboard\n",
        "\n",
        "run_dashboard(session)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "trulens",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
