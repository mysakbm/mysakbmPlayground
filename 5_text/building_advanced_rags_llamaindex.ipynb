{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: Advanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "dotenv.load_dotenv(\"/Users/michaelmateju/Documents/Data Science/PycharmProjects/.env\")\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "llm_model_name = \"gpt-4o-mini\" #jmeno modelu, ktery se bude pouzivat napric celym notebookem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.openai import OpenAI as truOpenAI\n",
    "from trulens.apps.llamaindex import TruLlama\n",
    "from trulens.core import TruSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import load_index_from_storage, SimpleDirectoryReader\n",
    "from llama_index.core.storage import StorageContext\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "from llama_index.core.node_parser import get_leaf_nodes\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=llm_model_name, temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./source_notebooks/building_and_evalutation_advanced_rags/eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "41 \n",
      "\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "Doc ID: 559d7a9f-4d2c-4e3e-a9ba-d1964a70fd0a\n",
      "Text: PAGE 1 Founder, DeepLearning.AI Collected Insights from Andrew\n",
      "Ng How to  Build Your Career in AI A Simple Guide\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TruLens settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When looking for projects to build your experience, consider the following steps:\n",
      "\n",
      "1. **Join Existing Projects**: Collaborate with others who have ideas and seek opportunities to contribute to their projects.\n",
      "\n",
      "2. **Engage with Learning**: Spend time reading, taking courses, and discussing with domain experts to generate new project ideas.\n",
      "\n",
      "3. **Focus on Application Areas**: Identify specific applications of machine learning that are underexplored and align with your interests or your organizationâ€™s goals.\n",
      "\n",
      "4. **Develop a Side Hustle**: Work on personal projects outside of your main job to foster creativity and potentially lead to significant opportunities.\n",
      "\n",
      "5. **Evaluate Technical Growth**: Choose projects that challenge your skills but are achievable, helping you progress technically.\n",
      "\n",
      "6. **Collaborate with Good Teammates**: Work with individuals who can provide support and enhance your learning experience.\n",
      "\n",
      "7. **Consider Stepping Stones**: Select projects that can serve as meaningful steps toward larger, more complex undertakings.\n",
      "\n",
      "8. **Avoid Analysis Paralysis**: Make decisions efficiently to avoid overthinking, allowing you to move forward with multiple projects over time.\n",
      "\n",
      "9. **Choose Your Approach**: Decide whether to conduct thorough research before starting a project or to jump in quickly, weighing the risks and benefits based on the situation.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are steps to take when finding projects to build your experience?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the keys to building a career in AI?\n",
      "How can teamwork contribute to success in AI?\n",
      "What is the importance of networking in AI?\n",
      "What are some good habits to develop for a successful career?\n",
      "How can altruism be beneficial in building a career?\n",
      "What is imposter syndrome and how does it relate to AI?\n",
      "Who are some accomplished individuals who have experienced imposter syndrome?\n",
      "What is the first step to becoming good at AI?\n",
      "What are some common challenges in AI?\n",
      "Is it normal to find parts of AI challenging?\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('./source_notebooks/building_and_evalutation_advanced_rags/lecture_1/eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try your own question:\n",
    "new_question = \"What is the right AI job for me?\"\n",
    "eval_questions.append(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the keys to building a career in AI?', 'How can teamwork contribute to success in AI?', 'What is the importance of networking in AI?', 'What are some good habits to develop for a successful career?', 'How can altruism be beneficial in building a career?', 'What is imposter syndrome and how does it relate to AI?', 'Who are some accomplished individuals who have experienced imposter syndrome?', 'What is the first step to becoming good at AI?', 'What are some common challenges in AI?', 'Is it normal to find parts of AI challenging?', 'What is the right AI job for me?']\n"
     ]
    }
   ],
   "source": [
    "print(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "tru = TruSession()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the classroom, we've written some of the code in helper functions inside a utils.py file.  \n",
    "- You can view the utils.py file in the file directory by clicking on the \"Jupyter\" logo at the top of the notebook.\n",
    "- In later lessons, you'll get to work directly with the code that's currently wrapped inside these helper functions, to give you more options to customize your RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = truOpenAI(model_engine=llm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "qa_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "qs_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(TruLlama.select_source_nodes().node.text)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks = [qa_relevance, qs_relevance, f_groundedness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruLlama(\n",
    "    query_engine,\n",
    "    app_id=\"Direct Query Engine\",\n",
    "    feedbacks=feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>...</th>\n",
       "      <th>Groundedness feedback cost in USD</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Context Relevance feedback cost in USD</th>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>cost_currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_4653f8910513cf27b4346249fe5eef08</td>\n",
       "      <td>What is the right AI job for me?</td>\n",
       "      <td>Finding the right AI job for you involves unde...</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_4653f8910513cf27b43...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2025-01-31T15:07:34.809679\", \"...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>3.392069</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_917c95a1f3402c2d695a5903d5c234a0</td>\n",
       "      <td>Is it normal to find parts of AI challenging?</td>\n",
       "      <td>Yes, it is normal to find parts of AI challeng...</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_917c95a1f3402c2d695...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2025-01-31T15:07:33.481111\", \"...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>1.228528</td>\n",
       "      <td>1956</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_bf73e6febbe0175196c15d38f042a9b9</td>\n",
       "      <td>What are some common challenges in AI?</td>\n",
       "      <td>Common challenges in AI include understanding ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_bf73e6febbe0175196c...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2025-01-31T15:07:31.619736\", \"...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>1.755121</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_e323266d66377068dbf095dbeddd6865</td>\n",
       "      <td>What is the first step to becoming good at AI?</td>\n",
       "      <td>The first step to becoming good at AI is to ac...</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_e323266d66377068dbf...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2025-01-31T15:07:30.351648\", \"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>1.158006</td>\n",
       "      <td>1972</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_24fc5fb33299305bd51686f0d56cbbed</td>\n",
       "      <td>Who are some accomplished individuals who have...</td>\n",
       "      <td>Many accomplished individuals in the AI commun...</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_24fc5fb33299305bd51...</td>\n",
       "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
       "      <td>{\"start_time\": \"2025-01-31T15:07:28.384136\", \"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'Who are some accomplishe...</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>1.859945</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      app_id  \\\n",
       "0  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "1  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "2  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "3  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "4  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "1  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "2  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "3  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "4  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_4653f8910513cf27b4346249fe5eef08   \n",
       "1  record_hash_917c95a1f3402c2d695a5903d5c234a0   \n",
       "2  record_hash_bf73e6febbe0175196c15d38f042a9b9   \n",
       "3  record_hash_e323266d66377068dbf095dbeddd6865   \n",
       "4  record_hash_24fc5fb33299305bd51686f0d56cbbed   \n",
       "\n",
       "                                               input  \\\n",
       "0                   What is the right AI job for me?   \n",
       "1      Is it normal to find parts of AI challenging?   \n",
       "2             What are some common challenges in AI?   \n",
       "3     What is the first step to becoming good at AI?   \n",
       "4  Who are some accomplished individuals who have...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  Finding the right AI job for you involves unde...    -   \n",
       "1  Yes, it is normal to find parts of AI challeng...    -   \n",
       "2  Common challenges in AI include understanding ...    -   \n",
       "3  The first step to becoming good at AI is to ac...    -   \n",
       "4  Many accomplished individuals in the AI commun...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {'record_id': 'record_hash_4653f8910513cf27b43...   \n",
       "1  {'record_id': 'record_hash_917c95a1f3402c2d695...   \n",
       "2  {'record_id': 'record_hash_bf73e6febbe0175196c...   \n",
       "3  {'record_id': 'record_hash_e323266d66377068dbf...   \n",
       "4  {'record_id': 'record_hash_24fc5fb33299305bd51...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
       "\n",
       "                                           perf_json  ...  \\\n",
       "0  {\"start_time\": \"2025-01-31T15:07:34.809679\", \"...  ...   \n",
       "1  {\"start_time\": \"2025-01-31T15:07:33.481111\", \"...  ...   \n",
       "2  {\"start_time\": \"2025-01-31T15:07:31.619736\", \"...  ...   \n",
       "3  {\"start_time\": \"2025-01-31T15:07:30.351648\", \"...  ...   \n",
       "4  {\"start_time\": \"2025-01-31T15:07:28.384136\", \"...  ...   \n",
       "\n",
       "  Groundedness feedback cost in USD  Context Relevance  \\\n",
       "0                               NaN                NaN   \n",
       "1                               NaN                NaN   \n",
       "2                               NaN                NaN   \n",
       "3                          0.001700                NaN   \n",
       "4                          0.001688                0.0   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  [{'args': {'prompt': 'Who are some accomplishe...   \n",
       "\n",
       "   Context Relevance feedback cost in USD             app_name app_version  \\\n",
       "0                                     NaN  Direct Query Engine        base   \n",
       "1                                     NaN  Direct Query Engine        base   \n",
       "2                                     NaN  Direct Query Engine        base   \n",
       "3                                     NaN  Direct Query Engine        base   \n",
       "4                                0.000492  Direct Query Engine        base   \n",
       "\n",
       "    latency  total_tokens total_cost  cost_currency  \n",
       "0  3.392069          2024   0.000348            USD  \n",
       "1  1.228528          1956   0.000315            USD  \n",
       "2  1.755121          1960   0.000329            USD  \n",
       "3  1.158006          1972   0.000316            USD  \n",
       "4  1.859945          1960   0.000330            USD  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_76663/1997498841.py:2: DeprecationWarning: Method `run_dashboard` has been renamed or moved to `trulens.dashboard.run.run_dashboard`.\n",
      "\n",
      "  tru.run_dashboard()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9a631b88934757b5fcbe3867d00b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://localhost:62031 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sentence Window retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.node_parser = node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sentence_window_index(\n",
    "    document, embed_model, save_dir=\"./sentence_index\"\n",
    "):\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents([document], embed_model=embedding_model)\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir))\n",
    "\n",
    "    return sentence_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir=\"./source_notebooks/building_and_evalutation_advanced_rags/lecture_1/sentence_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    embed_model=embedding_model,\n",
    "    save_dir=persist_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_window_query_engine(\n",
    "    sentence_index,\n",
    "    similarity_top_k=6,\n",
    "    rerank_top_n=2,\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get started on a personal project in AI, begin by selecting a topic that interests you and aligns with your current skill level. Itâ€™s important to start small; even simple projects can provide valuable learning experiences. For instance, you might consider training a neural network on a basic function or dataset to understand the fundamentals of machine learning.\n",
      "\n",
      "As you work on your project, focus on building foundational skills in machine learning and software development. Familiarize yourself with key concepts such as different models, optimization algorithms, and programming fundamentals. This knowledge will help you tackle more complex projects in the future.\n",
      "\n",
      "Document your progress and be prepared to communicate the value of your work. This will not only help you articulate your accomplishments but also attract potential collaborators or mentors who can provide guidance and support.\n",
      "\n",
      "Finally, remember that each project is a stepping stone in your journey. Use the insights gained from your personal projects to inform your next steps and gradually increase the complexity of your undertakings.\n"
     ]
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"how do I get started on a personal project in AI?\"\n",
    ")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tru.reset_database()\n",
    "\n",
    "tru_recorder_sentence_window = TruLlama(\n",
    "    sentence_window_engine,\n",
    "    app_id=\"Sentence Window Query Engine\",\n",
    "    feedbacks=feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = sentence_window_engine.query(question)\n",
    "        print(question)\n",
    "        print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Direct Query Engine</th>\n",
       "      <th>base</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2.216288</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <th>base</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.834291</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Answer Relevance  Context Relevance  \\\n",
       "app_name                     app_version                                        \n",
       "Direct Query Engine          base                 0.866667           0.395833   \n",
       "Sentence Window Query Engine base                      NaN                NaN   \n",
       "\n",
       "                                          Groundedness   latency  total_cost  \n",
       "app_name                     app_version                                      \n",
       "Direct Query Engine          base             0.866667  2.216288    0.000353  \n",
       "Sentence Window Query Engine base                  NaN  2.834291    0.000370  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Dashboard already running at path:   Local URL: http://localhost:62031\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Auto-merging retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_automerging_index(\n",
    "    documents,\n",
    "    save_dir=\"merging_index\",\n",
    "    chunk_sizes=None,\n",
    "):\n",
    "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
    "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "\n",
    "    Settings.node_parser = node_parser\n",
    "\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        automerging_index = VectorStoreIndex(\n",
    "            leaf_nodes, storage_context=storage_context)\n",
    "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        automerging_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir))\n",
    "    return automerging_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir=\"./source_notebooks/building_and_evalutation_advanced_rags/lecture_1/merging_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "automerging_index = build_automerging_index(\n",
    "    documents,\n",
    "    save_dir=persist_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_automerging_query_engine(\n",
    "    automerging_index,\n",
    "    similarity_top_k=12,\n",
    "    rerank_top_n=2,\n",
    "):\n",
    "    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "    retriever = AutoMergingRetriever(\n",
    "        base_retriever, automerging_index.storage_context, verbose=True\n",
    "    )\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "    auto_merging_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever, node_postprocessors=[rerank]\n",
    "    )\n",
    "    return auto_merging_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "automerging_query_engine = get_automerging_query_engine(\n",
    "    automerging_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: fd34c388-e5d0-4e76-99a5-14bc58d34f59.\n",
      "> Parent node text: PAGE 21\n",
      "Building a Portfolio of \n",
      "Projects that Shows \n",
      "Skill Progression \n",
      "CHAPTER 6\n",
      "PROJECTS\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 862488c3-9b98-4cca-b2a5-2bcf1c971365.\n",
      "> Parent node text: PAGE 21\n",
      "Building a Portfolio of \n",
      "Projects that Shows \n",
      "Skill Progression \n",
      "CHAPTER 6\n",
      "PROJECTS\n",
      "\n",
      "To build a portfolio of AI projects, start by selecting a range of projects that demonstrate your skills and knowledge. Focus on showcasing a progression from simpler projects to more complex ones, highlighting your growth and learning over time. It's also essential to communicate your thought process clearly, as this will help others understand the value of your work and trust you with more significant opportunities. Consider applying machine learning to various industries, as diverse applications can enrich your portfolio and provide valuable experience.\n"
     ]
    }
   ],
   "source": [
    "auto_merging_response = automerging_query_engine.query(\n",
    "    \"How do I build a portfolio of AI projects?\"\n",
    ")\n",
    "print(str(auto_merging_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tru.reset_database()\n",
    "\n",
    "tru_recorder_automerging = TruLlama(\n",
    "    automerging_query_engine,\n",
    "    app_id=\"Automerging Query Engine\",\n",
    "    feedbacks=feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerging_query_engine.query(question)\n",
    "        print(question)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Automerging Query Engine</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>2.144787</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Direct Query Engine</th>\n",
       "      <th>base</th>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>2.216288</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <th>base</th>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.890332</td>\n",
       "      <td>2.834291</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Answer Relevance  Context Relevance  \\\n",
       "app_name                     app_version                                        \n",
       "Automerging Query Engine     base                 1.000000           0.472222   \n",
       "Direct Query Engine          base                 0.878788           0.378788   \n",
       "Sentence Window Query Engine base                 0.848485           0.484848   \n",
       "\n",
       "                                          Groundedness   latency  total_cost  \n",
       "app_name                     app_version                                      \n",
       "Automerging Query Engine     base             0.909722  2.144787    0.000113  \n",
       "Direct Query Engine          base             0.872727  2.216288    0.000353  \n",
       "Sentence Window Query Engine base             0.890332  2.834291    0.000370  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Dashboard already running at path:   Local URL: http://localhost:62031\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
