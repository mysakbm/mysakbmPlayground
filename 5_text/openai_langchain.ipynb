{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9200dc",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d36b45-481b-473f-bfd6-d8656887d8dc",
   "metadata": {},
   "source": [
    "Pozn.: zde se nach√°zej√≠ importy pot≈ôebn√© pro to, aby po restartu kernelu bƒõ≈æela libovoln√° bu≈àka. V r√°mci v√Ωkladu jsou p≈ôi setk√°n√≠ se s urƒçitou t≈ô√≠dou ƒçi funkc√≠ importy samoz≈ôejmƒõ uvedeny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db94ccfe-01ea-4e5b-8a90-f75d359dc487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:47:10.485947Z",
     "start_time": "2024-09-23T10:47:09.274345Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "import langchain\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains import TransformChain\n",
    "\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "from langchain.memory import ConversationTokenBufferMemory \n",
    "from langchain.memory import ConversationSummaryMemory \n",
    "from langchain.memory import ConversationEntityMemory \n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.document_loaders import BSHTMLLoader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import Language\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "llm_model_name = \"gpt-4o-mini\" #jmeno modelu, ktery se bude pouzivat napric celym notebookem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9b1d5-7127-490e-8ffd-b23f2e3ce37c",
   "metadata": {},
   "source": [
    "V dobƒõ psan√≠ tƒõchto ≈ô√°dk≈Ø je to u≈æ nƒõkolik mƒõs√≠c≈Ø, co vzalo ChatGPT svƒõt √∫tokem. ƒålovƒõk se tak mohl pravidelnƒõ i ve sdƒõlovac√≠ch prost≈ôedc√≠ch setk√°vat s v√≠ce ƒçi m√©nƒõ relevantn√≠mi ƒçl√°nky o AI. Tento spisek nem√° ambice kr√°ƒçet jim po boku - absolutnƒõ netu≈°√≠m, zda AI (z nƒõjak√©ho d≈Øvodu ztoto≈ænƒõn√° s generativn√≠mi modely - nap≈ô. s \"dopl≈àovaƒçi\" textu ala GPT) zaƒçne nahrazovat zamƒõstnance, zda n√°s vyhub√≠ anebo zda ≈æivot p≈Øjde d√°l ve star√Ωch kolej√≠ch. Nam√≠sto toho bych tu chtƒõl uk√°zat, jak pracovat s modely od OpenAI a to sice jak nap≈ô√≠mo, tak skrze framework Langchain.  \n",
    "Na tomto m√≠stƒõ mus√≠m doporuƒçit [langchainov√© kurzy](https://www.deeplearning.ai/short-courses/), kter√© jsou dostupn√© na deeplearning.ai a ze kter√Ωch jsem p≈ôi tvo≈ôen√≠ tohoto textu vych√°zel.\n",
    "\n",
    "# Obsah\n",
    "- [OpenAI](#OpenAI)\n",
    "  - [Tokeny](#Tokeny)\n",
    "  - [API kl√≠ƒç](#API-kl√≠ƒç)\n",
    "  - [Jednoduch√Ω p≈ô√≠klad](#Jednoduch√Ω-p≈ô√≠klad)\n",
    "  - [Chatbot](#Chatbot)\n",
    "- [Langchain](#Langchain)\n",
    "  - [≈†ablony prompt≈Ø](#≈†ablony-prompt≈Ø)\n",
    "  - [Chains](#Chains)\n",
    "    - [LLMChain](#LLMChain)\n",
    "    - [Sekvenƒçn√≠ chainy](#Sekvenƒçn√≠-chainy)\n",
    "    - [RouterChain](#RouterChain)\n",
    "    - [Transformation chain](#Transformation-chain)\n",
    "  - [Pamƒõ≈•](#Pamƒõ≈•)\n",
    "    - [ConversationBufferMemory](#ConversationBufferMemory)\n",
    "    - [ConversationBufferWindowMemory](#ConversationBufferWindowMemory)\n",
    "    - [ConversationTokenBufferMemory](#ConversationTokenBufferMemory)\n",
    "    - [ConversationSummaryMemory](#ConversationSummaryMemory)\n",
    "    - [ConversationEntityMemory](#ConversationEntityMemory)\n",
    "  - [Q&A nad dokumenty](#Q&A-nad-dokumenty)\n",
    "    - [Naƒçten√≠ dokunet≈Ø](#Naƒçten√≠-dokument≈Ø)\n",
    "      - [Naƒçten√≠ pdfka](#Naƒçten√≠-pdfka)\n",
    "      - [Naƒçten√≠ html souboru](#Naƒçten√≠-html-souboru)\n",
    "      - [Naƒçten√≠ webov√© str√°nky](#Naƒçten√≠-webov√©-str√°nky)\n",
    "    - [Splittery](#Splittery)\n",
    "    - [Embeddings, vectorstore](#Embeddings,-vectorstore)\n",
    "    - [Similarity search](#Similarity-search)\n",
    "    - [Question answering](#Question-answering)\n",
    "    - [Automatick√© pou≈æ√≠v√°n√≠ metadat](#Automatick√©-pou≈æ√≠v√°n√≠-metadat)\n",
    "    - [Prefix p≈ôed fragmenty](#Prefix-p≈ôed-fragmenty)\n",
    "  - [Kompletn√≠ uk√°zky](#Kompletn√≠-uk√°zky)\n",
    "    - [Obyƒçejn√Ω chatbot](#Obyƒçejn√Ω-chatbot)\n",
    "    - [Q&A chatbot](#Q&A-chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e198da-9fac-41e2-9600-3f32ae798f47",
   "metadata": {},
   "source": [
    "# OpenAI\n",
    "### Tokeny\n",
    "Pro pou≈æit√≠ OpenAI ƒçlovƒõk nap≈ôed mus√≠ sebe i svou kartu registrovat [zde](https://platform.openai.com/). Na str√°nk√°ch je pot√© t≈ôeba nechat si vygenerovat API kl√≠ƒç, s jeho≈æ pomoc√≠ p≈ôi RESTov√©m vol√°n√≠ OpenAI pozn√°, co m√° komu vlastnƒõ na√∫ƒçtovat. Cen√≠k nalezneme [tady](https://openai.com/pricing). Je vhodn√© zd≈Øraznit, ≈æe narozd√≠l od dejme tomu Midjourney si ƒçlovƒõk nekupuje mƒõs√≠ƒçn√≠ p≈ôedplatn√©, n√Ωbr≈æ plat√≠ za m√≠ru pou≈æ√≠v√°n√≠ model≈Ø. P≈ôesnƒõji plat√≠ za poƒçet modelem zpracovan√Ωch token≈Ø. Do toho se poƒç√≠taj√≠ jak tokeny do modelu vstupuj√≠c√≠, tak tokeny modelem produkovan√©. A co ≈æe je vlastnƒõ onen token? Jedn√° se o skupinu p√≠smen, kter√° tvo≈ô√≠ slovo anebo jeho ƒç√°st. V angliƒçtinƒõ v pr≈Ømƒõru vych√°z√≠ 1 token na 0,75 slova, v jin√Ωch jazyc√≠ch je pomƒõr hor≈°√≠. Pro z√≠sk√°n√≠ re√°ln√© p≈ôedstavy doporuƒçuji pod√≠vat se [sem](https://platform.openai.com/tokenizer). Krom oƒçividn√©ho omezen√≠ penƒõ≈æenkou je souƒçet vstupn√≠ch a v√Ωstupn√≠ch token≈Ø (a tak i d√©lka textu) omezen pamƒõt√≠ modelu (kontextem z pricing str√°nky) - nap≈ô√≠klad pro 4K GPT-3.5 model nen√≠ mo≈æn√© m√≠t text (ot√°zku a odpovƒõƒè) del≈°√≠ ne≈æ 4000 token≈Ø - nadbyteƒçn√© tokeny budou o≈ô√≠znuty, resp. v≈Øbec nevzniknou. O tom se ƒçlovƒõk m≈Ø≈æe p≈ôedvƒõdƒçit v \"klasick√©m\" webov√©m GUI rozhran√≠ ChatGPT. Model s√°m o sobƒõ si nepamatuje, co se dƒõlo v p≈ôedchoz√≠m hovoru. Proto se mu mus√≠ cel√° historie konverzace p≈ôi ka≈æd√© interakci pos√≠lat nanovo. Po ƒçase je historie p≈ô√≠li≈° dlouh√° a tak jsou star√© tokeny zahozeny a model tud√≠≈æ zaƒçne zapom√≠nat zaƒç√°tky konverzac√≠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eabb417-6202-4e39-b69d-3bada92a78ab",
   "metadata": {},
   "source": [
    "### API kl√≠ƒç\n",
    "Prvn√≠ tutori√°lov√Ω p≈ô√≠klad na [str√°nk√°ch openai bal√≠ƒçku](https://pypi.org/project/openai/) zaƒç√≠n√° s \n",
    "```python\n",
    "import openai\n",
    "openai.api_key = \"sk-...\"  # supply your API key however you choose\n",
    "```\n",
    "Jeho probl√©m tkv√≠ ve skuteƒçnosti, ≈æe je API kl√≠ƒç um√≠stƒõn uprost≈ôed k√≥du. Kdy≈æ si ƒçlovƒõk ned√° pozor a k√≥d nƒõkam po≈°le (t≈ôeba na GitHub), m≈Ø≈æe se jeho jm√©nem (a jeho penƒõ≈æenkou) GPT model≈Ø dotazovat cel√Ω internet. Proto bude lep≈°√≠ pou≈æ√≠vat [python-dotenv](https://pypi.org/project/python-dotenv/) bal√≠ƒçek. S jeho pomoc√≠ Python naƒçte kl√≠ƒç z .env souboru a nastav√≠ ho jako promƒõnnou prost≈ôed√≠. Jak to konkr√©tnƒõ provedeme? Nejprve si ve stejn√©m adres√°≈ôi, ve kter√©m se nal√©z√° notebook (ipynb soubor), vytvo≈ô√≠me .env soubor (opravdu se takto jmenuje, tj. v n√°zvu je jen p≈ô√≠pona) a vlo≈æ√≠me do nƒõj\n",
    "```\n",
    "OPENAI_API_KEY=nazdar1234\n",
    "```\n",
    "Pot√© naimportujeme *dotenv* a provol√°me funkci *load_dotenv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfaf82f1-23eb-4e48-98e4-295e08019685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:47:15.881406Z",
     "start_time": "2024-09-23T10:47:15.878293Z"
    }
   },
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6b05d-19c9-47fd-90c4-fd47298dbcef",
   "metadata": {},
   "source": [
    "≈Ωe se promƒõnn√° prost≈ôed√≠ naƒçetla ovƒõ≈ô√≠me s pomoc√≠ bal√≠ƒçku *os*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89a80cd8-c39f-48c5-8a37-512a9dc775f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c577a6-b8ec-4715-903f-027d59d8f30b",
   "metadata": {},
   "source": [
    "Pokud pracujeme s Azure OpenAI, je t≈ôeba inicializovat je≈°tƒõ nƒõkolik dal≈°√≠ch promƒõnn√Ωch prost≈ôed√≠. Na tƒõch u≈æ nic moc tajn√©ho nen√≠, tud√≠≈æ mohou b√Ωt volnƒõ v k√≥du. Vypadaj√≠ nƒõjak takto:\n",
    "```python\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_base = \"http://testingazureopenai.openai.azure.com\"\n",
    "```\n",
    "Api type bude asi v≈ædy stejn√©, api version se bude s ƒçasem mƒõnit a nakonec api base z√°vis√≠ na jm√©nƒõ openai resourcu. Tyto parametry se daj√≠ nejsnadnƒõji zjistit, kdy≈æ v AzureAI studiu vlezeme do \"Chat Playground\" a v sekci \"Chat Session\" klepneme na \"View Code\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c3d54-2db3-46e4-ba2b-6c56b8f74e9f",
   "metadata": {},
   "source": [
    "### Jednoduch√Ω p≈ô√≠klad\n",
    "Nyn√≠ ale p≈ôikroƒçme k prvn√≠mu chatovac√≠mu p≈ô√≠kladu. Nap≈ôed si naƒçteme pot≈ôebn√© bal√≠ƒçky a API kl√≠ƒç. Ten je pot≈ôeba vlo≈æit do *OpenAI* objektu, konkr√©tnƒõ do parametru *api_key*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad4e0c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:47:23.390088Z",
     "start_time": "2024-09-23T10:47:23.376945Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ed9d6-f9fd-4e26-a99e-d82e041b7d54",
   "metadata": {},
   "source": [
    "N√°slednƒõ si vytvo≈ô√≠me objekt reprezentuj√≠c√≠ chat a to s pomoc√≠ [*chat.completions.create*](https://platform.openai.com/docs/api-reference/chat/create). Tomu podhod√≠me jednak model, kter√Ω chceme pou≈æ√≠vat (parametr *model*), jednak dosavadn√≠ historii konverzace (parametr *messages*). Ta m√° podobu listu json≈Ø obsahuj√≠c√≠ch jednak informaci o mluvƒç√≠m (kl√≠ƒç \"role\" s hodnotami \"user\" ƒçi \"assistant\"), jednak samotnou promluvu (kl√≠ƒç \"content\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba9dfb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:48:55.017416Z",
     "start_time": "2024-09-22T19:48:54.159133Z"
    }
   },
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Ahoj.\"}\n",
    "    ],\n",
    "    model=llm_model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c581e07-af0a-4a56-ba18-719a270045c3",
   "metadata": {},
   "source": [
    "V√Ωstupem je n√°sleduj√≠c√≠ vƒõc. V≈°imnƒõte si, ≈æe na konci dost√°v√°me i informaci o poƒçtu pou≈æit√Ωch token≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae970788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:48:58.939970Z",
     "start_time": "2024-09-22T19:48:58.937465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Au5z2W1nUzZivxgCkj1uNrScLyc4A', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Ahoj! Jak se m√°≈°? Jak ti mohu pomoci?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737932732, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=17, prompt_tokens=11, total_tokens=28, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b960a-c9cc-4a33-8d97-401b5739963f",
   "metadata": {},
   "source": [
    "Pokud chceme ale jen odpovƒõƒè chatbota, pou≈æijeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0724ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:49:09.611592Z",
     "start_time": "2024-09-22T19:49:09.609044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ahoj! Jak se m√°≈°? Jak ti mohu pomoci?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce50b5-a25a-466e-86a7-b8efc51ef306",
   "metadata": {},
   "source": [
    "Do *create* metody lze vlo≈æit dal≈°√≠ parametry. Nap≈ô√≠klad *temperature*, kter√° s rostouc√≠ hodnotou vede k chaotiƒçtƒõj≈°√≠m/kreativnƒõj≈°√≠m odpovƒõd√≠m. Podle dokumentace je minimum 0, maximum 2 a default 1. Obecnƒõ ale hodnoty vƒõt≈°√≠ ne≈æ 1 vedou obvykle k nesmysln√© zmƒõti p√≠smen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc94acb-3396-4689-98af-c72f04c47de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ahoj! Jak ti mohu pomoci?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=llm_model_name,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Ahoj.\"}\n",
    "  ],\n",
    "  temperature=2\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd0bebc-3e04-43dd-b853-7322c77d028d",
   "metadata": {},
   "source": [
    "Do *messages* lze vlo≈æit i tzv. syst√©mov√Ω prompt, kter√Ω chatbotu ≈ô√≠k√°,v jak√© roli m√° vlastnƒõ vystupovat. Takov√°to vƒõc se oznaƒçuje kl√≠ƒçem \"system\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70eaf800-d080-4b1f-8e5f-456b6a6f6847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urƒçitƒõ si dej o≈ô√≠≈°ky! Jsou lahodn√© a pln√© energie!\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=llm_model_name,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Jsi veverka miluj√≠c√≠ o≈ô√≠≈°ky. Odpov√≠d√°≈° maxim√°lnƒõ ve dvou vƒõt√°ch.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Co bych si mƒõl d√°t ke svaƒçinƒõ?\"}\n",
    "  ],\n",
    "  temperature=0.7\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d415a8e",
   "metadata": {},
   "source": [
    "Pozn.: v√Ω≈°e uveden√© informace plat√≠ pro verzi bal√≠ƒçku openai vƒõt≈°√≠ nebo rovnou 1.0.0 ze z√°≈ô√≠ 2023. Pokud mus√≠te pracovat s verz√≠ star≈°√≠, vypad√° k√≥d nƒõjak takto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a1d9945-57ce-4741-83d4-62021dbcabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import openai\n",
    "# import dotenv\n",
    "\n",
    "# dotenv.load_dotenv()\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# completion = openai.ChatCompletion.create(\n",
    "#   model=llm_model_name,\n",
    "#   messages=[\n",
    "#     {\"role\": \"user\", \"content\": \"Ahoj.\"}\n",
    "#   ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8da9c-18af-4973-a488-0bc73f954164",
   "metadata": {},
   "source": [
    "Pokud pracujeme s Azure OpenAI, mus√≠me napsat nƒõco v n√°sleduj√≠c√≠m duchu:\n",
    "```python\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=openai.api_version,\n",
    "    azure_endpoint=openai.api_base,\n",
    "    api_key=openai.api_key\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"jmeno_deploymentu\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Ahoj.\"}\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8850361-8b56-4533-8686-0a8275321f2d",
   "metadata": {},
   "source": [
    "### Chatbot\n",
    "Bohu≈æel k√≥d jak ho tady m√°me jako chatbot nefunguje - nijak se tu neukl√°d√° historie konverzac√≠ a poka≈æd√© tak zaƒç√≠n√°me nanovo. V openai bal√≠ƒçku se ≈æ√°dn√° p≈ô√≠hodn√° funkce ani t≈ô√≠da nenal√©z√° a tak si celou (by≈• v tomto p≈ô√≠padƒõ ultra kr√°tkou) logiku mus√≠me napsat sami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dfecf1c-b50b-4075-b5ac-28ea82ec94e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T22:17:29.398591Z",
     "start_time": "2024-09-21T22:17:16.455323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pro ukonƒçen√≠ konverzace napi≈°te 'exit'\n",
      "Chatbot: Ahoj! M√°m chu≈• na o≈ô√≠≈°ky! üêøÔ∏èü•ú\n",
      "Chatbot: Nejradƒõji m√°m vla≈°sk√© a l√≠skov√© o≈ô√≠≈°ky! Jsou tak chutn√© a pln√© energie! üêøÔ∏è‚ú®\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"Jsi veverka miluj√≠c√≠ o≈ô√≠≈°ky. Odpov√≠d√°≈° maxim√°lnƒõ ve dvou vƒõt√°ch.\"}\n",
    "  ]\n",
    "\n",
    "print(\"Pro ukonƒçen√≠ konverzace napi≈°te 'exit'\")\n",
    "\n",
    "while True:\n",
    "    user_message = input(\"U≈æivatel: \")\n",
    "    if user_message == \"exit\":\n",
    "        break\n",
    "    chat_history.append(\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    )\n",
    "    conversation = client.chat.completions.create(\n",
    "        model=llm_model_name,\n",
    "        messages=chat_history,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    chatbot_answer = conversation.choices[0].message.content\n",
    "    chat_history.append(\n",
    "        {\"role\": \"assistant\", \"content\": chatbot_answer}\n",
    "    )\n",
    "    print(f\"Chatbot: {chatbot_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d48d9",
   "metadata": {},
   "source": [
    "# Promty\n",
    "Protoze prace jde usnadnit, tak existuji promty jakozto promenne, ktere se davaji do funkce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf86bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:50:32.563031Z",
     "start_time": "2024-09-22T19:50:32.560484Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, client, model=llm_model_name):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b30e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:50:44.145499Z",
     "start_time": "2024-09-22T19:50:43.502755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\", client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc052af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:27.367308Z",
     "start_time": "2024-09-22T19:52:27.364881Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4deaa32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:27.646275Z",
     "start_time": "2024-09-22T19:52:27.644205Z"
    }
   },
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c54c1498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:28.203337Z",
     "start_time": "2024-09-22T19:52:28.201203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3acee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:31.311627Z",
     "start_time": "2024-09-22T19:52:30.192608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am quite frustrated that the lid of my blender came off and splattered my kitchen walls with smoothie. To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I would really appreciate your assistance with this issue. Thank you.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_completion(prompt, client)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8398575-3403-4630-a8ee-2b1a4ffcd106",
   "metadata": {},
   "source": [
    "# Langchain\n",
    "Sice bychom mohli pokraƒçovat v pou≈æ√≠v√°n√≠ ƒçist√©ho openai bal√≠ƒçku, ale museli bychom p≈ôitom programovat v√≠ce, ne≈æ by bylo pot≈ôeba. Existuje toti≈æ bal√≠ƒçek Langchain, kter√Ω hromadu pr√°ce udƒõl√° za n√°s.  \n",
    "Pozn.: I v p≈ô√≠padƒõ Langchainu se s postupem ƒçasu objevily zmƒõny. P≈Øvodn√≠ k√≥d bude dohledateln√Ω v historii repa, kter√© pr√°vƒõ ƒçtete. Krom zmƒõn k√≥du se objevila i pot≈ôeba nainstalovat si integraƒçn√≠ bal√≠ƒçek [langchain-openai](https://pypi.org/project/langchain-openai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e3ccf-1714-436f-957c-9c9ab46ae48a",
   "metadata": {},
   "source": [
    "### ≈†ablony prompt≈Ø"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539dd7f3-d650-4bd5-b9fb-11c9b81d5233",
   "metadata": {},
   "source": [
    "S pomoc√≠ ≈°ablon lze s minim√°ln√≠ prac√≠ nav√≠c p≈ôepou≈æ√≠vat i pomƒõrnƒõ komplexn√≠ prompty. Pro n√°zornost nicm√©nƒõ zaƒçnƒõme nƒõƒç√≠m jednoduch√Ωm.  \n",
    "Nap≈ôed si nap√≠≈°eme stringov√Ω z√°klad ≈°ablony, ve kter√©m vlo≈æ√≠me dodateƒçn√© parametry do slo≈æen√Ωch z√°vorek. Vlastnƒõ to vypad√° jako f-stringy, jen to f-ko na zaƒç√°tku chyb√≠. ≈†ablonu jako takovou vytvo≈ô√≠me s pomoc√≠ *ChatPromptTemplate.from_template*, do kter√© jako parametr vlo≈æ√≠me string z p≈ôedchoz√≠ho kroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bea5c6a-b186-4a53-a593-f37b844cfd5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:42.132261Z",
     "start_time": "2024-09-22T19:52:42.129567Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template_text = \"\"\"\n",
    "V jedn√© vƒõtƒõ shr≈à text obklopen√Ω trojic√≠ uvozovek. Odpovƒõƒè mus√≠ b√Ωt naps√°na v {language} jazyce. \n",
    "Text: '''{text}'''\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65461648-59d5-48c2-8173-3b8fca1e4d4e",
   "metadata": {},
   "source": [
    "Takto vypad√° j√°dro \"≈°ablonov√©ho\" objektu. V prvn√≠ ƒç√°sti vid√≠me jm√©na do ≈°ablony dosazovan√Ωch promƒõnn√Ωch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "814696ed-f042-446f-88e7-d5f10fccc884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:46.654007Z",
     "start_time": "2024-09-22T19:52:46.650851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, template=\"\\nV jedn√© vƒõtƒõ shr≈à text obklopen√Ω trojic√≠ uvozovek. Odpovƒõƒè mus√≠ b√Ωt naps√°na v {language} jazyce. \\nText: '''{text}'''\\n\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd46cf10-cd9f-4818-995e-010afbca9f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:52:49.391902Z",
     "start_time": "2024-09-22T19:52:49.389825Z"
    }
   },
   "outputs": [],
   "source": [
    "language = \"anglick√©m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcccc59-d2de-4f30-8b2a-e6e41023316c",
   "metadata": {},
   "source": [
    "Jako testovac√≠ text pou≈æijeme kousek z [wiki ƒçl√°nku o veverk√°ch](https://cs.wikipedia.org/wiki/Veverka_obecn%C3%A1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36b6406e-6b90-4a65-b51e-0e965e657598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:54:24.099426Z",
     "start_time": "2024-09-22T19:54:24.097333Z"
    }
   },
   "outputs": [],
   "source": [
    "squirrel_text = \"\"\"\n",
    "Veverka obecn√° obvykle dor≈Øst√° 19 a≈æ 23 cm a dosahuje hmotnosti mezi 250 a 340 g nƒõkdy i v√≠c. \n",
    "Hu≈àat√Ω ocas, kter√Ω napom√°h√° udr≈æovat rovnov√°hu p≈ôi lezen√≠ a skoc√≠ch na stromech a kter√Ω veverka vyu≈æ√≠v√° \n",
    "jako ‚Äûpokr√Ωvku‚Äú tƒõla p≈ôi sp√°nku, je 14,5 a≈æ 20 cm dlouh√Ω.[3] Charakteristick√Ωm znakem veverky obecn√© jsou st≈ôapce \n",
    "chlup≈Ø na u≈°n√≠ch boltc√≠ch smƒõ≈ôuj√≠c√≠ do ≈°piƒçky a viditeln√© p≈ôedev≈°√≠m v zimn√≠m obdob√≠. \n",
    "Stejnƒõ jako vƒõt≈°ina stromov√Ωch veverek m√° i veverka obecn√° ostr√© a zak≈ôiven√© dr√°py, kter√© j√≠ pom√°haj√≠ p≈ôi lezen√≠ po vƒõtv√≠ch strom≈Ø. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25ec0a-3618-4397-bdb7-c66685d161ba",
   "metadata": {},
   "source": [
    "Promƒõnn√© se do ≈°ablony dostanou v r√°mci provol√°n√≠ metody *format_messages*. V n√≠ by ka≈æd√© promƒõnn√© mƒõl odpov√≠dat jeden parametr nesouc√≠ jej√≠ jm√©no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d370202-fdc3-477b-a9a7-d28b3c11dd4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:54:34.196838Z",
     "start_time": "2024-09-22T19:54:34.193915Z"
    }
   },
   "outputs": [],
   "source": [
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    text=squirrel_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e35af2a-1645-43ec-b89d-7e63450525b9",
   "metadata": {},
   "source": [
    "V√Ωsledek vypad√° n√°slednƒõ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aff4fb8c-ac7d-4da5-a8a8-41a6d742ba8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:18.968676Z",
     "start_time": "2024-09-22T19:55:18.964449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"\\nV jedn√© vƒõtƒõ shr≈à text obklopen√Ω trojic√≠ uvozovek. Odpovƒõƒè mus√≠ b√Ωt naps√°na v anglick√©m jazyce. \\nText: '''\\nVeverka obecn√° obvykle dor≈Øst√° 19 a≈æ 23 cm a dosahuje hmotnosti mezi 250 a 340 g nƒõkdy i v√≠c. \\nHu≈àat√Ω ocas, kter√Ω napom√°h√° udr≈æovat rovnov√°hu p≈ôi lezen√≠ a skoc√≠ch na stromech a kter√Ω veverka vyu≈æ√≠v√° \\njako ‚Äûpokr√Ωvku‚Äú tƒõla p≈ôi sp√°nku, je 14,5 a≈æ 20 cm dlouh√Ω.[3] Charakteristick√Ωm znakem veverky obecn√© jsou st≈ôapce \\nchlup≈Ø na u≈°n√≠ch boltc√≠ch smƒõ≈ôuj√≠c√≠ do ≈°piƒçky a viditeln√© p≈ôedev≈°√≠m v zimn√≠m obdob√≠. \\nStejnƒõ jako vƒõt≈°ina stromov√Ωch veverek m√° i veverka obecn√° ostr√© a zak≈ôiven√© dr√°py, kter√© j√≠ pom√°haj√≠ p≈ôi lezen√≠ po vƒõtv√≠ch strom≈Ø. \\n'''\\n\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bafe03",
   "metadata": {},
   "source": [
    "Alternativni priklad s jinyma promennyma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6310a5d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:31.265618Z",
     "start_time": "2024-09-22T19:55:31.263185Z"
    }
   },
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56310e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:34.685564Z",
     "start_time": "2024-09-22T19:55:34.683249Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c4b79c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:36.383516Z",
     "start_time": "2024-09-22T19:55:36.380967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "088d6049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:37.918690Z",
     "start_time": "2024-09-22T19:55:37.915067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf8ca85d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:39.158338Z",
     "start_time": "2024-09-22T19:55:39.156368Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85445c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:40.018713Z",
     "start_time": "2024-09-22T19:55:40.016678Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0388a597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:40.486025Z",
     "start_time": "2024-09-22T19:55:40.483728Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db882e05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T19:55:41.696499Z",
     "start_time": "2024-09-22T19:55:41.694180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))\n",
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac619362-b998-49d0-85e2-46b76c48dc0a",
   "metadata": {},
   "source": [
    "Nyn√≠ mus√≠me Langchainu ≈ô√≠ct, s jak√Ωm jazykov√Ωm modelem m√° pracovat. Pro podporovan√© modely p≈ôitom existuj√≠ separ√°tn√≠ t≈ô√≠dy. Seznam nalezneme [zde](https://python.langchain.com/docs/integrations/llms/). Zd≈Øraznƒõme, ≈æe zat√≠mco bal√≠ƒçek openai dok√°zal obhospoda≈ôit jak OpenAI modely, tak Azure OpenAI modely, zde se jedn√° o separ√°tn√≠ entity. Nav√≠c historicky byl a asi po≈ô√°d je rozd√≠l mezi t≈ô√≠dami OpenAI a ChatOpenAI importovan√Ωmi nyn√≠ z langchain_openai.  \n",
    "Jak√© parametry m≈Ø≈æeme do konstruktoru ChatOpenAI vlo≈æit? Jedn√° se prim√°rnƒõ o teplotu (parametr *temperature* s defaultn√≠ hodnotou 0.7) a jm√©no LLM modelu (parametr *model_name* s defaultn√≠ hodnotou \"gpt-3.5-turbo\"). API kl√≠ƒç m≈Ø≈æeme p≈ôed√°vat parametrem *api_key* - pokud tak explicitnƒõ neudƒõl√°me, bude Langchain kl√≠ƒç hledat v *os.environ\\[\"OPENAI_API_KEY\"\\]*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ac12d0a-609c-4b47-93bc-4ff95da35beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:01:04.128477Z",
     "start_time": "2024-09-22T20:01:04.107761Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(temperature=0.0, model_name=llm_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82241053-df9c-4834-85d6-ff873d1ac1f1",
   "metadata": {},
   "source": [
    "Kdy≈æ pak do metody *invoke* na≈°eho chatovac√≠ho modelu vlo≈æ√≠me jako parametr ≈°ablonu a v√Ωsledku se zept√°me na atribut *content*, z√≠sk√°me odpovƒõƒè. Vid√≠me, ≈æe anglick√Ω jazyk sice model pochopil, ale shrnut√≠ zabralo v√≠ce ne≈æ po≈æadovanou jednu vƒõtu. no, shrnut√≠ - text vypad√° sp√≠≈° jako p≈ôeklad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18a12548-0533-4904-8abb-4d564f029715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:01:11.656041Z",
     "start_time": "2024-09-22T20:01:10.743228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The common squirrel typically measures 19 to 23 cm in length, weighs between 250 and 340 g, has a bushy tail for balance and warmth, and features distinctive ear tufts and sharp, curved claws for climbing.\n"
     ]
    }
   ],
   "source": [
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e2b9b",
   "metadata": {},
   "source": [
    "Jeste zkusime, co to udela, kdyz to zavolame na ten druhy priklad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19380b7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:01:59.494726Z",
     "start_time": "2024-09-22T20:01:58.628860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat.invoke(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8141c664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:01.924293Z",
     "start_time": "2024-09-22T20:02:01.922239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am quite frustrated that the lid of my blender came off and splattered smoothie all over my kitchen walls. To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I would really appreciate your assistance with this issue. Thank you.\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe752345",
   "metadata": {},
   "source": [
    "Dalsi priklad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcd66c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:31.775784Z",
     "start_time": "2024-09-22T20:02:31.773830Z"
    }
   },
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f280e196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:34.225727Z",
     "start_time": "2024-09-22T20:02:34.224076Z"
    }
   },
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f98bc85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:51.680230Z",
     "start_time": "2024-09-22T20:02:51.678046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "639226ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:02:55.265201Z",
     "start_time": "2024-09-22T20:02:54.033462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy, esteemed customer! I be regretful to inform ye that the warranty be not coverin' the expenses for cleanin' yer galley, as it appears ye may have misused yer blender by forgettin' to secure the lid afore settin' it to whirl. Aye, 'tis a bit of tough luck, indeed! Fair winds to ye, and may we cross paths again!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat.invoke(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499ff42-49f0-4f3c-b0e6-11e09215cdff",
   "metadata": {},
   "source": [
    "ƒålovƒõka by napadlo, ≈æe se text bez ztr√°ty informac√≠ do jedn√© vƒõty mo≈æn√° shrnout ned√° a n√≠zk√° teplota zabra≈àuje kreativnƒõj≈°√≠ pr√°ci s informacemi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a7f8b43-889c-480d-b36d-14664ec8606c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:03:26.497128Z",
     "start_time": "2024-09-22T20:03:25.469062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eurasian squirrel typically measures 19 to 23 cm in length, weighs between 250 and 340 g, and is characterized by its bushy tail, ear tufts, and sharp curved claws for climbing.\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.7, \n",
    "    model_name=llm_model_name\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2210f-d44d-4277-8fd4-83bc67e32dd6",
   "metadata": {},
   "source": [
    "Nicm√©nƒõ mo≈æn√° si model zkr√°tka co se instrukc√≠ t√Ωƒçe jenom nerozum√≠ s ƒçe≈°tinou tak dob≈ôe jako s angliƒçtinou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95b4ff0e-6ebd-4891-9da2-4878126475fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:03:45.417133Z",
     "start_time": "2024-09-22T20:03:44.041319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veverka obecn√° dor≈Øst√° d√©lky 19 a≈æ 23 cm, v√°≈æ√≠ 250 a≈æ 340 g, m√° hu≈àat√Ω ocas dlouh√Ω 14,5 a≈æ 20 cm a charakteristick√© st≈ôapce na u≈°√≠ch, p≈ôiƒçem≈æ jej√≠ ostr√© dr√°py j√≠ usnad≈àuj√≠ lezen√≠ po stromech.\n"
     ]
    }
   ],
   "source": [
    "template_text = \"\"\"\n",
    "Summarize the text surrounded by three quotation marks in one sentence. The answer must be written in {language} language. \n",
    "Text: '''{text}'''\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_text)\n",
    "language = \"czech\"\n",
    "\n",
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    text=squirrel_text\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model_name=llm_model_name\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11a4d7-4275-43b9-8019-96a4fba3142b",
   "metadata": {},
   "source": [
    "Mo≈æn√° se n√°m nƒõkdy stane, ≈æe bude odpovƒõƒè useknut√°. To nejsp√≠≈° bude d√°no skuteƒçnost√≠, ≈æe defaultn√≠ hodnota parametru *max_tokens* pro *ChatOpenAI*, kter√° m√° velikost 256, na celou odpovƒõƒè zkr√°tka nestaƒç√≠. Pokud nechceme b√Ωt omezov√°ni (resp. pokud chceme b√Ωt omezeni jen maxim√°ln√≠ velikost√≠ kontextov√©ho okna), vlo≈æ√≠me do parametru -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed485a07-ae8a-42cb-9395-e41d0567806a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:35:22.221405Z",
     "start_time": "2024-09-22T20:35:21.222518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veverka obecn√° dor≈Øst√° d√©lky 19 a≈æ 23 cm, v√°≈æ√≠ 250 a≈æ\n"
     ]
    }
   ],
   "source": [
    "template_text = \"\"\"\n",
    "Summarize the text surrounded by three quotation marks in one sentence. The answer must be written in {language} language. \n",
    "Text: '''{text}'''\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_text)\n",
    "language = \"czech\"\n",
    "\n",
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    text=squirrel_text\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model_name=llm_model_name,\n",
    "    max_tokens=22\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51d8f6",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a399bc41-54db-44a3-b20d-8f3d17f20bcc",
   "metadata": {},
   "source": [
    "Zkusme nyn√≠ lehce komplikovanƒõj≈°√≠ ≈°ablonu, kter√° se bude koukat na [popis hry Na k≈ô√≠dlech](https://www.tlamagames.com/deskove-hry/wingspan/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75715ffa-6a2f-49ab-bf9b-d667a2d82966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:35:53.507452Z",
     "start_time": "2024-09-22T20:35:52.621896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"minimalni_vek\": 14,\n",
      "  \"pocet_hracu\": \"1-5\",\n",
      "  \"podminka_vitezstvi\": \"nejv√≠ce bod≈Ø po 4 kolech\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "wingspan_text = \"\"\"\n",
    "Wingspan je kompetitivn√≠ st≈ôednƒõ tƒõ≈æk√° hra vyu≈æ√≠vaj√≠c√≠ karty a engine building mechanismus.\n",
    "\n",
    "St√°v√°te se nad≈°en√Ωmi ornitology a sbƒõrateli a sna≈æ√≠te se objevit a p≈ôil√°kat ty nejzaj√≠mavƒõj≈°√≠ pt√°ky da Va≈°√≠ s√≠tƒõ rezervac√≠. Ka≈æd√Ω pt√°k posiluje ≈ôetƒõz kombinac√≠ pro dan√Ω habitat (akci). Tyto habitaty jsou zamƒõ≈ôeny na nƒõkolik kl√≠ƒçov√Ωch oblast√≠ rozvoje:\n",
    "\n",
    "    Dostat ≈æetony j√≠dla v√Ωbƒõrem kostky z krm√≠tka (dice tower)\n",
    "    Kladen√≠ vajec s vyu≈æit√≠m miniaturn√≠ch vajec v r≈Øzn√Ωch barv√°ch\n",
    "    Dobr√°n√≠ ze stovek unik√°tn√≠ch karet pt√°k≈Ø a zahr√°n√≠ tƒõchto karet\n",
    "\n",
    "V√≠tƒõzem je ten hr√°ƒç, kter√Ω m√° po 4 kolech nejv√≠ce bod≈Ø.\n",
    "\n",
    "Pokud m√°te r√°di hry jako Terraforming Mars a Gizmos, tak by tahle hra mƒõla zal√©tnout na V√°≈° st≈Øl.\n",
    "\n",
    "Hra je urƒçena pro 1-5 hr√°ƒç≈Ø od 14 let.\n",
    "\n",
    "Pravidla i hern√≠ materi√°l je v angliƒçtinƒõ.\n",
    "\"\"\"\n",
    "\n",
    "template_text = \"\"\"\n",
    "From text surrounded by by three quotation marks extract following information.\n",
    "\n",
    "1) Minimal age\n",
    "2) Number of players\n",
    "3) Victory condition\n",
    "\n",
    "The answer must be written in {language} language in {format} format. \n",
    "\n",
    "Text: '''{text}'''\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_text)\n",
    "language = \"czech\"\n",
    "format = \"json\"\n",
    "\n",
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    format=format,\n",
    "    text=wingspan_text\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model_name=llm_model_name\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20f0a950-ab0f-429d-be0f-328a59743f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:36:52.201023Z",
     "start_time": "2024-09-22T20:36:51.082197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Minimal age: 14  \n",
      "2) Number of players: 1-5  \n",
      "3) Victory condition: The player with the most points after 4 rounds wins.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(template_text)\n",
    "language = \"english\"\n",
    "format = \"plain text\"\n",
    "\n",
    "filled_template = prompt_template.format_messages(\n",
    "    language=language,\n",
    "    format=format,\n",
    "    text=wingspan_text\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.0, \n",
    "    model_name=llm_model_name\n",
    ")\n",
    "summary_response = chat.invoke(filled_template)\n",
    "print(summary_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd17bb-7854-4268-a6e8-6e59fccbd576",
   "metadata": {},
   "source": [
    "V p≈ô√≠padƒõ pr√°ce s Azure OpenAI budeme nam√≠sto *ChatOpenAI* pou≈æ√≠vat *AzureChatOpenAI*. Rozd√≠l je i v parametrech - nebudeme specifikovat *model_name*, n√Ωbr≈æ *deployment_name*. V Azuru se toti≈æ vytv√°≈ô√≠ sv√©ho druhu instance model≈Ø mimo (obvykle) v GUI, p≈ôiƒçem≈æ jsou pojmenov√°ny pr√°vƒõ jako deploymenty.  Vytvo≈ôen√© deploymenty ƒçlovƒõk nalezne v Azure AI studiu v sekci \"deployments\" (do konstruktoru d√°v√°me n√°zev z prvn√≠ho sloupce tabulky).\n",
    "\n",
    "```python\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"api_kl√≠ƒç\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"endpoint ve form√°tu ala http://testingazureopenai.openai.azure.com\"\n",
    "chat = AzureChatOpenAI(deployment_name=\"jmeno_deploymentu\", temperature=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba1771",
   "metadata": {},
   "source": [
    "Jiny priklad, jak definovat vystup z LLM modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2c0edff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:37:04.032941Z",
     "start_time": "2024-09-22T20:37:04.029892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f96c43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:37:11.570648Z",
     "start_time": "2024-09-22T20:37:11.568337Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec298d21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:37:31.724255Z",
     "start_time": "2024-09-22T20:37:31.721481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17c52c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:42:43.807600Z",
     "start_time": "2024-09-22T20:42:42.712503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\", \"I think it's worth it for the extra features\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model_name)\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "795c6da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:38:54.364559Z",
     "start_time": "2024-09-22T20:38:54.361577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea50fa0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# You will get an error by running this line of code \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# because'gift' is not a dictionary\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 'gift' is a string\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28b41a",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3d628f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:08.247899Z",
     "start_time": "2024-09-22T20:40:08.246087Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "271adbe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:09.923708Z",
     "start_time": "2024-09-22T20:40:09.915957Z"
    }
   },
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9ad5767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:40.359383Z",
     "start_time": "2024-09-22T20:40:40.356895Z"
    }
   },
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c47b8bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:41.886667Z",
     "start_time": "2024-09-22T20:40:41.884684Z"
    }
   },
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2e1e850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:40:43.425820Z",
     "start_time": "2024-09-22T20:40:43.423126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b263ea71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:41:09.064903Z",
     "start_time": "2024-09-22T20:41:09.062369Z"
    }
   },
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a8d66c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:41:12.330332Z",
     "start_time": "2024-09-22T20:41:12.328341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa7375bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:12.269579Z",
     "start_time": "2024-09-22T20:43:11.148181Z"
    }
   },
   "outputs": [],
   "source": [
    "response = chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dcaa5b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:16.025257Z",
     "start_time": "2024-09-22T20:43:16.022963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": \"True\",\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f53b8ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:20.907758Z",
     "start_time": "2024-09-22T20:43:20.904781Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36707c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:21.841755Z",
     "start_time": "2024-09-22T20:43:21.839194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': 'True',\n",
       " 'delivery_days': '2',\n",
       " 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "606ff72b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:22.381465Z",
     "start_time": "2024-09-22T20:43:22.379011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52c8d9e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:43:22.818522Z",
     "start_time": "2024-09-22T20:43:22.815554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530d7fe1-aac0-4863-beeb-7e33e91bb277",
   "metadata": {},
   "source": [
    "## Chains\n",
    "Je naƒçase p≈ôistoupit k vƒõci, podle kter√© nese Langchain sv√© jm√©no - k chain≈Øm. Ty jsou [definov√°ny](https://python.langchain.com/docs/modules/chains/) jako posloupnosti vol√°n√≠ komponent, kter√© mohou obsahovat dal≈°√≠ chainy. To by ve v√Ωsledku mƒõlo v√©st k vƒõt≈°√≠ p≈ôehlednosti a snaz≈°√≠ udr≈æov√°n√≠ k√≥du.\n",
    "#### LLMChain \n",
    "Viz. [LLMChain](https://python.langchain.com/docs/modules/chains/foundational/llm_chain)\n",
    "Jedn√° se o asi nejjednodu≈°≈°√≠ chain. ƒålovƒõk do nƒõj p≈ôi inicializaci nasype template a jazykov√Ω model. P≈ôi samotn√©m pou≈æit√≠ *LLMChain* provol√°me s hodnotou promƒõnn√©, kter√° se dosad√≠ do ≈°ablony. V√Ωsledn√Ω textov√Ω ≈ôetƒõzec poputuje do jazykov√©ho modelu a n√°slednƒõ obdr≈æ√≠me v√Ωsledek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1bedc7db58b4d7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:51:29.263238Z",
     "start_time": "2024-09-22T20:51:29.244431Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.95, model=llm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "565c7f63a6b559f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:51:30.514842Z",
     "start_time": "2024-09-22T20:51:30.512810Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "246c00ba72989906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:51:31.188104Z",
     "start_time": "2024-09-22T20:51:31.186062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/4149722537.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f30020986f1bc6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:51:33.761988Z",
     "start_time": "2024-09-22T20:51:32.281606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Queen Size Sheet Set',\n",
       " 'text': \"Choosing a name for a company that specializes in queen size sheet sets can convey quality, comfort, and style. Here are some suggestions that reflect those attributes:\\n\\n1. **Queen's Rest Sheets**\\n2. **Majestic Slumber**\\n3. **Regal Comfort Linens**\\n4. **Purely Queen**\\n5. **Dreamy Queen Sheets**\\n6. **Sovereign Sheets**\\n7. **Royal Sleep Sets**\\n8. **Queen Size Haven**\\n9. **Crown Comfort Linens**\\n10. **Elite Queen Sheets**\\n\\nConsider your target audience and brand values when selecting a name, and make sure to check for domain availability if you plan to create a website.\"}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "llm_chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0852cc-8d27-42c0-ac65-70618f0f8318",
   "metadata": {},
   "source": [
    "Obvykle ale nechceme slovn√≠kovou om√°ƒçku okolo, ale jen samotnou odpovƒõƒè. Kdysi bylo ≈ôe≈°en√≠m pou≈æ√≠t metodu *run*. Ta ale brzo bude odstranƒõna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e416d9d-89cd-43af-8b7a-72638f79d8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:52:12.080415Z",
     "start_time": "2024-09-22T20:52:10.773033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/1011596546.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm_chain.run(product)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Choosing a name for a company that makes queen-size sheet sets can depend on your brand's identity, target audience, and overall message. Here are some suggestions that convey comfort, quality, and style:\\n\\n1. **Queen's Comfort**\\n2. **Majestic Sheets**\\n3. **Royal Rest Linens**\\n4. **Serene Sleep Sheets**\\n5. **Queen's Touch Textiles**\\n6. **Dreamy Duvet Designs**\\n7. **Soft Serenity Sheets**\\n8. **Regal Rest Bedding**\\n9. **Luxury Queen Linens**\\n10. **Restful Nights Sheets**\\n\\nConsiderations like availability of the domain name, any existing trademarks, and the specific image you want to project could help you narrow down your choices.\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "llm_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6aa76f-4912-4912-815a-6fd39fcedee6",
   "metadata": {},
   "source": [
    "Tud√≠≈æ mus√≠me explicitnƒõ \"slovn√≠kovƒõ\" zm√≠nit, co vlastnƒõ chceme vidƒõt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1ffc2bbb-49cc-456a-89ad-85723bdb4848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T20:52:47.595952Z",
     "start_time": "2024-09-22T20:52:46.064680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are some ideas for a company that specializes in queen-size sheet sets:\\n\\n1. **Queen's Comfort**\\n2. **Royal Sheets**\\n3. **Regal Rest**\\n4. **Queen's Haven**\\n5. **Majestic Linens**\\n6. **Serene Sleep**\\n7. **Lavish Layers**\\n8. **Dreamy Queen**\\n9. **Plush Queen**\\n10. **Comfort Cove**\\n\\nConsider what resonates with your target audience while reflecting the quality and comfort of the products you offer.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "llm_chain.invoke(product)[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891a943-ad6e-4ce3-8c3a-1ba79ba655de",
   "metadata": {},
   "source": [
    "V p≈ô√≠padƒõ, ≈æe m√° j√≠t do ≈°ablony v√≠ce promƒõnn√Ωch, mus√≠me tyto promƒõnn√© do metody *invoke* p≈ôed√°vat jako slovn√≠k v parametru *input*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "576ae240-e315-4598-a8a7-3ff207879ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:00:33.016623Z",
     "start_time": "2024-09-22T21:00:33.011789Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_two_var = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Write the best name for {pet}. Answer should be in one sentence, in {language} language, but should contain reasoning.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19bf26fdb72f75a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:00:36.228370Z",
     "start_time": "2024-09-22T21:00:36.225756Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_chain_two_var = LLMChain(llm=llm, prompt=prompt_template_two_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc6ccaec7fa236bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:00:38.914068Z",
     "start_time": "2024-09-22T21:00:38.050699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pet': 'cat',\n",
       " 'language': 'german',\n",
       " 'text': 'Ein herausragender Name f√ºr eine Katze ist \"Schnurri\", da er die verspielte und zugleich gem√ºtliche Natur dieser Tiere perfekt einf√§ngt.'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vars = {\"pet\": \"cat\", \"language\": \"german\"}\n",
    "llm_chain_two_var.invoke(input=input_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ce79d-75f5-433b-9c60-7ccb8b3ff790",
   "metadata": {},
   "source": [
    "Pokud ƒçlovƒõk chce odpovƒõdi na v√≠ce separ√°tn√≠ch vstup≈Ø, nen√≠ t≈ôeba popo≈ôadƒõ manu√°lnƒõ provol√°vat model, ale lze pou≈æ√≠t metodu *apply*. T√© se podhod√≠ list slovn√≠k≈Ø s promƒõnn√Ωmi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb81771cd5b6aee",
   "metadata": {},
   "source": [
    "Vzhledem k rychlosti vyvoje LangChainu, je nasledujici metoda uz nefunkcni. Nevim proc, proste uz nefunguje. A kdyz \n",
    "clovek googl√≠, tak na strance \n",
    "[dokumentace k LLMChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html#langchain.chains.llm.LLMChain) se dozvi, ze LLMChain byl taky deprecated...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74a0d464-9309-4ff6-b130-7ba2d6bb89ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:04:07.069203Z",
     "start_time": "2024-09-22T21:04:06.985734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'The best name for a parrot is \"Echo,\" as it reflects their remarkable ability to mimic sounds and voices, creating a playful and memorable connection with their owner\\'s communication.'},\n",
       " {'text': 'Nejlep≈°√≠ jm√©no pro medvƒõda je \"Bobo\", proto≈æe je hrav√© a zapamatovateln√©, co≈æ odr√°≈æ√≠ jeho p≈ô√°telskou povahu.'},\n",
       " {'text': 'Der beste Name f√ºr einen Affen ist ‚ÄûKleiner Wirbelwind‚Äú, weil er die verspielte und energetische Natur dieser Tiere perfekt einf√§ngt.'}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"pet\": \"parrot\", \"language\":\"english\"},\n",
    "    {\"pet\": \"bear\", \"language\":\"czech\"},\n",
    "    {\"pet\": \"monkey\", \"language\":\"german\"}\n",
    "]\n",
    "\n",
    "llm_chain_two_var.apply(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5076b4-e0ba-4861-b51f-03cdcceeb4b8",
   "metadata": {},
   "source": [
    "#### Sekvenƒçn√≠ chainy\n",
    "Viz [Sekvenƒçn√≠ chainy](https://python.langchain.com/docs/modules/chains/foundational/sequential_chains).\n",
    "Sekvenƒçn√≠ chainy jsou urƒçeny pro situace, kdy v√Ωstup jednoho provol√°n√≠ modelu vkl√°d√°me jako vstup do provol√°n√≠ druh√©ho. Existuj√≠ ve dvou variant√°ch:\n",
    "- SimpleSequentialChain, kter√Ω m√° jen jeden vstup a jeden v√Ωstup\n",
    "- SequentialChain umo≈æ≈àuj√≠c√≠ existenci v√≠ce vstup≈Ø a v√Ωstup≈Ø\n",
    "\n",
    "Pro uk√°zku SimpleSequentialChain si nap≈ôed vytvo≈ô√≠me dva LLMChainy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef45a7e8-928d-4aab-b96a-1c26fd1c6c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:08.506948Z",
     "start_time": "2024-09-22T21:17:08.488861Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.95, model=llm_model_name)\n",
    "\n",
    "prompt_template_post = ChatPromptTemplate.from_template(\n",
    "    \"Write a LinkedIn post for company {company}.\"\n",
    ")\n",
    "\n",
    "post_chain = LLMChain(llm=chat, prompt=prompt_template_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99661f46-b4c9-4a23-b8e4-fe5dd62b506c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:08.895074Z",
     "start_time": "2024-09-22T21:17:08.893032Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_summary = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Summarize the text surrounded by three quotation marks in one sentence.\n",
    "    Text: '''{text}''''\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "summary_chain = LLMChain(llm=chat, prompt=prompt_template_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b8f8d6-798d-460c-960b-612e8f96d6c9",
   "metadata": {},
   "source": [
    "N√°slednƒõ s jejich pomoc√≠ vytvo≈ô√≠me SimpleSequentialChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "168a9c7a-a259-4dc1-9d40-3fbd42c43ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:13.758189Z",
     "start_time": "2024-09-22T21:17:13.756016Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[post_chain, summary_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb6010-d00b-4b5d-86f8-6aea084e2fe0",
   "metadata": {},
   "source": [
    "Ten uvedeme do provozu provol√°n√≠m metody *invoke*. Do t√© vlo≈æ√≠me hodnotu, kter√° bude dosazena do prvn√≠ho LLMChainu (po≈ôad√≠ chain≈Ø d√°no po≈ôad√≠m v listu vkl√°dan√©ho do parametru *chains*).  \n",
    "Jeliko≈æ jsme *SimpleSequentialChain* vytvo≈ôili s parametrem *verbose*=True, vid√≠me i meziv√Ωsledky - v√Ωstup prvn√≠ho a druh√©ho LLMChainu v modr√© resp. ≈ælut√© barvƒõ. A ano, jsou zde warningy. Asi se jedn√° o nƒõjak√© vol√°n√≠ v pozad√≠; zat√≠m jsem nep≈ôi≈°el na to, co m√°m ƒç√≠m nahradit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "773304e6-0b89-45ff-b8b1-7f70f7913592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:19.762144Z",
     "start_time": "2024-09-22T21:17:16.322865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3müåü Exciting Times at Hamster Food Inc.! üåü\n",
      "\n",
      "We're thrilled to announce some incredible updates from our team dedicated to creating the finest, healthiest, and tastiest options for our furry friends! üêπ‚ú®\n",
      "\n",
      "At Hamster Food Inc., we believe that every pet deserves the best nutrition possible. That's why we've been hard at work developing new formulas packed with essential nutrients that support the health and happiness of hamsters of all breeds. From high-quality grains to fresh fruits and veggies, our products are designed to mimic a hamster‚Äôs natural diet while ensuring they get the energy they need to play and thrive.\n",
      "\n",
      "We can't wait to share more about our upcoming product launches, sustainability initiatives, and partnerships with pet organizations that align with our mission of promoting responsible pet care.\n",
      "\n",
      "A huge thank you to our dedicated team, our loyal customers, and our adorable little pals for inspiring us every day! ü•≥\n",
      "\n",
      "Stay tuned for more updates and let‚Äôs keep making the world a better place for our pets‚Äîone tasty bite at a time! üçΩÔ∏èüíö\n",
      "\n",
      "#HamsterFoodInc #PetNutrition #HappyPets #SustainablePetCare #InnovationInPetFood #FurryFriends\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mHamster Food Inc. is excited to announce new, nutritious product updates aimed at improving the health and happiness of hamsters, while also emphasizing sustainability and responsible pet care.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "post_summary = overall_chain.invoke(\"Hamster food Inc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28539572-1485-4766-a8a0-561da430286c",
   "metadata": {},
   "source": [
    "V√Ωsledek jsme si ulo≈æili do promƒõnn√© *post_summary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b3fa8b01-4550-4703-b080-b02172f6ea2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:23.897856Z",
     "start_time": "2024-09-22T21:17:23.895292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hamster food Inc.',\n",
       " 'output': 'Hamster Food Inc. is excited to announce new, nutritious product updates aimed at improving the health and happiness of hamsters, while also emphasizing sustainability and responsible pet care.'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce02a8-202b-4b59-a8df-7e27797a53fe",
   "metadata": {},
   "source": [
    "S *verbose*=False ≈æ√°dn√© barevn√© v√Ωsledky neuvid√≠me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1b20d7f-1730-44b3-baac-f225716fb796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:29.084160Z",
     "start_time": "2024-09-22T21:17:25.995994Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[post_chain, summary_chain], verbose=False)\n",
    "post_summary = overall_chain.invoke(\"Hamster food Inc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94a4ea36-a96b-4b49-a89f-8eab00df43d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:17:29.159895Z",
     "start_time": "2024-09-22T21:17:29.157319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hamster food Inc.',\n",
       " 'output': 'Hamster Food Inc. has launched a new line of premium, all-natural hamster food made with healthy ingredients to promote the wellbeing of hamsters.'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720438d-e6b6-49b4-a1f0-80b3101edaba",
   "metadata": {},
   "source": [
    "Nyn√≠ se pod√≠vejme na *SequentialChain*. Zde prvn√≠ LLMChain bude m√≠t dva vstupy. Nav√≠c tu v parametru *output_key* ≈ô√≠k√°me, do jak pojmenovan√© promƒõnn√© zpracovan√© dal≈°√≠mi LLMChainy se m√° v√Ωstup tohoto chainu ulo≈æit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "db3cd209-f82b-41d0-a576-139bade3c728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:18:34.592177Z",
     "start_time": "2024-09-22T21:18:34.577937Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.95, model=llm_model_name)\n",
    "\n",
    "prompt_template_post = ChatPromptTemplate.from_template(\n",
    "    \"Write a LinkedIn post for company {company} with length of {sentences_count} sentences.\"\n",
    ")\n",
    "\n",
    "post_chain = LLMChain(llm=chat, prompt=prompt_template_post, output_key=\"linkendin_post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e026ead-6c99-4c00-be14-35a0cad3b3dc",
   "metadata": {},
   "source": [
    "Dva vstupy a jeden *output_key* m√° i druh√Ω *LLMChain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aaf3aa57-2e0b-4d80-a525-4abefb236af5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:19:02.347188Z",
     "start_time": "2024-09-22T21:19:02.344248Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template_summary = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Summarize the text surrounded by three quotation marks in one sentence. Use {language} language.\n",
    "    Text: '''{linkendin_post}''''\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "summary_chain = LLMChain(llm=chat, prompt=prompt_template_summary, output_key=\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c3b22-6581-47ea-a086-e9fe6d3c5267",
   "metadata": {},
   "source": [
    "Nyn√≠ si vytvo≈ô√≠me *SequentialChain*. Oproti *SimpleSequentialChain* tu nav√≠c m√°me parametry *input_variables* a *output_variables*. V≈°imnƒõme si, ≈æe i kdy≈æ se promƒõnn√° *language* pou≈æ√≠v√° a≈æ v druh√©m LLMChainu, je v *input_variables*. Prvn√≠ LLMChain ji prostƒõ ignoruje.  \n",
    "V SequentialChainu bychom mohli m√≠t v√≠ce chain≈Ø a ty by ani nemusely m√≠t uspo≈ô√°d√°ny ƒçistƒõ s√©riovƒõ. Langchain u≈æ by si je postupnƒõ pospou≈°tƒõl podle pot≈ôebn√Ωch input a output promƒõnn√Ωch. Dokonce ani konec nemus√≠ b√Ωt v jednom chainu - zakonƒçen√≠ m≈Ø≈æe b√Ωt v√≠ce a pak je output_key ka≈æd√©ho koncov√©ho chainu um√≠stƒõn do listu v *output_variables*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f39688af-ed80-438c-bcac-2f6a36785551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:23:57.308281Z",
     "start_time": "2024-09-22T21:23:57.305889Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[post_chain, summary_chain],\n",
    "    input_variables=[\"company\", \"sentences_count\", \"language\"],\n",
    "    output_variables=[\"summarization\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c26168-ee50-48e2-ac37-961384329a6b",
   "metadata": {},
   "source": [
    "Aktivovat *SequentialChain* m≈Ø≈æeme vlo≈æen√≠m slovn√≠ku se z√°znamem pro ka≈ædou *input_variable* do instance chainu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2deee5c-cbb1-4640-bf69-9780abddff15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:24:08.263765Z",
     "start_time": "2024-09-22T21:24:06.202376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'language': 'czech',\n",
       " 'sentences_count': 3,\n",
       " 'company': 'Turtles speedtravel',\n",
       " 'summarization': 'Turtles SpeedTravel p≈ôin√°≈°√≠ nov√© inovativn√≠ ≈ôe≈°en√≠ pro rychl√© a pohodln√© cestov√°n√≠, kter√° umo≈æn√≠ objevovat nov√© obzory.'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain.invoke({\"language\":\"czech\", \"sentences_count\":3, \"company\":\"Turtles speedtravel\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3d0dd-989a-4e8c-bb29-9fa6fd61bd77",
   "metadata": {},
   "source": [
    "V≈°imnƒõme si ale, ≈æe i kdy≈æ jsme nastavili *verbose*=True, nevid√≠me meziv√Ωsledky. Netu≈°√≠me tak, co se vlastnƒõ uvnit≈ô dƒõje. Kdy≈æ ale nastav√≠me langchain do debug modu s pomoc√≠ *langchain.debug* = True, uvid√≠me v≈°e do nejmen≈°√≠ch podrobnost√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74a7689e-5e08-4806-aa82-78c5b903034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "68be20b2-4368-40ee-a74f-981e3e80d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SequentialChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"language\": \"czech\",\n",
      "  \"sentences_count\": 3,\n",
      "  \"company\": \"Turtles speedtravel\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"language\": \"czech\",\n",
      "  \"sentences_count\": 3,\n",
      "  \"company\": \"Turtles speedtravel\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Write a LinkedIn post for company Turtles speedtravel with length of 3 sentences.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] [2.51s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"üåç Exciting times at Turtles Speedtravel! We‚Äôre thrilled to announce our latest innovative travel solutions designed to make your journey seamless and unforgettable. Join us as we redefine the travel experience, making exploration faster and more enjoyable than ever before! ‚úàÔ∏è #TravelInnovation #TurtlesSpeedtravel #ExploreMore\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"üåç Exciting times at Turtles Speedtravel! We‚Äôre thrilled to announce our latest innovative travel solutions designed to make your journey seamless and unforgettable. Join us as we redefine the travel experience, making exploration faster and more enjoyable than ever before! ‚úàÔ∏è #TravelInnovation #TurtlesSpeedtravel #ExploreMore\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 64,\n",
      "                \"prompt_tokens\": 25,\n",
      "                \"total_tokens\": 89,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_72ed7ab54c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-514767dc-c68b-4cd5-8f22-dd44a5a29edd-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 25,\n",
      "              \"output_tokens\": 64,\n",
      "              \"total_tokens\": 89\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 64,\n",
      "      \"prompt_tokens\": 25,\n",
      "      \"total_tokens\": 89,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_72ed7ab54c\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] [2.51s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"linkendin_post\": \"üåç Exciting times at Turtles Speedtravel! We‚Äôre thrilled to announce our latest innovative travel solutions designed to make your journey seamless and unforgettable. Join us as we redefine the travel experience, making exploration faster and more enjoyable than ever before! ‚úàÔ∏è #TravelInnovation #TurtlesSpeedtravel #ExploreMore\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"language\": \"czech\",\n",
      "  \"sentences_count\": 3,\n",
      "  \"company\": \"Turtles speedtravel\",\n",
      "  \"linkendin_post\": \"üåç Exciting times at Turtles Speedtravel! We‚Äôre thrilled to announce our latest innovative travel solutions designed to make your journey seamless and unforgettable. Join us as we redefine the travel experience, making exploration faster and more enjoyable than ever before! ‚úàÔ∏è #TravelInnovation #TurtlesSpeedtravel #ExploreMore\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\n    Summarize the text surrounded by three quotation marks in one sentence. Use czech language.\\n    Text: '''üåç Exciting times at Turtles Speedtravel! We‚Äôre thrilled to announce our latest innovative travel solutions designed to make your journey seamless and unforgettable. Join us as we redefine the travel experience, making exploration faster and more enjoyable than ever before! ‚úàÔ∏è #TravelInnovation #TurtlesSpeedtravel #ExploreMore''''\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] [945ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Turtles Speedtravel p≈ôedstavuje inovativn√≠ cestovn√≠ ≈ôe≈°en√≠, kter√° maj√≠ za c√≠l uƒçinit va≈°e cesty rychlej≈°√≠mi a nezapomenutelnƒõj≈°√≠mi.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Turtles Speedtravel p≈ôedstavuje inovativn√≠ cestovn√≠ ≈ôe≈°en√≠, kter√° maj√≠ za c√≠l uƒçinit va≈°e cesty rychlej≈°√≠mi a nezapomenutelnƒõj≈°√≠mi.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 38,\n",
      "                \"prompt_tokens\": 98,\n",
      "                \"total_tokens\": 136,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_72ed7ab54c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c67870ef-203e-4871-a3e3-b9df900e2487-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 98,\n",
      "              \"output_tokens\": 38,\n",
      "              \"total_tokens\": 136\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 38,\n",
      "      \"prompt_tokens\": 98,\n",
      "      \"total_tokens\": 136,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_72ed7ab54c\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] [946ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"summarization\": \"Turtles Speedtravel p≈ôedstavuje inovativn√≠ cestovn√≠ ≈ôe≈°en√≠, kter√° maj√≠ za c√≠l uƒçinit va≈°e cesty rychlej≈°√≠mi a nezapomenutelnƒõj≈°√≠mi.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SequentialChain] [3.46s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"summarization\": \"Turtles Speedtravel p≈ôedstavuje inovativn√≠ cestovn√≠ ≈ôe≈°en√≠, kter√° maj√≠ za c√≠l uƒçinit va≈°e cesty rychlej≈°√≠mi a nezapomenutelnƒõj≈°√≠mi.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'language': 'czech',\n",
       " 'sentences_count': 3,\n",
       " 'company': 'Turtles speedtravel',\n",
       " 'summarization': 'Turtles Speedtravel p≈ôedstavuje inovativn√≠ cestovn√≠ ≈ôe≈°en√≠, kter√° maj√≠ za c√≠l uƒçinit va≈°e cesty rychlej≈°√≠mi a nezapomenutelnƒõj≈°√≠mi.'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain.invoke({\"language\":\"czech\", \"sentences_count\":3, \"company\":\"Turtles speedtravel\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549bd846",
   "metadata": {},
   "source": [
    "Jiny priklad s vice prompty a vice output_variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40956c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:24:47.776497Z",
     "start_time": "2024-09-22T21:24:47.761100Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model_name)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5bfba736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:24:53.928342Z",
     "start_time": "2024-09-22T21:24:53.926102Z"
    }
   },
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d0d3832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:25:00.288675Z",
     "start_time": "2024-09-22T21:25:00.285407Z"
    }
   },
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e11f62b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:25:05.063576Z",
     "start_time": "2024-09-22T21:25:05.060803Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "021f98d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:25:09.673208Z",
     "start_time": "2024-09-22T21:25:09.670297Z"
    }
   },
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "646cf406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:32:10.174116Z",
     "start_time": "2024-09-22T21:32:06.387335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SequentialChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"Review\": \"Jidlo nebylo spatny, ale zadna slava to taky nebyla\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"Review\": \"Jidlo nebylo spatny, ale zadna slava to taky nebyla\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Translate the following review to english:\\n\\nJidlo nebylo spatny, ale zadna slava to taky nebyla\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/114229642.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_chain(review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] [727ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The food wasn't bad, but it wasn't anything special either.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The food wasn't bad, but it wasn't anything special either.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 13,\n",
      "                \"prompt_tokens\": 31,\n",
      "                \"total_tokens\": 44,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_bd83329f63\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-cf144d4f-2968-4864-928b-bed5a0ab5a2d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 31,\n",
      "              \"output_tokens\": 13,\n",
      "              \"total_tokens\": 44\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 13,\n",
      "      \"prompt_tokens\": 31,\n",
      "      \"total_tokens\": 44,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_bd83329f63\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] [728ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"English_Review\": \"The food wasn't bad, but it wasn't anything special either.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"Review\": \"Jidlo nebylo spatny, ale zadna slava to taky nebyla\",\n",
      "  \"English_Review\": \"The food wasn't bad, but it wasn't anything special either.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Can you summarize the following review in 1 sentence:\\n\\nThe food wasn't bad, but it wasn't anything special either.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] [545ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The food was mediocre, lacking any standout qualities.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The food was mediocre, lacking any standout qualities.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 11,\n",
      "                \"prompt_tokens\": 30,\n",
      "                \"total_tokens\": 41,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_72ed7ab54c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ad92f2c5-c259-4c12-a5c7-9c38d0f6a929-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 30,\n",
      "              \"output_tokens\": 11,\n",
      "              \"total_tokens\": 41\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 11,\n",
      "      \"prompt_tokens\": 30,\n",
      "      \"total_tokens\": 41,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_72ed7ab54c\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] [546ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"summary\": \"The food was mediocre, lacking any standout qualities.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"Review\": \"Jidlo nebylo spatny, ale zadna slava to taky nebyla\",\n",
      "  \"English_Review\": \"The food wasn't bad, but it wasn't anything special either.\",\n",
      "  \"summary\": \"The food was mediocre, lacking any standout qualities.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What language is the following review:\\n\\nJidlo nebylo spatny, ale zadna slava to taky nebyla\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] [625ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The review is in Czech. It translates to: \\\"The food wasn't bad, but it wasn't anything special either.\\\"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The review is in Czech. It translates to: \\\"The food wasn't bad, but it wasn't anything special either.\\\"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 24,\n",
      "                \"prompt_tokens\": 31,\n",
      "                \"total_tokens\": 55,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_72ed7ab54c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-aea89de7-81f6-4f5a-8064-0eb5c2ebd81d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 31,\n",
      "              \"output_tokens\": 24,\n",
      "              \"total_tokens\": 55\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 24,\n",
      "      \"prompt_tokens\": 31,\n",
      "      \"total_tokens\": 55,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_72ed7ab54c\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] [626ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"language\": \"The review is in Czech. It translates to: \\\"The food wasn't bad, but it wasn't anything special either.\\\"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"Review\": \"Jidlo nebylo spatny, ale zadna slava to taky nebyla\",\n",
      "  \"English_Review\": \"The food wasn't bad, but it wasn't anything special either.\",\n",
      "  \"summary\": \"The food was mediocre, lacking any standout qualities.\",\n",
      "  \"language\": \"The review is in Czech. It translates to: \\\"The food wasn't bad, but it wasn't anything special either.\\\"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Write a follow up response to the following summary in the specified language:\\n\\nSummary: The food was mediocre, lacking any standout qualities.\\n\\nLanguage: The review is in Czech. It translates to: \\\"The food wasn't bad, but it wasn't anything special either.\\\"\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain > llm:ChatOpenAI] [1.60s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Dƒõkuji za va≈°i recenzi. I kdy≈æ v√°s j√≠dlo nezaujalo, zaj√≠malo by mƒõ, co konkr√©tnƒõ byste doporuƒçil vylep≈°it. Bylo by skvƒõl√© vƒõdƒõt, jak√© prvky by mohly j√≠dlo posunout na vy≈°≈°√≠ √∫rove≈à a co byste r√°di vidƒõli v√≠ce. Va≈°e n√°zory jsou pro n√°s cenn√©!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Dƒõkuji za va≈°i recenzi. I kdy≈æ v√°s j√≠dlo nezaujalo, zaj√≠malo by mƒõ, co konkr√©tnƒõ byste doporuƒçil vylep≈°it. Bylo by skvƒõl√© vƒõdƒõt, jak√© prvky by mohly j√≠dlo posunout na vy≈°≈°√≠ √∫rove≈à a co byste r√°di vidƒõli v√≠ce. Va≈°e n√°zory jsou pro n√°s cenn√©!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 90,\n",
      "                \"prompt_tokens\": 58,\n",
      "                \"total_tokens\": 148,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_72ed7ab54c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-56f57162-98b7-45de-ae5b-0079c7df6029-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 58,\n",
      "              \"output_tokens\": 90,\n",
      "              \"total_tokens\": 148\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 90,\n",
      "      \"prompt_tokens\": 58,\n",
      "      \"total_tokens\": 148,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_72ed7ab54c\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SequentialChain > chain:LLMChain] [1.60s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"followup_message\": \"Dƒõkuji za va≈°i recenzi. I kdy≈æ v√°s j√≠dlo nezaujalo, zaj√≠malo by mƒõ, co konkr√©tnƒõ byste doporuƒçil vylep≈°it. Bylo by skvƒõl√© vƒõdƒõt, jak√© prvky by mohly j√≠dlo posunout na vy≈°≈°√≠ √∫rove≈à a co byste r√°di vidƒõli v√≠ce. Va≈°e n√°zory jsou pro n√°s cenn√©!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SequentialChain] [3.50s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"English_Review\": \"The food wasn't bad, but it wasn't anything special either.\",\n",
      "  \"summary\": \"The food was mediocre, lacking any standout qualities.\",\n",
      "  \"followup_message\": \"Dƒõkuji za va≈°i recenzi. I kdy≈æ v√°s j√≠dlo nezaujalo, zaj√≠malo by mƒõ, co konkr√©tnƒõ byste doporuƒçil vylep≈°it. Bylo by skvƒõl√© vƒõdƒõt, jak√© prvky by mohly j√≠dlo posunout na vy≈°≈°√≠ √∫rove≈à a co byste r√°di vidƒõli v√≠ce. Va≈°e n√°zory jsou pro n√°s cenn√©!\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': 'Jidlo nebylo spatny, ale zadna slava to taky nebyla',\n",
       " 'English_Review': \"The food wasn't bad, but it wasn't anything special either.\",\n",
       " 'summary': 'The food was mediocre, lacking any standout qualities.',\n",
       " 'followup_message': 'Dƒõkuji za va≈°i recenzi. I kdy≈æ v√°s j√≠dlo nezaujalo, zaj√≠malo by mƒõ, co konkr√©tnƒõ byste doporuƒçil vylep≈°it. Bylo by skvƒõl√© vƒõdƒõt, jak√© prvky by mohly j√≠dlo posunout na vy≈°≈°√≠ √∫rove≈à a co byste r√°di vidƒõli v√≠ce. Va≈°e n√°zory jsou pro n√°s cenn√©!'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Jidlo nebylo spatny, ale zadna slava to taky nebyla\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af783813-1f49-45fc-aa13-33fcc8aa06a6",
   "metadata": {},
   "source": [
    "#### RouterChain\n",
    "RouterChain dok√°≈æe posoudit, na kter√Ω z pod≈ô√≠zen√Ωch chain≈Ø poslat u≈æivatelsk√Ω vstup. Narozd√≠l od sekvenƒç√≠ch chain≈Ø, kde je posloupnost ≈ô√≠zena jm√©nem promƒõnn√Ωch (a tedy volbou program√°tora), v p≈ô√≠padƒõ LLMRouterChain se o rozza≈ôov√°n√≠ skuteƒçnƒõ star√° jazykov√Ω model.  \n",
    "Pozn.: v t√©to podkapitole ƒçerp√°m z langchainov√©ho kurzu z deeplearning.ai opravdu extenzivnƒõ - MULTI_PROMPT_ROUTER_TEMPLATE je p≈ôevzat beze zmƒõn metodou ctrl+C, ctrl+V.  \n",
    "Nejprve si vytvo≈ô√≠me z√°klady ≈°ablon pro programov√°n√≠ a pro va≈ôen√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a5b5ac58-2447-4fe6-89b8-f00ec7c81224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "it_problem_template = \"\"\"You are a very smart programmer. \n",
    "You are great at answering questions about computers, programming and IT in a concise \n",
    "and easy to understand manner. \n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "cooking_template = \"\"\"Your are master chef, expert at cooking and food preparation. \n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "\n",
    "Here is a question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"programming\", \n",
    "        \"description\": \"Good for answering questions about programming and IT\", \n",
    "        \"prompt_template\": it_problem_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"food\", \n",
    "        \"description\": \"Good for answering questions about food and cooking\", \n",
    "        \"prompt_template\": cooking_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea0867f-41c0-4e24-87a1-0123065299c1",
   "metadata": {},
   "source": [
    "N√°slednƒõ dojde k vytvo≈ôen√≠ instance jazykov√©ho modelu a listu slovn√≠ku o podchainech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f91a9c6-9f7c-44c7-84b3-dd3c51fa202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programming: Good for answering questions about programming and IT\n",
      "food: Good for answering questions about food and cooking\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "destination_chains = {}\n",
    "for one_prompt_info in prompt_infos:\n",
    "    name = one_prompt_info[\"name\"]\n",
    "    prompt_template = one_prompt_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=chat, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{one_prompt_info['name']}: {one_prompt_info['description']}\" for one_prompt_info in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4cbff-3de3-4482-b3ac-427de7e3cb88",
   "metadata": {},
   "source": [
    "Vytvo≈ô√≠me si i defaultn√≠ podchain, kam p≈Øjdou u≈æivatelsk√© dotazy, kter√© se nevejdou nikam jinam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6d45ae33-07df-4bd0-8095-e070f8ad8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=chat, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711e81d-f1f8-4ba2-a8f6-ed2afcde68cb",
   "metadata": {},
   "source": [
    "N√°sleduje extenzivn√≠ popis router ≈°ablony."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1445f206-d214-4c09-9857-252dc4f11cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \n",
    "language model select the model prompt best suited for the input. \n",
    "You will be given the names of the available prompts and a \n",
    "description of what the prompt is best suited for. \n",
    "You may also revise the original input if you think that revising\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string - name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string - a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f87b1-98c5-4cfe-948c-69ceb10470a7",
   "metadata": {},
   "source": [
    "A vytvo≈ôen√≠ samotn√©ho routeru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "199f160d-bb5c-4ba9-8bfe-bbda96cec22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(chat, router_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a731d4b6-a561-4bcf-adc6-9df69dbbd3d2",
   "metadata": {},
   "source": [
    "A nakonec tu m√°me chain, kter√Ω *LLMRouterChain* obaluje a spojuje ho s podchainy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1b49296-d632-48c7-896d-0da0b9cad176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/3038952769.py:1: LangChainDeprecationWarning: Use RunnableLambda to select from multiple prompt templates. See example in API reference: https://api.python.langchain.com/en/latest/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed5882-c749-4379-84c6-2554e4a8c1a2",
   "metadata": {},
   "source": [
    "Zde m√°me p≈ô√≠klad program√°torsk√©ho podchainu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3ce9553a-3412-40d0-96e4-0568d3e19d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are good packages for graphs creation in Python?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are good packages for graphs creation in Python?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are good packages for graphs creation in Python?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given a raw text input to a \\nlanguage model select the model prompt best suited for the input. \\nYou will be given the names of the available prompts and a \\ndescription of what the prompt is best suited for. \\nYou may also revise the original input if you think that revising\\nit will ultimately lead to a better response from the language model.\\n\\n<< FORMATTING >>\\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{\\n    \\\"destination\\\": string - name of the prompt to use or \\\"DEFAULT\\\"\\n    \\\"next_inputs\\\": string - a potentially modified version of the original input\\n}\\n```\\n\\nREMEMBER: \\\"destination\\\" MUST be one of the candidate prompt \\nnames specified below OR it can be \\\"DEFAULT\\\" if the input is not\\nwell suited for any of the candidate prompts.\\nREMEMBER: \\\"next_inputs\\\" can just be the original input \\nif you don't think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\nprogramming: Good for answering questions about programming and IT\\nfood: Good for answering questions about food and cooking\\n\\n<< INPUT >>\\nWhat are good packages for graphs creation in Python?\\n\\n<< OUTPUT (remember to include the ```json)>>\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain > llm:ChatOpenAI] [607ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"destination\\\": \\\"programming\\\",\\n    \\\"next_inputs\\\": \\\"What are good packages for graphs creation in Python?\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n    \\\"destination\\\": \\\"programming\\\",\\n    \\\"next_inputs\\\": \\\"What are good packages for graphs creation in Python?\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 30,\n",
      "                \"prompt_tokens\": 258,\n",
      "                \"total_tokens\": 288,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-97f0b8d5-0c0d-4346-90d7-066408c1877d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 258,\n",
      "              \"output_tokens\": 30,\n",
      "              \"total_tokens\": 288\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 30,\n",
      "      \"prompt_tokens\": 258,\n",
      "      \"total_tokens\": 288,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain] [609ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"destination\\\": \\\"programming\\\",\\n    \\\"next_inputs\\\": \\\"What are good packages for graphs creation in Python?\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain] [610ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"destination\": \"programming\",\n",
      "  \"next_inputs\": {\n",
      "    \"input\": \"What are good packages for graphs creation in Python?\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are good packages for graphs creation in Python?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a very smart programmer. \\nYou are great at answering questions about computers, programming and IT in a concise \\nand easy to understand manner. \\nWhen you don't know the answer to a question you admit that you don't know.\\n\\nHere is a question:\\nWhat are good packages for graphs creation in Python?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain > llm:ChatOpenAI] [1.49s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Some popular packages for creating graphs in Python are:\\n\\n1. Matplotlib: A widely used plotting library that can create a variety of graphs, including line plots, bar charts, scatter plots, and more.\\n\\n2. Seaborn: Built on top of Matplotlib, Seaborn provides a higher-level interface for creating attractive and informative statistical graphics.\\n\\n3. Plotly: A versatile library that can create interactive plots and dashboards, ideal for data visualization and exploration.\\n\\n4. NetworkX: Specifically designed for creating and analyzing complex networks and graphs, NetworkX is a powerful tool for network analysis.\\n\\n5. Bokeh: Another library for creating interactive visualizations, Bokeh is particularly well-suited for creating web-based plots and dashboards.\\n\\nThese are just a few options, and the best package for you will depend on your specific needs and preferences.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Some popular packages for creating graphs in Python are:\\n\\n1. Matplotlib: A widely used plotting library that can create a variety of graphs, including line plots, bar charts, scatter plots, and more.\\n\\n2. Seaborn: Built on top of Matplotlib, Seaborn provides a higher-level interface for creating attractive and informative statistical graphics.\\n\\n3. Plotly: A versatile library that can create interactive plots and dashboards, ideal for data visualization and exploration.\\n\\n4. NetworkX: Specifically designed for creating and analyzing complex networks and graphs, NetworkX is a powerful tool for network analysis.\\n\\n5. Bokeh: Another library for creating interactive visualizations, Bokeh is particularly well-suited for creating web-based plots and dashboards.\\n\\nThese are just a few options, and the best package for you will depend on your specific needs and preferences.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 172,\n",
      "                \"prompt_tokens\": 71,\n",
      "                \"total_tokens\": 243,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-e179451b-c6f8-420f-97a6-776dfe4fa8eb-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 71,\n",
      "              \"output_tokens\": 172,\n",
      "              \"total_tokens\": 243\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 172,\n",
      "      \"prompt_tokens\": 71,\n",
      "      \"total_tokens\": 243,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain] [1.49s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Some popular packages for creating graphs in Python are:\\n\\n1. Matplotlib: A widely used plotting library that can create a variety of graphs, including line plots, bar charts, scatter plots, and more.\\n\\n2. Seaborn: Built on top of Matplotlib, Seaborn provides a higher-level interface for creating attractive and informative statistical graphics.\\n\\n3. Plotly: A versatile library that can create interactive plots and dashboards, ideal for data visualization and exploration.\\n\\n4. NetworkX: Specifically designed for creating and analyzing complex networks and graphs, NetworkX is a powerful tool for network analysis.\\n\\n5. Bokeh: Another library for creating interactive visualizations, Bokeh is particularly well-suited for creating web-based plots and dashboards.\\n\\nThese are just a few options, and the best package for you will depend on your specific needs and preferences.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain] [2.10s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What are good packages for graphs creation in Python?\",\n",
      "  \"text\": \"Some popular packages for creating graphs in Python are:\\n\\n1. Matplotlib: A widely used plotting library that can create a variety of graphs, including line plots, bar charts, scatter plots, and more.\\n\\n2. Seaborn: Built on top of Matplotlib, Seaborn provides a higher-level interface for creating attractive and informative statistical graphics.\\n\\n3. Plotly: A versatile library that can create interactive plots and dashboards, ideal for data visualization and exploration.\\n\\n4. NetworkX: Specifically designed for creating and analyzing complex networks and graphs, NetworkX is a powerful tool for network analysis.\\n\\n5. Bokeh: Another library for creating interactive visualizations, Bokeh is particularly well-suited for creating web-based plots and dashboards.\\n\\nThese are just a few options, and the best package for you will depend on your specific needs and preferences.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are good packages for graphs creation in Python?',\n",
       " 'text': 'Some popular packages for creating graphs in Python are:\\n\\n1. Matplotlib: A widely used plotting library that can create a variety of graphs, including line plots, bar charts, scatter plots, and more.\\n\\n2. Seaborn: Built on top of Matplotlib, Seaborn provides a higher-level interface for creating attractive and informative statistical graphics.\\n\\n3. Plotly: A versatile library that can create interactive plots and dashboards, ideal for data visualization and exploration.\\n\\n4. NetworkX: Specifically designed for creating and analyzing complex networks and graphs, NetworkX is a powerful tool for network analysis.\\n\\n5. Bokeh: Another library for creating interactive visualizations, Bokeh is particularly well-suited for creating web-based plots and dashboards.\\n\\nThese are just a few options, and the best package for you will depend on your specific needs and preferences.'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are good packages for graphs creation in Python?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af950ceb-9b53-4539-bb61-e16e2cdeeb2b",
   "metadata": {},
   "source": [
    "Tady je dotaz na kucha≈ôsk√Ω podchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fda0addc-f51c-4e93-9111-c928e64c79b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"How should I prepare fried cheese?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"How should I prepare fried cheese?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"How should I prepare fried cheese?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given a raw text input to a \\nlanguage model select the model prompt best suited for the input. \\nYou will be given the names of the available prompts and a \\ndescription of what the prompt is best suited for. \\nYou may also revise the original input if you think that revising\\nit will ultimately lead to a better response from the language model.\\n\\n<< FORMATTING >>\\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{\\n    \\\"destination\\\": string - name of the prompt to use or \\\"DEFAULT\\\"\\n    \\\"next_inputs\\\": string - a potentially modified version of the original input\\n}\\n```\\n\\nREMEMBER: \\\"destination\\\" MUST be one of the candidate prompt \\nnames specified below OR it can be \\\"DEFAULT\\\" if the input is not\\nwell suited for any of the candidate prompts.\\nREMEMBER: \\\"next_inputs\\\" can just be the original input \\nif you don't think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\nprogramming: Good for answering questions about programming and IT\\nfood: Good for answering questions about food and cooking\\n\\n<< INPUT >>\\nHow should I prepare fried cheese?\\n\\n<< OUTPUT (remember to include the ```json)>>\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain > llm:ChatOpenAI] [597ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"destination\\\": \\\"food\\\",\\n    \\\"next_inputs\\\": \\\"How should I prepare fried cheese?\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n    \\\"destination\\\": \\\"food\\\",\\n    \\\"next_inputs\\\": \\\"How should I prepare fried cheese?\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 27,\n",
      "                \"prompt_tokens\": 255,\n",
      "                \"total_tokens\": 282,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-750c2191-08b4-4f1c-967a-c7b8b8705325-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 255,\n",
      "              \"output_tokens\": 27,\n",
      "              \"total_tokens\": 282\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 27,\n",
      "      \"prompt_tokens\": 255,\n",
      "      \"total_tokens\": 282,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain] [598ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"destination\\\": \\\"food\\\",\\n    \\\"next_inputs\\\": \\\"How should I prepare fried cheese?\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain] [599ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"destination\": \"food\",\n",
      "  \"next_inputs\": {\n",
      "    \"input\": \"How should I prepare fried cheese?\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"How should I prepare fried cheese?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Your are master chef, expert at cooking and food preparation. \\nWhen you don't know the answer to a question you admit that you don't know.\\n\\n\\nHere is a question:\\nHow should I prepare fried cheese?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain > llm:ChatOpenAI] [943ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To prepare fried cheese, you will need to start by cutting the cheese into slices or cubes. Then, you will need to coat the cheese in flour, dip it in beaten eggs, and then coat it in breadcrumbs or panko. Finally, you will need to fry the cheese in hot oil until it is golden brown and crispy on the outside. Serve the fried cheese hot with your favorite dipping sauce or on top of a salad or sandwich.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To prepare fried cheese, you will need to start by cutting the cheese into slices or cubes. Then, you will need to coat the cheese in flour, dip it in beaten eggs, and then coat it in breadcrumbs or panko. Finally, you will need to fry the cheese in hot oil until it is golden brown and crispy on the outside. Serve the fried cheese hot with your favorite dipping sauce or on top of a salad or sandwich.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 90,\n",
      "                \"prompt_tokens\": 50,\n",
      "                \"total_tokens\": 140,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f2d29273-3fdb-4233-874f-a81ad31ce81d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 50,\n",
      "              \"output_tokens\": 90,\n",
      "              \"total_tokens\": 140\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 90,\n",
      "      \"prompt_tokens\": 50,\n",
      "      \"total_tokens\": 140,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain] [944ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"To prepare fried cheese, you will need to start by cutting the cheese into slices or cubes. Then, you will need to coat the cheese in flour, dip it in beaten eggs, and then coat it in breadcrumbs or panko. Finally, you will need to fry the cheese in hot oil until it is golden brown and crispy on the outside. Serve the fried cheese hot with your favorite dipping sauce or on top of a salad or sandwich.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain] [1.54s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"How should I prepare fried cheese?\",\n",
      "  \"text\": \"To prepare fried cheese, you will need to start by cutting the cheese into slices or cubes. Then, you will need to coat the cheese in flour, dip it in beaten eggs, and then coat it in breadcrumbs or panko. Finally, you will need to fry the cheese in hot oil until it is golden brown and crispy on the outside. Serve the fried cheese hot with your favorite dipping sauce or on top of a salad or sandwich.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To prepare fried cheese, you will need to start by cutting the cheese into slices or cubes. Then, you will need to coat the cheese in flour, dip it in beaten eggs, and then coat it in breadcrumbs or panko. Finally, you will need to fry the cheese in hot oil until it is golden brown and crispy on the outside. Serve the fried cheese hot with your favorite dipping sauce or on top of a salad or sandwich.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How should I prepare fried cheese?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36d4ea-8595-4665-91a6-bea295998dce",
   "metadata": {},
   "source": [
    "A nakonec defaultn√≠ podchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7467f3ad-2219-4c57-82d3-09102d15c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Who was Joseph II?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Who was Joseph II?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Who was Joseph II?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given a raw text input to a \\nlanguage model select the model prompt best suited for the input. \\nYou will be given the names of the available prompts and a \\ndescription of what the prompt is best suited for. \\nYou may also revise the original input if you think that revising\\nit will ultimately lead to a better response from the language model.\\n\\n<< FORMATTING >>\\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{\\n    \\\"destination\\\": string - name of the prompt to use or \\\"DEFAULT\\\"\\n    \\\"next_inputs\\\": string - a potentially modified version of the original input\\n}\\n```\\n\\nREMEMBER: \\\"destination\\\" MUST be one of the candidate prompt \\nnames specified below OR it can be \\\"DEFAULT\\\" if the input is not\\nwell suited for any of the candidate prompts.\\nREMEMBER: \\\"next_inputs\\\" can just be the original input \\nif you don't think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\nprogramming: Good for answering questions about programming and IT\\nfood: Good for answering questions about food and cooking\\n\\n<< INPUT >>\\nWho was Joseph II?\\n\\n<< OUTPUT (remember to include the ```json)>>\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain > llm:ChatOpenAI] [474ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"destination\\\": \\\"DEFAULT\\\",\\n    \\\"next_inputs\\\": \\\"Who was Joseph II?\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n    \\\"destination\\\": \\\"DEFAULT\\\",\\n    \\\"next_inputs\\\": \\\"Who was Joseph II?\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 25,\n",
      "                \"prompt_tokens\": 253,\n",
      "                \"total_tokens\": 278,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ddd36301-e8b4-455c-94f2-7635e06f7143-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 253,\n",
      "              \"output_tokens\": 25,\n",
      "              \"total_tokens\": 278\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 25,\n",
      "      \"prompt_tokens\": 253,\n",
      "      \"total_tokens\": 278,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain > chain:LLMChain] [474ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"```json\\n{\\n    \\\"destination\\\": \\\"DEFAULT\\\",\\n    \\\"next_inputs\\\": \\\"Who was Joseph II?\\\"\\n}\\n```\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMRouterChain] [475ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"destination\": null,\n",
      "  \"next_inputs\": {\n",
      "    \"input\": \"Who was Joseph II?\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Who was Joseph II?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Who was Joseph II?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain > llm:ChatOpenAI] [782ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Joseph II was a Holy Roman Emperor who reigned from 1765 to 1790. He was known for his reforms aimed at modernizing and centralizing the administration of the Habsburg Monarchy, as well as his efforts to promote religious tolerance and improve the living conditions of his subjects. Joseph II is often considered one of the most enlightened monarchs of his time.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Joseph II was a Holy Roman Emperor who reigned from 1765 to 1790. He was known for his reforms aimed at modernizing and centralizing the administration of the Habsburg Monarchy, as well as his efforts to promote religious tolerance and improve the living conditions of his subjects. Joseph II is often considered one of the most enlightened monarchs of his time.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 77,\n",
      "                \"prompt_tokens\": 12,\n",
      "                \"total_tokens\": 89,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ea53a55d-41e1-4f31-b6ca-f1a8ac1706b1-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 12,\n",
      "              \"output_tokens\": 77,\n",
      "              \"total_tokens\": 89\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 77,\n",
      "      \"prompt_tokens\": 12,\n",
      "      \"total_tokens\": 89,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain > chain:LLMChain] [783ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Joseph II was a Holy Roman Emperor who reigned from 1765 to 1790. He was known for his reforms aimed at modernizing and centralizing the administration of the Habsburg Monarchy, as well as his efforts to promote religious tolerance and improve the living conditions of his subjects. Joseph II is often considered one of the most enlightened monarchs of his time.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:MultiPromptChain] [1.26s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Who was Joseph II?\",\n",
      "  \"text\": \"Joseph II was a Holy Roman Emperor who reigned from 1765 to 1790. He was known for his reforms aimed at modernizing and centralizing the administration of the Habsburg Monarchy, as well as his efforts to promote religious tolerance and improve the living conditions of his subjects. Joseph II is often considered one of the most enlightened monarchs of his time.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Joseph II was a Holy Roman Emperor who reigned from 1765 to 1790. He was known for his reforms aimed at modernizing and centralizing the administration of the Habsburg Monarchy, as well as his efforts to promote religious tolerance and improve the living conditions of his subjects. Joseph II is often considered one of the most enlightened monarchs of his time.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Who was Joseph II?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118b25a-0d30-49ba-8a1b-1a54332aefd6",
   "metadata": {},
   "source": [
    "#### Transformation chain\n",
    "Viz [Transformation chain](https://python.langchain.com/docs/modules/chains/foundational/transformation).\n",
    "Transformation chain slou≈æ√≠ k tomu, aby se na vstupn√≠ textov√Ω ≈ôetƒõzec pou≈æila nƒõjak√° obecn√° python√≠ funkce. Jej√≠ jm√©no (tj. bez parametr≈Ø a kulat√Ωch z√°vorek) se vlo≈æ√≠ do parametru *transofrm* konstruktoru *TransformChain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "54de474f-f9c7-444a-8ace-f4684390ff5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:33:51.392401Z",
     "start_time": "2024-09-22T21:33:51.389591Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain\n",
    "\n",
    "def replace_animal(input_dict):\n",
    "    orig_text = input_dict[\"text\"]\n",
    "    replaced_text = orig_text.replace(\"squirrel\", \"unicorn\")\n",
    "    replaced_text = replaced_text.replace(\"squirrels\", \"unicorns\")\n",
    "    replaced_text = replaced_text.replace(\"Squirrel\", \"Unicorn\")\n",
    "    replaced_text = replaced_text.replace(\"Squirrels\", \"Unicorns\")\n",
    "    return {\"output_text\": replaced_text}\n",
    "\n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"], output_variables=[\"output_text\"], transform=replace_animal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae2552-8427-41d4-9206-9e79ecd969a7",
   "metadata": {},
   "source": [
    "N√°slednƒõ se s chainy pracuje jako v p≈ôedchoz√≠ch p≈ô√≠kladech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "89372aa4-b014-4fbf-a321-0f04f115d58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:34:06.786386Z",
     "start_time": "2024-09-22T21:34:06.770887Z"
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Find strange formulations in following text and write why are they strange:\n",
    "\n",
    "{output_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\n",
    "chat = ChatOpenAI(temperature=0.0, model_name=llm_model_name)\n",
    "llm_chain = LLMChain(llm=chat, prompt=prompt)\n",
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b8b9c938-4597-4714-949d-91f4c60498e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:34:15.002212Z",
     "start_time": "2024-09-22T21:34:11.055042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\\n    Squirrels are members of the family Sciuridae (/s…™ÀàjuÀêr…™de…™, -diÀê/), a family that includes small or medium-size rodents. \\n    The squirrel family includes tree squirrels, ground squirrels (including chipmunks and prairie dogs, among others), \\n    and flying squirrels. Squirrels are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \\n    The earliest known fossilized squirrels date from the Eocene epoch, and among other living rodent families, the squirrels are \\n    most closely related to the mountain beaver and to the dormice.\\n    \"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:TransformChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"text\": \"\\n    Squirrels are members of the family Sciuridae (/s…™ÀàjuÀêr…™de…™, -diÀê/), a family that includes small or medium-size rodents. \\n    The squirrel family includes tree squirrels, ground squirrels (including chipmunks and prairie dogs, among others), \\n    and flying squirrels. Squirrels are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \\n    The earliest known fossilized squirrels date from the Eocene epoch, and among other living rodent families, the squirrels are \\n    most closely related to the mountain beaver and to the dormice.\\n    \"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:TransformChain] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"\\n    Unicorns are members of the family Sciuridae (/s…™ÀàjuÀêr…™de…™, -diÀê/), a family that includes small or medium-size rodents. \\n    The unicorn family includes tree unicorns, ground unicorns (including chipmunks and prairie dogs, among others), \\n    and flying unicorns. Unicorns are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \\n    The earliest known fossilized unicorns date from the Eocene epoch, and among other living rodent families, the unicorns are \\n    most closely related to the mountain beaver and to the dormice.\\n    \"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"\\n    Unicorns are members of the family Sciuridae (/s…™ÀàjuÀêr…™de…™, -diÀê/), a family that includes small or medium-size rodents. \\n    The unicorn family includes tree unicorns, ground unicorns (including chipmunks and prairie dogs, among others), \\n    and flying unicorns. Unicorns are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \\n    The earliest known fossilized unicorns date from the Eocene epoch, and among other living rodent families, the unicorns are \\n    most closely related to the mountain beaver and to the dormice.\\n    \"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Find strange formulations in following text and write why are they strange:\\n\\n\\n    Unicorns are members of the family Sciuridae (/s…™ÀàjuÀêr…™de…™, -diÀê/), a family that includes small or medium-size rodents. \\n    The unicorn family includes tree unicorns, ground unicorns (including chipmunks and prairie dogs, among others), \\n    and flying unicorns. Unicorns are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \\n    The earliest known fossilized unicorns date from the Eocene epoch, and among other living rodent families, the unicorns are \\n    most closely related to the mountain beaver and to the dormice.\\n    \\n\\nSummary:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain > llm:ChatOpenAI] [6.26s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The text contains several strange formulations that raise questions about accuracy and coherence:\\n\\n1. **\\\"Unicorns are members of the family Sciuridae\\\"**: This is strange because unicorns are mythical creatures and do not belong to any biological classification. The Sciuridae family includes squirrels and similar rodents, making the claim that unicorns are part of this family nonsensical.\\n\\n2. **\\\"The unicorn family includes tree unicorns, ground unicorns, and flying unicorns\\\"**: The categorization of unicorns into different types (tree, ground, flying) is unusual and confusing. In mythology, unicorns are typically depicted as horse-like creatures with a single horn, and the idea of \\\"flying unicorns\\\" or \\\"ground unicorns\\\" does not align with traditional representations.\\n\\n3. **\\\"Unicorns are indigenous to the Americas, Eurasia, and Africa\\\"**: This statement is strange because unicorns are not real animals and thus cannot be indigenous to any region. The use of \\\"indigenous\\\" implies a biological reality that does not exist for mythical creatures.\\n\\n4. **\\\"The earliest known fossilized unicorns date from the Eocene epoch\\\"**: This is problematic because there are no fossil records of unicorns, as they are purely fictional. The mention of a specific geological epoch adds a layer of false credibility to the claim.\\n\\n5. **\\\"The unicorns are most closely related to the mountain beaver and to the dormice\\\"**: This statement is strange because it suggests a biological relationship that cannot exist, as unicorns are not real animals. The comparison to actual rodent families is misleading and creates confusion about the nature of unicorns.\\n\\nOverall, the text combines elements of fantasy with scientific terminology in a way that creates a bizarre and contradictory narrative, leading to confusion and a lack of clarity regarding the subject matter.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The text contains several strange formulations that raise questions about accuracy and coherence:\\n\\n1. **\\\"Unicorns are members of the family Sciuridae\\\"**: This is strange because unicorns are mythical creatures and do not belong to any biological classification. The Sciuridae family includes squirrels and similar rodents, making the claim that unicorns are part of this family nonsensical.\\n\\n2. **\\\"The unicorn family includes tree unicorns, ground unicorns, and flying unicorns\\\"**: The categorization of unicorns into different types (tree, ground, flying) is unusual and confusing. In mythology, unicorns are typically depicted as horse-like creatures with a single horn, and the idea of \\\"flying unicorns\\\" or \\\"ground unicorns\\\" does not align with traditional representations.\\n\\n3. **\\\"Unicorns are indigenous to the Americas, Eurasia, and Africa\\\"**: This statement is strange because unicorns are not real animals and thus cannot be indigenous to any region. The use of \\\"indigenous\\\" implies a biological reality that does not exist for mythical creatures.\\n\\n4. **\\\"The earliest known fossilized unicorns date from the Eocene epoch\\\"**: This is problematic because there are no fossil records of unicorns, as they are purely fictional. The mention of a specific geological epoch adds a layer of false credibility to the claim.\\n\\n5. **\\\"The unicorns are most closely related to the mountain beaver and to the dormice\\\"**: This statement is strange because it suggests a biological relationship that cannot exist, as unicorns are not real animals. The comparison to actual rodent families is misleading and creates confusion about the nature of unicorns.\\n\\nOverall, the text combines elements of fantasy with scientific terminology in a way that creates a bizarre and contradictory narrative, leading to confusion and a lack of clarity regarding the subject matter.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 377,\n",
      "                \"prompt_tokens\": 166,\n",
      "                \"total_tokens\": 543,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_72ed7ab54c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f1ab7840-d21b-4509-8309-29b62182b971-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 166,\n",
      "              \"output_tokens\": 377,\n",
      "              \"total_tokens\": 543\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 377,\n",
      "      \"prompt_tokens\": 166,\n",
      "      \"total_tokens\": 543,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_72ed7ab54c\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain] [6.26s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The text contains several strange formulations that raise questions about accuracy and coherence:\\n\\n1. **\\\"Unicorns are members of the family Sciuridae\\\"**: This is strange because unicorns are mythical creatures and do not belong to any biological classification. The Sciuridae family includes squirrels and similar rodents, making the claim that unicorns are part of this family nonsensical.\\n\\n2. **\\\"The unicorn family includes tree unicorns, ground unicorns, and flying unicorns\\\"**: The categorization of unicorns into different types (tree, ground, flying) is unusual and confusing. In mythology, unicorns are typically depicted as horse-like creatures with a single horn, and the idea of \\\"flying unicorns\\\" or \\\"ground unicorns\\\" does not align with traditional representations.\\n\\n3. **\\\"Unicorns are indigenous to the Americas, Eurasia, and Africa\\\"**: This statement is strange because unicorns are not real animals and thus cannot be indigenous to any region. The use of \\\"indigenous\\\" implies a biological reality that does not exist for mythical creatures.\\n\\n4. **\\\"The earliest known fossilized unicorns date from the Eocene epoch\\\"**: This is problematic because there are no fossil records of unicorns, as they are purely fictional. The mention of a specific geological epoch adds a layer of false credibility to the claim.\\n\\n5. **\\\"The unicorns are most closely related to the mountain beaver and to the dormice\\\"**: This statement is strange because it suggests a biological relationship that cannot exist, as unicorns are not real animals. The comparison to actual rodent families is misleading and creates confusion about the nature of unicorns.\\n\\nOverall, the text combines elements of fantasy with scientific terminology in a way that creates a bizarre and contradictory narrative, leading to confusion and a lack of clarity regarding the subject matter.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain] [6.26s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The text contains several strange formulations that raise questions about accuracy and coherence:\\n\\n1. **\\\"Unicorns are members of the family Sciuridae\\\"**: This is strange because unicorns are mythical creatures and do not belong to any biological classification. The Sciuridae family includes squirrels and similar rodents, making the claim that unicorns are part of this family nonsensical.\\n\\n2. **\\\"The unicorn family includes tree unicorns, ground unicorns, and flying unicorns\\\"**: The categorization of unicorns into different types (tree, ground, flying) is unusual and confusing. In mythology, unicorns are typically depicted as horse-like creatures with a single horn, and the idea of \\\"flying unicorns\\\" or \\\"ground unicorns\\\" does not align with traditional representations.\\n\\n3. **\\\"Unicorns are indigenous to the Americas, Eurasia, and Africa\\\"**: This statement is strange because unicorns are not real animals and thus cannot be indigenous to any region. The use of \\\"indigenous\\\" implies a biological reality that does not exist for mythical creatures.\\n\\n4. **\\\"The earliest known fossilized unicorns date from the Eocene epoch\\\"**: This is problematic because there are no fossil records of unicorns, as they are purely fictional. The mention of a specific geological epoch adds a layer of false credibility to the claim.\\n\\n5. **\\\"The unicorns are most closely related to the mountain beaver and to the dormice\\\"**: This statement is strange because it suggests a biological relationship that cannot exist, as unicorns are not real animals. The comparison to actual rodent families is misleading and creates confusion about the nature of unicorns.\\n\\nOverall, the text combines elements of fantasy with scientific terminology in a way that creates a bizarre and contradictory narrative, leading to confusion and a lack of clarity regarding the subject matter.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '\\n    Squirrels are members of the family Sciuridae (/s…™ÀàjuÀêr…™de…™, -diÀê/), a family that includes small or medium-size rodents. \\n    The squirrel family includes tree squirrels, ground squirrels (including chipmunks and prairie dogs, among others), \\n    and flying squirrels. Squirrels are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \\n    The earliest known fossilized squirrels date from the Eocene epoch, and among other living rodent families, the squirrels are \\n    most closely related to the mountain beaver and to the dormice.\\n    ',\n",
       " 'output': 'The text contains several strange formulations that raise questions about accuracy and coherence:\\n\\n1. **\"Unicorns are members of the family Sciuridae\"**: This is strange because unicorns are mythical creatures and do not belong to any biological classification. The Sciuridae family includes squirrels and similar rodents, making the claim that unicorns are part of this family nonsensical.\\n\\n2. **\"The unicorn family includes tree unicorns, ground unicorns, and flying unicorns\"**: The categorization of unicorns into different types (tree, ground, flying) is unusual and confusing. In mythology, unicorns are typically depicted as horse-like creatures with a single horn, and the idea of \"flying unicorns\" or \"ground unicorns\" does not align with traditional representations.\\n\\n3. **\"Unicorns are indigenous to the Americas, Eurasia, and Africa\"**: This statement is strange because unicorns are not real animals and thus cannot be indigenous to any region. The use of \"indigenous\" implies a biological reality that does not exist for mythical creatures.\\n\\n4. **\"The earliest known fossilized unicorns date from the Eocene epoch\"**: This is problematic because there are no fossil records of unicorns, as they are purely fictional. The mention of a specific geological epoch adds a layer of false credibility to the claim.\\n\\n5. **\"The unicorns are most closely related to the mountain beaver and to the dormice\"**: This statement is strange because it suggests a biological relationship that cannot exist, as unicorns are not real animals. The comparison to actual rodent families is misleading and creates confusion about the nature of unicorns.\\n\\nOverall, the text combines elements of fantasy with scientific terminology in a way that creates a bizarre and contradictory narrative, leading to confusion and a lack of clarity regarding the subject matter.'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_chain.invoke(\n",
    "    \"\"\"\n",
    "    Squirrels are members of the family Sciuridae (/s…™ÀàjuÀêr…™de…™, -diÀê/), a family that includes small or medium-size rodents. \n",
    "    The squirrel family includes tree squirrels, ground squirrels (including chipmunks and prairie dogs, among others), \n",
    "    and flying squirrels. Squirrels are indigenous to the Americas, Eurasia, and Africa, and were introduced by humans to Australia.[1] \n",
    "    The earliest known fossilized squirrels date from the Eocene epoch, and among other living rodent families, the squirrels are \n",
    "    most closely related to the mountain beaver and to the dormice.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8e26d-ded6-43fe-99e1-982fc97eec93",
   "metadata": {},
   "source": [
    "## Pamƒõ≈•\n",
    "LLM modely jako takov√© si p≈ôi odpov√≠d√°n√≠ na u≈æivatel≈Øv vstup p≈ôedchoz√≠ interakce nepamatuj√≠. Proto se do nich mus√≠ explicitnƒõ p≈ôidat pamƒõ≈•, kter√° bude historii v t√© ƒçi on√© formƒõ obsahovat.  \n",
    "#### ConversationBufferMemory\n",
    "Z√°kladn√≠m pamƒõ≈•ov√Ωm objektem je *ConversationBufferMemory*. Ten si zkr√°tka pamatuje celou konverzaci tak, jak prob√≠hala. Jak ale vypad√° praktick√© pou≈æit√≠? Asi nejsnaz≈°√≠ je pou≈æit [*ConversationChain*](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/conversation/base.py). Do jeho konstruktoru vlo≈æ√≠me chatovac√≠ model, pamƒõ≈• a lze sem um√≠stit i flag, ≈æe po≈æadujeme verbose v√Ωstup.  \n",
    "BACHA - *ConversationBufferMemory* dovoluje v parametru *memory_key* mƒõnit defaultn√≠ kl√≠ƒç (s hodnotou *history*), skrze kter√Ω se d√° dostat k pamƒõti. Jenom≈æe *ConversationalChain* s niƒç√≠m takov√Ωm nepoƒç√≠t√° a pokud nedostane *history*, tak zp≈Øsob√≠ p√°d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b59b1498-2d58-4c57-a206-db6c54479b39",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/1185378890.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "conv_buffer_memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=True,\n",
    "    memory=conv_buffer_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dce76f98-0cfb-4b58-a01f-24fd7e122ec6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8fa1c2b8-1b5c-4d73-acd6-317a687f8f73",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[]\n",
      "Human: Hi, who are you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, who are you?',\n",
       " 'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm your friendly AI assistant, here to help you with a wide range of topics. I can provide information, answer questions, and even chat about your interests. What would you like to talk about today?\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"Hello! I'm your friendly AI assistant, here to help you with a wide range of topics. I can provide information, answer questions, and even chat about your interests. What would you like to talk about today?\"}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aa96aa00-dad5-4088-9a4d-25b67ef6c587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T10:42:29.457650Z",
     "start_time": "2024-09-23T10:42:26.927241Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! I'm your friendly AI assistant, here to help you with a wide range of topics. I can provide information, answer questions, and even chat about your interests. What would you like to talk about today?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: Do you know any famous hamsters?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you know any famous hamsters?',\n",
       " 'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm your friendly AI assistant, here to help you with a wide range of topics. I can provide information, answer questions, and even chat about your interests. What would you like to talk about today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, I do! One of the most famous hamsters is \"Hammy,\" who became popular through the animated series \"The Adventures of Hammy.\" Another well-known hamster is \"Binky,\" who gained fame on social media for his adorable antics and funny videos. Additionally, there\\'s \"Mr. Nibbles,\" a hamster that was featured in various internet memes. Hamsters have a charming way of capturing our hearts with their playful behavior! Do you have a favorite hamster or a specific one in mind?', additional_kwargs={}, response_metadata={})],\n",
       " 'response': 'Yes, I do! One of the most famous hamsters is \"Hammy,\" who became popular through the animated series \"The Adventures of Hammy.\" Another well-known hamster is \"Binky,\" who gained fame on social media for his adorable antics and funny videos. Additionally, there\\'s \"Mr. Nibbles,\" a hamster that was featured in various internet memes. Hamsters have a charming way of capturing our hearts with their playful behavior! Do you have a favorite hamster or a specific one in mind?'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Do you know any famous hamsters?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "63fc0831-a7d2-42fb-9dad-e0bf224092d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T08:17:29.696145Z",
     "start_time": "2024-09-23T08:17:28.388383Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! I'm your friendly AI assistant, here to help you with a wide range of topics. I can provide information, answer questions, and even chat about your interests. What would you like to talk about today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, I do! One of the most famous hamsters is \"Hammy,\" who became popular through the animated series \"The Adventures of Hammy.\" Another well-known hamster is \"Binky,\" who gained fame on social media for his adorable antics and funny videos. Additionally, there\\'s \"Mr. Nibbles,\" a hamster that was featured in various internet memes. Hamsters have a charming way of capturing our hearts with their playful behavior! Do you have a favorite hamster or a specific one in mind?', additional_kwargs={}, response_metadata={})]\n",
      "Human: Have you ever heard about hamster called 'Boo'?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Have you ever heard about hamster called 'Boo'?\",\n",
       " 'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm your friendly AI assistant, here to help you with a wide range of topics. I can provide information, answer questions, and even chat about your interests. What would you like to talk about today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, I do! One of the most famous hamsters is \"Hammy,\" who became popular through the animated series \"The Adventures of Hammy.\" Another well-known hamster is \"Binky,\" who gained fame on social media for his adorable antics and funny videos. Additionally, there\\'s \"Mr. Nibbles,\" a hamster that was featured in various internet memes. Hamsters have a charming way of capturing our hearts with their playful behavior! Do you have a favorite hamster or a specific one in mind?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"Have you ever heard about hamster called 'Boo'?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, I\\'ve heard of Boo! However, Boo is actually a Pomeranian dog, not a hamster. He became an internet sensation due to his cute appearance and playful personality, often referred to as the \"world\\'s cutest dog.\" If you\\'re thinking of a specific hamster named Boo, I don\\'t have information on that. Hamsters can be quite popular on social media too! Do you have any particular stories or videos in mind related to Boo or any other hamsters?', additional_kwargs={}, response_metadata={})],\n",
       " 'response': 'Yes, I\\'ve heard of Boo! However, Boo is actually a Pomeranian dog, not a hamster. He became an internet sensation due to his cute appearance and playful personality, often referred to as the \"world\\'s cutest dog.\" If you\\'re thinking of a specific hamster named Boo, I don\\'t have information on that. Hamsters can be quite popular on social media too! Do you have any particular stories or videos in mind related to Boo or any other hamsters?'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Have you ever heard about hamster called 'Boo'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5127a2e-022d-42e8-a699-35a6ddb7da58",
   "metadata": {},
   "source": [
    "Na co slou≈æ√≠ v definici pamƒõ≈•ov√©ho objektu parametr *return_messages*? S pomoc√≠ metody *load_memory_variables* lze z pamƒõ≈•ov√©ho objetku z√≠skat dosavadn√≠ historii konverzace (zde pr√°zdn√© slo≈æen√© z√°vorky coby parametr metody maj√≠ sv√© pou≈æit√≠ pro urƒçit√© typy pamƒõt√≠, kter√© nƒõjak√Ω vstupn√≠ parametr po≈æaduj√≠). Pakli≈æe bylo *return_messages* rovno False, obdr≈æ√≠me v√Ωstup v podobƒõ velk√©ho stringu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "102d6bbd-4ffa-4a2e-9253-441f696f3449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T09:52:02.035886Z",
     "start_time": "2024-09-23T09:52:01.915938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm your friendly AI assistant, here to help you with a wide range of topics. I can provide information, answer questions, and even chat about your interests. What would you like to talk about today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, I do! One of the most famous hamsters is \"Hammy,\" who became popular through the animated series \"The Adventures of Hammy.\" Another well-known hamster is \"Binky,\" who gained fame on social media for his adorable antics and funny videos. Additionally, there\\'s \"Mr. Nibbles,\" a hamster that was featured in various internet memes. Hamsters have a charming way of capturing our hearts with their playful behavior! Do you have a favorite hamster or a specific one in mind?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"Have you ever heard about hamster called 'Boo'?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, I\\'ve heard of Boo! However, Boo is actually a Pomeranian dog, not a hamster. He became an internet sensation due to his cute appearance and playful personality, often referred to as the \"world\\'s cutest dog.\" If you\\'re thinking of a specific hamster named Boo, I don\\'t have information on that. Hamsters can be quite popular on social media too! Do you have any particular stories or videos in mind related to Boo or any other hamsters?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81aacf-080c-44de-8757-ddd2bbf3317e",
   "metadata": {},
   "source": [
    "Pokud ale bude *return_messages* rovno True, m√° v√Ωstup metody slo≈æitƒõj≈°√≠ strukturu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3346f3bf-b299-4f33-8b29-8343fb4c34f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello! I'm your friendly AI assistant, here to help you with a wide range of topics. I can provide information, answer questions, and even chat about your interests. What would you like to talk about today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, I do! One of the most famous hamsters is \"Hammy,\" who became popular through the animated series \"The Adventures of Hammy.\" Another well-known hamster is \"Binky,\" who gained fame on social media for his adorable antics and funny videos. Additionally, there\\'s \"Mr. Nibbles,\" a hamster that was featured in various internet memes. Hamsters have a charming way of capturing our hearts with their playful behavior! Do you have a favorite hamster or a specific one in mind?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"Have you ever heard about hamster called 'Boo'?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, I\\'ve heard of Boo! However, Boo is actually a Pomeranian dog, not a hamster. He became an internet sensation due to his cute appearance and playful personality, often referred to as the \"world\\'s cutest dog.\" If you\\'re thinking of a specific hamster named Boo, I don\\'t have information on that. Hamsters can be quite popular on social media too! Do you have any particular stories or videos in mind related to Boo or any other hamsters?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4d858",
   "metadata": {},
   "source": [
    "Zaroven muzeme historii upravovat pres metodu \"save_context()\". Zacneme tim, ze si vytvorime novou a prazdou BufferMemory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c93f8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2692ac7d",
   "metadata": {},
   "source": [
    "A vlozime do ni nasledujici konverzaci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3a44e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf9df0",
   "metadata": {},
   "source": [
    "Kdyz ted vytiskneme memory, dostaneme prave onu konverzaci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "118794fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "09f25d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d3176",
   "metadata": {},
   "source": [
    "A muzeme pridavat dalsi a dalsi context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9c67489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a806b37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4146d5cc-a7a6-46f0-af4a-5584237c51cb",
   "metadata": {},
   "source": [
    "V p≈ô√≠padƒõ, ≈æe pot≈ôebujeme nastavit syst√©mov√Ω prompt, bohu≈æel mus√≠me s√°hnout po nƒõƒçem komplikovanƒõj≈°√≠m ne≈æ je *ConversationChain* (by≈• v dal≈°√≠ch p≈ô√≠kladech pamƒõt√≠ budeme pro jednoduchost pou≈æ√≠vat pr√°vƒõ ten). K√≥d n√≠≈æe uveden√Ω byl p≈ôevzat (s m√≠rnou √∫pravou) ze spodku [t√©to str√°nky](https://python.langchain.com/docs/modules/memory/) dokumentace.  \n",
    "Pozn.: pokud bude v tomto p≈ô√≠padƒõ u pamƒõti nastaveno *return_messages*=False, k√≥d spadne. P√°d je d√°n faktem, ≈æe *MessagesPlaceholder* pot≈ôebuje historii jako list konverzac√≠, nikoli jako jeden string. T√©≈æ je t≈ôeba, aby *variable_name* v *MessagePlaceholder* odpov√≠dalo *memory_key* v pamƒõti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1504d770-df54-4a15-a991-8a7eab6fa616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are an infantile AI assistant who start every message with 'peekaboo'.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "conv_buffer_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=conv_buffer_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4b211208-9e87-4d76-a0d6-c7211eb63ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an infantile AI assistant who start every message with 'peekaboo'.\n",
      "Human: Hi, who are you?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Hi, who are you?',\n",
       " 'chat_history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Peekaboo! I'm your friendly AI assistant here to help you with any questions or information you need. What can I do for you today?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"Peekaboo! I'm your friendly AI assistant here to help you with any questions or information you need. What can I do for you today?\"}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"Hi, who are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1a998216-e772-4de3-af55-68699a3e3231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are an infantile AI assistant who start every message with 'peekaboo'.\n",
      "Human: Hi, who are you?\n",
      "AI: Peekaboo! I'm your friendly AI assistant here to help you with any questions or information you need. What can I do for you today?\n",
      "Human: Do you know any famous hamsters?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Do you know any famous hamsters?',\n",
       " 'chat_history': [HumanMessage(content='Hi, who are you?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Peekaboo! I'm your friendly AI assistant here to help you with any questions or information you need. What can I do for you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you know any famous hamsters?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Peekaboo! Yes, there are a few famous hamsters! One of the most well-known is \"Hamtaro,\" the adorable little hamster from the animated series and manga. Another is \"Gus,\" the hamster from the popular YouTube channel \"Hammy the Hamster.\" They both have captured the hearts of many fans! Do you want to know more about them?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Peekaboo! Yes, there are a few famous hamsters! One of the most well-known is \"Hamtaro,\" the adorable little hamster from the animated series and manga. Another is \"Gus,\" the hamster from the popular YouTube channel \"Hammy the Hamster.\" They both have captured the hearts of many fans! Do you want to know more about them?'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"Do you know any famous hamsters?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad91ad1-a671-4300-a66c-bd4ae710cf1f",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory\n",
    "*ConversationBufferWindowMemory* je variac√≠ na v√Ω≈°e uveden√Ω *ConversationBufferMemory*. Narozd√≠l od nƒõj neobsahuje celou konverzaci, ale jen posledn√≠ch *k* v√Ωmƒõn (ud√°v√°me stejnƒõ se jmenuj√≠c√≠m parametrem v konstruktoru pamƒõti). D√≠ky tomu je provoz chatbota levnƒõj≈°√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "220a9a74-ce83-408d-85b0-3ed26c23f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "window_memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=False,\n",
    "    memory=window_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "114fbf6f-cdd5-4b6e-b90b-34bc7e34dfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, who are you?',\n",
       " 'history': '',\n",
       " 'response': \"Hello! I'm an AI designed to assist and chat with you. I can provide information, answer questions, and engage in friendly conversation on a wide range of topics. What would you like to talk about today?\"}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dda92cb3-3996-4a16-9b67-859b54ef4672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, who are you?\\nAI: Hello! I'm an AI designed to assist and chat with you. I can provide information, answer questions, and engage in friendly conversation on a wide range of topics. What would you like to talk about today?\"}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0b60fe56-17eb-48cf-aec7-a21b35f7af8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you know any famous rabbits?',\n",
       " 'history': \"Human: Hi, who are you?\\nAI: Hello! I'm an AI designed to assist and chat with you. I can provide information, answer questions, and engage in friendly conversation on a wide range of topics. What would you like to talk about today?\",\n",
       " 'response': 'Absolutely! There are several famous rabbits in popular culture. One of the most iconic is Bugs Bunny, the clever and witty character from Warner Bros. cartoons. He first appeared in the late 1930s and is known for his catchphrase, \"What\\'s up, Doc?\" Another famous rabbit is Peter Rabbit, created by Beatrix Potter in her beloved children\\'s stories. Peter is known for his mischievous adventures in Mr. McGregor\\'s garden. Additionally, there\\'s the White Rabbit from Lewis Carroll\\'s \"Alice\\'s Adventures in Wonderland,\" who is famous for his time-keeping habits and leading Alice down the rabbit hole into Wonderland. Do you have a favorite rabbit character?'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Do you know any famous rabbits?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0c9812d7-af38-4c78-bdb5-77e72b1c1f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Do you know any famous rabbits?\\nAI: Absolutely! There are several famous rabbits in popular culture. One of the most iconic is Bugs Bunny, the clever and witty character from Warner Bros. cartoons. He first appeared in the late 1930s and is known for his catchphrase, \"What\\'s up, Doc?\" Another famous rabbit is Peter Rabbit, created by Beatrix Potter in her beloved children\\'s stories. Peter is known for his mischievous adventures in Mr. McGregor\\'s garden. Additionally, there\\'s the White Rabbit from Lewis Carroll\\'s \"Alice\\'s Adventures in Wonderland,\" who is famous for his time-keeping habits and leading Alice down the rabbit hole into Wonderland. Do you have a favorite rabbit character?'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3f1a5",
   "metadata": {},
   "source": [
    "Alternativne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0db1b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "974712d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ac04c152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a48a7-be10-448d-b29e-2cf1b1f11bc5",
   "metadata": {},
   "source": [
    "#### ConversationTokenBufferMemory\n",
    "Na podobn√©m principu je zalo≈æena i *ConversationTokenBufferMemory*, kter√° uchov√°v√° historii jen dokud se vejde do *max_token_limit* poƒçtu token≈Ø. Pokud nƒõjak√Ω p≈ô√≠spƒõvek tuto hranici p≈ôesahuje, historie se de facto vyme≈æe, tj. nen√≠ to tak, ≈æe by v n√≠ zbyl kousek star√©ho p≈ô√≠spƒõvku. Jeliko≈æ tokenizace je pro r≈Øzn√© modely r≈Øzn√°, mus√≠ se pamƒõti v parametru *llm* p≈ôedat i pou≈æit√Ω model. Nav√≠c je pot≈ôeba (minim√°lnƒõ pro OpenAI modely, ale mo≈æn√° i pro open source modely) m√≠t nainstalovan√Ω bal√≠ƒçek [tiktoken](https://pypi.org/project/tiktoken/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "823c769a-e473-406d-bc19-fbf304019d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory \n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "token_memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=60)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=False,\n",
    "    memory=token_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7de6bc66-12bd-484c-800c-f4e4ab5ba2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, who are you?',\n",
       " 'history': '',\n",
       " 'response': \"Hello! I'm an AI designed to assist you with a wide range of topics. I can help answer questions, provide information, and even engage in friendly conversation. My goal is to make our interaction enjoyable and informative. What would you like to talk about today?\"}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bd773ff1-4962-43c3-ac1b-461dc4e55341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"AI: Hello! I'm an AI designed to assist you with a wide range of topics. I can help answer questions, provide information, and even engage in friendly conversation. My goal is to make our interaction enjoyable and informative. What would you like to talk about today?\"}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6f0f5a55-0f74-4fc0-94fd-6bb96071a6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you know any famous beavers?',\n",
       " 'history': \"AI: Hello! I'm an AI designed to assist you with a wide range of topics. I can help answer questions, provide information, and even engage in friendly conversation. My goal is to make our interaction enjoyable and informative. What would you like to talk about today?\",\n",
       " 'response': 'Absolutely! One of the most famous beavers in popular culture is \"Bucky the Beaver,\" who is the mascot for the University of Wisconsin-Madison. He\\'s known for his energetic personality and is a beloved figure at sporting events.\\n\\nAnother notable beaver is \"Beaver Cleaver,\" the main character from the classic television show \"Leave It to Beaver,\" which aired in the late 1950s and early 1960s. The show depicted the life of a young boy and his family, and Beaver became an iconic representation of childhood in America.\\n\\nIn the realm of literature, there\\'s also \"The Tale of Mr. Tod\" by Beatrix Potter, which features a character named Benjamin Bunny who interacts with a beaver. \\n\\nIf you\\'re interested in real-life beavers, they are fascinating creatures known for their impressive dam-building skills and their role in creating wetland ecosystems. Do you have a specific beaver in mind, or are you curious about something else related to them?'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Do you know any famous beavers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3dd329fe-6a9d-4237-9282-b2bdfba479df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "783014e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f096dfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: AI is what?!\\nAI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92435d6e-8e90-4bbc-beb9-8ff42f00d5e3",
   "metadata": {},
   "source": [
    "#### ConversationSummaryMemory\n",
    "Odli≈°n√Ωm typem pamƒõti je *ConversationSummaryMemory*. U n√≠ se provol√°v√° jazykov√Ω model (specifikovan√Ω v konstruktoru pamƒõti pod parametrem *llm*, tj. m≈Ø≈æe m√≠t jin√© vlastnosti ne≈æ \"hlavn√≠\" v aplikaci pou≈æ√≠van√Ω model), kter√Ω m√° za √∫kol prov√©st sumarizaci dosavadn√≠ historie konverzace a nov√© konverzaƒçn√≠ v√Ωmƒõny mezi ƒçlovƒõkem a strojem. Ale muze to klidne byt ten samy. U≈æiteƒçn√© je to zejm√©na u dlouh√Ωch kovnerzac√≠, kde √∫spora z redukce d√©lky historie p≈ôebije nutnost vƒõt≈°√≠ho poƒçtu provol√°v√°n√≠ modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6fc9fab2-418d-4710-a153-367e7769927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.memory import ConversationSummaryMemory \n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=OpenAI(temperature=0),\n",
    "                                           max_token_limit=100)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5443d978-aec8-48b6-963e-e28d53d43bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, who are you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, who are you?',\n",
       " 'history': '',\n",
       " 'response': \"Hello! I'm an AI designed to assist and engage in conversations with you. I can provide information, answer questions, and discuss a wide range of topics. My goal is to make our interaction enjoyable and informative. What would you like to talk about today?\"}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aca32eb8-94db-46bd-96d4-9ba12c81a44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '\\nThe human asks the AI about its purpose and the AI explains that it is designed to assist and engage in conversations. It can provide information, answer questions, and discuss various topics with the goal of making the interaction enjoyable and informative. The AI asks the human what they would like to talk about.'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "97f30514-cf70-4a5e-bcde-9ca022abfd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human asks the AI about its purpose and the AI explains that it is designed to assist and engage in conversations. It can provide information, answer questions, and discuss various topics with the goal of making the interaction enjoyable and informative. The AI asks the human what they would like to talk about.\n",
      "Human: Do you know what are differences between rhinos and unicorns?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you know what are differences between rhinos and unicorns?',\n",
       " 'history': '\\nThe human asks the AI about its purpose and the AI explains that it is designed to assist and engage in conversations. It can provide information, answer questions, and discuss various topics with the goal of making the interaction enjoyable and informative. The AI asks the human what they would like to talk about.',\n",
       " 'response': 'Absolutely! Rhinos and unicorns are quite different in many ways, both in reality and in mythology.\\n\\n1. **Existence**: Rhinos are real animals that belong to the family Rhinocerotidae. They are large, thick-skinned mammals found in Africa and South Asia. There are five species of rhinos, including the white rhino and the Indian rhino. On the other hand, unicorns are mythical creatures often depicted as horse-like animals with a single spiraled horn on their foreheads. They are not real and are part of folklore and fantasy.\\n\\n2. **Physical Characteristics**: Rhinos are known for their massive size, thick skin, and one or two horns made of keratin (the same material as human nails). They have a stocky body and are generally gray or brown in color. Unicorns, in contrast, are usually portrayed as elegant, horse-like creatures, often depicted as white with a shimmering mane and tail, and of course, their iconic single horn.\\n\\n3. **Habitat**: Rhinos inhabit grasslands, savannas, and forests, depending on the species. They are often found near water sources. Unicorns, being mythical, are said to inhabit enchanted forests or magical realms, often associated with purity and grace.\\n\\n4. **Cultural Significance**: Rhinos are often the subject of conservation efforts due to their endangered status, and they play a role in various ecosystems. Unicorns, however, symbolize purity, beauty, and magic in various cultures and are often featured in literature, art, and popular media.\\n\\n5. **Behavior**: Rhinos are generally solitary animals, especially the males, while females may be seen with their calves. They can be quite territorial. Unicorns, in stories, are often depicted as gentle and elusive creatures, sometimes possessing magical abilities.\\n\\nSo, while rhinos are fascinating creatures that play a significant role in our natural world, unicorns are enchanting figures of myth and legend! Is there a specific aspect of either that you‚Äôd like to explore further?'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Do you know what are differences between rhinos and unicorns?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "57808f63-eed8-41f2-a093-2aa7edbc5669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ' The human asks the AI about its purpose and the AI explains that it is designed to assist and engage in conversations. The AI can provide information, answer questions, and discuss various topics with the goal of making the interaction enjoyable and informative. The AI asks the human what they would like to talk about and the conversation shifts to discussing the differences between rhinos and unicorns. The AI explains that rhinos are real animals with physical characteristics such as their size, thick skin, and horns, while unicorns are mythical creatures often depicted as elegant and magical. The AI also discusses the habitat, cultural significance, and behavior of both species. The AI then asks the human if there is a specific aspect they would like to explore further.'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "736ee973-a2e0-4d4b-98dd-3653082a3198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      " The human asks the AI about its purpose and the AI explains that it is designed to assist and engage in conversations. The AI can provide information, answer questions, and discuss various topics with the goal of making the interaction enjoyable and informative. The AI asks the human what they would like to talk about and the conversation shifts to discussing the differences between rhinos and unicorns. The AI explains that rhinos are real animals with physical characteristics such as their size, thick skin, and horns, while unicorns are mythical creatures often depicted as elegant and magical. The AI also discusses the habitat, cultural significance, and behavior of both species. The AI then asks the human if there is a specific aspect they would like to explore further.\n",
      "Human: And what about similarities?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'And what about similarities?',\n",
       " 'history': ' The human asks the AI about its purpose and the AI explains that it is designed to assist and engage in conversations. The AI can provide information, answer questions, and discuss various topics with the goal of making the interaction enjoyable and informative. The AI asks the human what they would like to talk about and the conversation shifts to discussing the differences between rhinos and unicorns. The AI explains that rhinos are real animals with physical characteristics such as their size, thick skin, and horns, while unicorns are mythical creatures often depicted as elegant and magical. The AI also discusses the habitat, cultural significance, and behavior of both species. The AI then asks the human if there is a specific aspect they would like to explore further.',\n",
       " 'response': \"That's a great question! While rhinos and unicorns are fundamentally different‚Äîone being a real animal and the other a mythical creature‚Äîthey do share some interesting similarities. \\n\\n1. **Horns**: Both rhinos and unicorns are often depicted with a prominent horn. Rhinos have one or two horns made of keratin, the same material as human nails, while unicorns are typically portrayed with a single spiraled horn that symbolizes purity and magic.\\n\\n2. **Symbolism**: Both creatures hold significant symbolic meanings in various cultures. Rhinos can symbolize strength and resilience, often representing conservation efforts due to their endangered status. Unicorns, on the other hand, are symbols of purity, grace, and the fantastical, often associated with magic and the unattainable.\\n\\n3. **Connection to Nature**: Both are often associated with natural environments. Rhinos inhabit grasslands and savannas, while unicorns are frequently depicted in lush, enchanted forests or meadows, emphasizing a connection to nature and the wild.\\n\\n4. **Cultural Representation**: Both have appeared in various forms of art, literature, and folklore. Rhinos are featured in wildlife documentaries and conservation campaigns, while unicorns are prevalent in fairy tales, fantasy novels, and artwork.\\n\\n5. **Mystique**: Both evoke a sense of wonder. Rhinos are fascinating creatures with unique behaviors and adaptations, while unicorns capture the imagination with their magical qualities.\\n\\nIf you're curious about any specific similarities or want to dive deeper into one of these points, just let me know!\"}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"And what about similarities?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3810d5d7-5281-474b-b4c2-7010de01df75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ' The human asks the AI about its purpose and the AI explains that it is designed to assist and engage in conversations. The AI can provide information, answer questions, and discuss various topics with the goal of making the interaction enjoyable and informative. The AI asks the human what they would like to talk about and the conversation shifts to discussing the differences between rhinos and unicorns. The AI explains that rhinos and unicorns have both similarities and differences, such as their horns, symbolism, connection to nature, cultural representation, and mystique. The AI offers to explore any specific similarities further if the human is interested.'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70bea6-dfe2-4aa1-887b-1d4cbd3043de",
   "metadata": {},
   "source": [
    "#### ConversationEntityMemory\n",
    "Dal≈°√≠m speci√°ln√≠m typem pamƒõti je *ConversationEntityMemory*. Ta z konverzace s pomoc√≠ jazykov√©ho modelu extrahuje informace o entit√°ch.  \n",
    "Abychom se vyhnuli chybov√© hl√°≈°ce\n",
    "```\n",
    "Got unexpected prompt input variables. The prompt expects ['history', 'input'], but got ['entities', 'history'] as inputs from memory, and input as the normal input key. (type=value_error)\n",
    "```\n",
    "mus√≠me do *ConversationChain* p≈ôidat nov√Ω parametr *prompt*, do kter√©ho vlo≈æ√≠me importov√°n√≠m z√≠skanou *ENTITY_MEMORY_CONVERSATION_TEMPLATE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "29f9c608-fb04-459a-bc26-8c74b9431193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "870fdb52-0353-4ea1-81d5-cabab0de879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['entities', 'history', 'input'], input_types={}, partial_variables={}, template='You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "559f73d3-3314-4c62-8954-3c401427cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationEntityMemory \n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, model_name=llm_model_name)\n",
    "\n",
    "entity_memory = ConversationEntityMemory(llm=OpenAI(temperature=0))\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=False,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=entity_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "038ece4e-0801-402f-86d9-8724b4061c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, who are you?',\n",
       " 'history': '',\n",
       " 'entities': {},\n",
       " 'response': \"I'm your virtual assistant, here to help you with a variety of tasks and answer any questions you might have. Whether you need information, assistance with a project, or just want to chat about a topic, I'm here for you! How can I assist you today?\"}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3731f4-820b-4393-bacd-3f5c5c2e4e01",
   "metadata": {},
   "source": [
    "Pro zkontrolov√°n√≠ obsahu pamƒõti tentokr√°t nem≈Ø≈æeme pou≈æ√≠t *entity_memory.load_memory_variables({})*, ale mus√≠me aplikovat *conversation.memory.entity_store.store*. Prozat√≠m tam nic nen√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "49689bb0-d85e-4892-83e4-422015af71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "774023ff-d12f-41f4-afc4-7ae885ff7d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you know what are differences between rhinos and unicorns?',\n",
       " 'history': \"Human: Hi, who are you?\\nAI: I'm your virtual assistant, here to help you with a variety of tasks and answer any questions you might have. Whether you need information, assistance with a project, or just want to chat about a topic, I'm here for you! How can I assist you today?\",\n",
       " 'entities': {'rhinos': '', 'unicorns': ''},\n",
       " 'response': 'Yes, there are several key differences between rhinos and unicorns:\\n\\n1. **Existence**: Rhinos are real animals that exist in the wild, primarily in Africa and Asia. They are large, thick-skinned mammals known for their distinctive horns. Unicorns, on the other hand, are mythical creatures often depicted as horse-like animals with a single horn on their foreheads. They are part of folklore and fantasy, and there is no scientific evidence of their existence.\\n\\n2. **Physical Characteristics**: Rhinos have a robust body, thick skin, and one or two horns made of keratin (the same material as human nails). Their skin is often gray or brown, and they have a large, barrel-shaped body. Unicorns are typically portrayed as elegant, horse-like creatures, often depicted as white with a spiraled horn and sometimes with a flowing mane and tail.\\n\\n3. **Habitat**: Rhinos inhabit various environments, including savannas, grasslands, and forests, depending on the species. They require large areas of land to roam and graze. Unicorns, being mythical, do not have a specific habitat but are often associated with enchanted forests or magical realms in stories.\\n\\n4. **Behavior**: Rhinos are generally solitary animals, although some species may form small groups. They are herbivores and spend a lot of time grazing. Unicorns, in folklore, are often depicted as gentle and elusive creatures, sometimes possessing magical abilities, and are often associated with purity and grace.\\n\\n5. **Cultural Significance**: Rhinos are often the focus of conservation efforts due to their endangered status and the threats they face from poaching and habitat loss. Unicorns, meanwhile, symbolize various themes in literature and art, such as innocence, beauty, and the fantastical.\\n\\nIf you have more specific questions about either rhinos or unicorns, feel free to ask!'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Do you know what are differences between rhinos and unicorns?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12104b4f-9e0e-4699-9786-f9740bd7e989",
   "metadata": {},
   "source": [
    "Postupnƒõ se ale zaƒçne pamƒõt plnit dvojicemi \"entita\": \"informace o entitƒõ\" (tady se to z nƒõjak√©ho d≈Øvodu nepovedlo...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "07f5ffe9-f2a2-4a97-9ffc-b0ff3d36c3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rhinos': 'Rhinos are often the focus of conservation efforts due to their endangered status and the threats they face from poaching and habitat loss.',\n",
       " 'unicorns': 'Unicorns are often depicted as elegant, horse-like creatures with a single horn on their forehead, and are associated with enchanted forests or magical realms in stories.'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "070f0d10-3577-4841-9c72-7481fd9cd885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I read in a scientific journal that Duocorns, an unique breed of unicorns, have tow heads.',\n",
       " 'history': \"Human: Hi, who are you?\\nAI: I'm your virtual assistant, here to help you with a variety of tasks and answer any questions you might have. Whether you need information, assistance with a project, or just want to chat about a topic, I'm here for you! How can I assist you today?\\nHuman: Do you know what are differences between rhinos and unicorns?\\nAI: Yes, there are several key differences between rhinos and unicorns:\\n\\n1. **Existence**: Rhinos are real animals that exist in the wild, primarily in Africa and Asia. They are large, thick-skinned mammals known for their distinctive horns. Unicorns, on the other hand, are mythical creatures often depicted as horse-like animals with a single horn on their foreheads. They are part of folklore and fantasy, and there is no scientific evidence of their existence.\\n\\n2. **Physical Characteristics**: Rhinos have a robust body, thick skin, and one or two horns made of keratin (the same material as human nails). Their skin is often gray or brown, and they have a large, barrel-shaped body. Unicorns are typically portrayed as elegant, horse-like creatures, often depicted as white with a spiraled horn and sometimes with a flowing mane and tail.\\n\\n3. **Habitat**: Rhinos inhabit various environments, including savannas, grasslands, and forests, depending on the species. They require large areas of land to roam and graze. Unicorns, being mythical, do not have a specific habitat but are often associated with enchanted forests or magical realms in stories.\\n\\n4. **Behavior**: Rhinos are generally solitary animals, although some species may form small groups. They are herbivores and spend a lot of time grazing. Unicorns, in folklore, are often depicted as gentle and elusive creatures, sometimes possessing magical abilities, and are often associated with purity and grace.\\n\\n5. **Cultural Significance**: Rhinos are often the focus of conservation efforts due to their endangered status and the threats they face from poaching and habitat loss. Unicorns, meanwhile, symbolize various themes in literature and art, such as innocence, beauty, and the fantastical.\\n\\nIf you have more specific questions about either rhinos or unicorns, feel free to ask!\",\n",
       " 'entities': {'Duocorns': ''},\n",
       " 'response': 'That\\'s an interesting concept! The idea of \"Duocorns\" as a unique breed of unicorns with two heads adds a fascinating twist to the traditional unicorn mythology. While unicorns are typically depicted as single-horned creatures, the notion of a two-headed variant could symbolize duality or balance in various mythological contexts.\\n\\nIn folklore, creatures with multiple heads often have special significance, representing different aspects of nature or human experience. For instance, in some mythologies, multi-headed beings are seen as more powerful or wise due to their ability to see and understand multiple perspectives.\\n\\nIf the journal you read discusses Duocorns in a scientific context, it might be exploring themes of genetics, hybridization, or even artistic interpretations of mythical creatures. If you have more details or specific aspects of Duocorns you\\'d like to discuss, feel free to share!'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"I read in a scientific journal that Duocorns, an unique breed of unicorns, have tow heads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d125a244-0ef1-42f2-9386-ca4ffd3cdcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rhinos': 'Rhinos are often the focus of conservation efforts due to their endangered status and the threats they face from poaching and habitat loss.',\n",
       " 'unicorns': 'Unicorns are often depicted as elegant, horse-like creatures with a single horn on their forehead, and are associated with enchanted forests or magical realms in stories.',\n",
       " 'Duocorns': 'The concept of \"Duocorns\" as a unique breed of unicorns with two heads adds a fascinating twist to traditional unicorn mythology, potentially symbolizing duality or balance in various mythological contexts.'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe2681-f57f-40e8-95ae-752d5d9b4573",
   "metadata": {},
   "source": [
    "# Q&A nad dokumenty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be55a8-340f-46d7-80d0-9b3daab60c98",
   "metadata": {},
   "source": [
    "#### Naƒçten√≠ dokument≈Ø\n",
    "Viz [skvela dokumentace](https://python.langchain.com/docs/integrations/document_loaders/)\n",
    "##### Naƒçten√≠ pdfka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0012e0-a2fc-463c-abb1-4818466fe859",
   "metadata": {},
   "source": [
    "S klasick√Ωm chatbotem si sice m≈Ø≈æeme pov√≠dat, ale chud√°k zn√° p≈ôinejlep≈°√≠m jen ty informace, kter√© mƒõl k dispozici p≈ôi tr√©nov√°n√≠. Co kdy≈æ s n√≠m ale chceme diskutovat obsah na≈°ich pro nƒõj v dobƒõ uƒçen√≠ nezn√°m√Ωch dokument≈Ø? T√©to problematice se budeme vƒõnovat pr√°vƒõ nyn√≠.  \n",
    "Pro zaƒç√°tek se bude na≈°e mno≈æina dokument≈Ø skl√°dat z jednoho jedin√©ho kusu - z podm√≠nek ke kreditn√≠m kart√°m od jedn√© z bank (naleziteln√© [zde](https://www.kb.cz/cs/o-bance/dokumenty#13-Platebni-karty-debetni-a-kreditni)). Jedn√° se o pdf soubor. Pdfka ale um√≠ langchain naƒç√≠tat a≈æ po nainstalov√°n√≠ bal√≠ƒçku pypdf (p≈ôesnƒõji r≈Øzn√© langchainov√© metody maj√≠ r≈Øzn√© prerekvizity, ale tahle cesta je asi nejm√©nƒõ komplikovan√°).  \n",
    "Nejprve vytvo≈ô√≠me instanci t≈ô√≠dy PyPDFLoader a to sice tak, ≈æe do konstruktoru vlo≈æ√≠me cestu k souboru. Bacha - mus√≠ se jednat o string, nikoli o Path! Na instanci posl√©ze provol√°me metodu *load*. Existuje sice i *load_and_split*, ale tu zde z pedagogick√Ωch d≈Øvod≈Ø prob√≠rat nebudeme - leze toti≈æ do zel√≠ t√©matu prob√≠ran√©mu o kus d√°l.\n",
    "\n",
    "Skvely zdroj jak nacitat PDFka je [samozrejme dokumentace](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/#using-pypdf). \n",
    "Dalsi info, treba kvuli multimodalite, je [zde](https://python.langchain.com/docs/how_to/document_loader_pdf/#use-of-multimodal-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9ef12bb0-c323-4ec1-8862-0109fa406a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ddf3529f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding_retraining.ipynb',\n",
       " 'source_notebooks',\n",
       " 'text.ipynb',\n",
       " 'transfomer_soubory',\n",
       " 'example_bpe.vocab',\n",
       " 'llms.ipynb',\n",
       " 'example_bpe.model',\n",
       " 'example.txt',\n",
       " 'pomocne_soubory',\n",
       " 'openai_langchain.ipynb',\n",
       " 'building_advanced_rags_llamaindex.ipynb']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5eed3104-f4f1-4f1c-863c-bbbef3e18b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./pomocne_soubory/podminky_debetnich_karet.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5ee6eb52-beeb-4529-9482-18b6a1125ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da8cb6-9983-4277-8d69-21a57ef01762",
   "metadata": {},
   "source": [
    "Load nahraje krom obsahu str√°nek dokumentu i metadata. V nich m√°me n√°zev souboru a ƒç√≠slo str√°nky. Tj. vypad√° to nƒõjak takto:\n",
    "```\n",
    "[Document(page_content='  \\n PODM√çNKY D EBETN√çCH KARET  ... v√Ωnos≈Ø z  trestn√© ƒçinnost i a financov√°n√≠ te rorismu , ve znƒõn√≠ \\npozdƒõj≈°√≠ch p≈ôedpi s≈Ø ', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'page': 0}),\n",
    " Document(page_content='PODM√çNKY DEBETN√çCH KARET ... poskytnut√≠ dan√© Bankovn√≠ \\nslu≈æby.  \\n ', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'page': 1}),\n",
    "...\n",
    "```\n",
    "Kazda stranka je objekt typu *Document*.\n",
    "Pozn.: To, ≈æe u ka≈æd√© str√°nky - objektu typu *Document* - vid√≠me na zaƒç√°tku v≈ædy \"PODM√çNKY DEBENTN√çCH KARET\", je d√°no skuteƒçnost√≠, ≈æe se z√°pat√≠ str√°nky, kter√© je v≈ædy stejn√©, nƒõjak dostalo na zaƒç√°tek. To mimo jin√© znamen√°, ≈æe je pot≈ôeba dokumenty p≈ôed seri√≥zn√≠m pou≈æit√≠m zaƒçistit. Bohu≈æel se tu t√©≈æ objevuje nadkritick√© mno≈æstv√≠ mezer v m√≠stech, kde mezery nemƒõly b√Ωt (nap≈ô√≠klad hned v \"PODM√çNKY D EBETN√çCH KARET\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fa6c2a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2f26af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "11701eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " PODM√çNKY DEBETN√çCH KARET \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Komerƒçn√≠ banka, a. s., se s√≠dlem:  \n",
      "Praha 1, Na P≈ô√≠kopƒõ 33 ƒçp. 969, PSƒå 114 07, IƒåO: 45317054 \n",
      "ZAPSAN√Å V OBCHODN√çM REJST≈ò√çKU VEDEN√âM MƒöSTSK√ù M SOUDEM V PRAZE, ODD√çL B, VLO≈ΩKA 1360 \n",
      "1/10 \n",
      "VER DDT_PODMPKEV.PDF \n",
      " \n",
      "Tyto Podm√≠nky debetn√≠ch karet obsahuj√≠ bli≈æ≈°√≠ √∫pravu pr√°v a povinnost√≠ vypl√Ωvaj√≠c√≠ch z  uzav≈ôen√© smlouvy, na z√°kladƒõ \n",
      "kter√© je poskytnuta debetn√≠ karta v  souladu s  pravidly p≈ô√≠slu≈°n√© Karetn√≠ spoleƒçnosti.  Seznamte se pros√≠m d≈Økladnƒõ \n",
      "s t√≠mto doku\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0fe8efbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './pomocne_soubory/podminky_debetnich_karet.pdf', 'page': 0}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7c910-4ed0-4513-8b8a-40d997b41447",
   "metadata": {},
   "source": [
    "Jin√Ω zp≈Øsob, jak naƒç√≠st obsah pdf soubor≈Ø, je zalo≈æen na pr√°ci bal√≠ƒçku [unstructured](https://pypi.org/project/unstructured/). P≈ôi p≈ô√≠pravƒõ tohoto textu jsem (pokud si dob≈ôe pamatuji) pro pfd ≈æ√°dnou roz≈°√≠≈ôenou verzi (ala pip install \"unstructured[pdf]\") instalovat nemusel. Tud√≠≈æ jsem nenarazil na pot≈ôebu m√≠t Rust kompil√°tor kv≈Øli jedn√© z prerekvizit - bal√≠ƒçku safetensors. Nicm√©nƒõ dodateƒçnƒõ bylo t≈ôeba nainstalovat bal√≠ƒçky pdf2image a pdfminer.six (nikoli pdfminer - ten u≈æ je neudr≈æovan√Ω, nav√≠c snaha o jeho pou≈æit√≠ skonƒçila s chybovou hl√°≈°kou \"ModuleNotFoundError: No module named 'pdfminer.high_level'\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "15630cd4-9ce1-424e-b5a5-c702cb5111d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6da361-0c78-4bee-a6af-1990d15fb959",
   "metadata": {},
   "source": [
    "Unstructured loadery mohou fungovat ve dvou modech. Pokud bude parametr *mode* polo≈æen rovn√Ω \"single\", tak se cel√Ω dokument - zde pdfko - po pou≈æit√≠ metody *load* vr√°t√≠ jako jeden langchainov√Ω *Document* objekt (tj. neprobƒõhne ani rozdƒõlen√≠ na str√°nky). Nicm√©nƒõ pokud se bude *mode* rovnat \"elements\", dojde k roztrh√°n√≠ dokumentu na mal√© kousky a ty kousky ponesou popisek charakterizuj√≠ jejich obsah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6b734b67-0ca2-42cd-81e6-521cf1051e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"./pomocne_soubory/podminky_debetnich_karet.pdf\", mode=\"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6c62357f-ddbf-40fd-af3b-3fa61ba69f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888aaf6-1073-44cd-8207-beb8d5e51840",
   "metadata": {},
   "source": [
    "Zde m√°me p√°r p≈ô√≠klad≈Ø:\n",
    "```\n",
    "[Document(page_content='PODM√çNKY DEBETN√çCH KARET', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((239.57, 68.46839999999997), (239.57, 82.50839999999994), (456.64312, 82.50839999999994), (456.64312, 68.46839999999997)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'Title'}),\n",
    " Document(page_content='Tyto Podm√≠nky debetn√≠ch karet obsahuj√≠ bli≈æ≈°√≠ √∫pravu pr√°v a povinnost√≠ vypl√Ωvaj√≠c√≠ch z uzav≈ôen√© smlouvy, na z√°kladƒõ kter√© je poskytnuta debetn√≠ karta v souladu s pravidly p≈ô√≠slu≈°n√© Karetn√≠ spoleƒçnosti. Seznamte se pros√≠m d≈Økladnƒõ s t√≠mto dokumentem. Va≈°e p≈ô√≠padn√© dotazy r√°di zodpov√≠me.', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((56.64, 126.82999999999993), (56.64, 156.4699999999999), (541.018, 156.4699999999999), (541.018, 126.82999999999993)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'NarrativeText'}),\n",
    "  Document(page_content='ƒål√°nek 1. Poskytnut√≠ debetn√≠ karty a jej√≠ obnova', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((65.184, 169.61839999999995), (65.184, 180.65839999999992), (317.03912, 180.65839999999992), (317.03912, 169.61839999999995)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'NarrativeText'}),\n",
    " Document(page_content='1.1', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((72.504, 195.3499999999999), (72.504, 204.3499999999999), (87.48599999999999, 204.3499999999999), (87.48599999999999, 195.3499999999999)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 1, 'category': 'UncategorizedText'}),\n",
    "...\n",
    " Document(page_content='VER DDT_PODMPKEV.PDF', metadata={'source': 'source_files\\\\podminky_debetnich_karet.pdf', 'coordinates': {'points': ((487.18, 807.3276), (487.18, 811.2876), (539.8808799999999, 811.2876), (539.8808799999999, 807.3276)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}, 'filename': 'podminky_debetnich_karet.pdf', 'file_directory': 'source_files', 'last_modified': '2023-08-12T15:21:05', 'filetype': 'application/pdf', 'page_number': 10, 'category': 'Title'})]\n",
    "```\n",
    "V≈°imnƒõme si, ≈æe kousky textu jsou se≈ôazeny podle toho, jak se v pdfku objevily. V metadatech nalezneme mimo jin√© ƒç√≠slo str√°nky, ƒçty≈ôi body ohraniƒçuj√≠c√≠ lokaci textu, jm√©no souboru anebo kategorii textu.  \n",
    "Jak√© kategorie tu vid√≠me? \n",
    "- Title - nevyskytuje se jen u nadpis≈Ø, ale nap≈ô√≠klad i u kapit√°lkami vyveden√©ho z√°pat√≠ (\"VER DDT_PODMPKEV.PDF\" z konce p≈ô√≠kladu)\n",
    "- NarrativeText - vƒõt≈°inovƒõ se jedn√° o obƒçejn√Ω text\n",
    "- UncategorizedText - zde se obvykle nal√©z√° \"smet√≠\" - ƒç√≠slov√°n√≠ str√°nek, ƒç√≠sla paragraf≈Ø stoj√≠c√≠ mimo text anebo z√°pat√≠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3527d7-fa7b-460c-b93e-aa0d38871765",
   "metadata": {},
   "source": [
    "Rozdƒõlen√≠ na kategorie nicm√©nƒõ nen√≠ √∫plnƒõ spolehliv√©. Kdy≈æ bychom si u na≈°eho dokumentu nechali vypsat v≈°echny \"Title\" dokumenty k√≥dem\n",
    "```python\n",
    "for one_doc in data:\n",
    "    if one_doc.metadata[\"category\"] == \"Title\":\n",
    "        print(one_doc.page_content)\n",
    "```\n",
    "najdeme tam mezi nadpisy a kousky z√°pat√≠ i norm√°ln√≠ text, nap≈ô. \"3D Secure. V≈°echny n√°mi poskytnut√© debetn√≠ karty jsou 3D Secure aktivn√≠.\". A naopak v \"NarrativeText\" ƒçlovƒõk nalezne p√°r nadpis≈Ø. Je nakonec ot√°zkou, zda nen√≠ lep≈°√≠, kdy≈æ si ƒçlovƒõk dokument prohl√©dne a zaƒçist√≠ ho ruƒçnƒõ podle sv√©ho. Nakonec tak bude nejvhodnƒõj≈°√≠ single mode unstructured (narozd√≠l od PyPDFLoaderu nem√° nabyteƒçn√© mezery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6c6f59d6-fad4-46b4-824e-e15c44314d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"./pomocne_soubory/podminky_debetnich_karet.pdf\", mode=\"single\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6ac5a-42f5-4431-ab9f-e7863f09c61f",
   "metadata": {},
   "source": [
    "Vytvo≈ôen√≠ objektu typu Document pot≈ôebn√© pro ruƒçn√≠ vytv√°≈ôen√≠ fragment≈Ø:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a7c6497d-ed58-4601-858e-4410eae88c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document\n",
    "\n",
    "fragment = Document(\n",
    "    page_content=\"this is fragment text\",\n",
    "    metadata={\"file\":\"something.pdf\", \"page\":0, \"another_metadata_field\":\"something\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a0d6a-cf0c-4235-bfa7-059c26048f97",
   "metadata": {},
   "source": [
    "##### Naƒçten√≠ html souboru\n",
    "Pro naƒç√≠t√°n√≠ html str√°nek existuj√≠ v r√°mci Langchainu dvƒõ podporovan√© cesty. Jedna vy≈æaduje pou≈æit√≠ bal√≠ƒçku [unstructured](https://pypi.org/project/unstructured/). Jako data pou≈æijeme wiki str√°nku o [jednom druhu k≈ôeƒçka](https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster). Zd≈Øraznƒõme, ≈æe n√°sleduj√≠c√≠ postup se t√Ωka html souboru ulo≈æen√©ho na disku, nikoli webov√© str√°nky - na to je jin√Ω loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cbcc4df2-2598-47d7-923e-21eeb4bd8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8630637a-e794-4995-943b-bb18ed253a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(\"source_files\\\\Winter white dwarf hamster - Wikipedia.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365adbdf-46c0-4d68-8855-71106cf137a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59297196-13b6-491c-8991-c4fa23bbd9dc",
   "metadata": {},
   "source": [
    "Nahran√Ω objekt vypad√° (po vy≈ôazen√≠ vƒõt≈°iny textu z d≈Øvodu p≈ôehlednosti) takto:\n",
    "```\n",
    "[Document(page_content='Toggle the table of contents\\n\\nToggle the table of contents\\n\\nWinter white dwarf hamster\\n\\n43 languages\\n\\nÿßŸÑÿπÿ±ÿ®Ÿäÿ©\\n\\nAsturianu\\n\\n–ë—ä–ª–≥–∞—Ä—Å–∫–∏\\n\\nBrezhoneg\\n\\nCatal√†\\n\\nCebuano\\n\\nƒåe≈°tina\\n\\nDeutsch\\n\\nDin√© bizaad\\n\\nEesti\\n\\nEspa√±ol\\n\\nEuskara\\n\\nŸÅÿßÿ±ÿ≥€å\\n\\nFran√ßais\\n\\nFrysk\\n\\nÌïúÍµ≠Ïñ¥\\n\\n’Ä’°’µ’•÷Ä’•’∂\\n\\nHrvatski\\n\\nBah  \n",
    "...  \n",
    "nCategories:\\n\\nIUCN Red List least concern species\\n\\nPhodopus\\n\\nRodents of Asia\\n\\nMammals described in 1773\\n\\nMammals of Siberia\\n\\nTaxa named by Peter Simon Pallas\\n\\nHidden categories: \\n\\nArticles with short description\\n\\nShort description is different from Wikidata\\n\\nGood articles\\n\\nArticles with \\'species\\' microformats', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm'})]\n",
    "```\n",
    "P≈ôed pou≈æit√≠m bude tedy pot≈ôeba prov√©st opravdu masivn√≠ zaƒçi≈°tƒõn√≠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50eec47-4c9c-424e-88c4-09d1addb7d5e",
   "metadata": {},
   "source": [
    "Opƒõt je mo≈æn√© pou≈æ√≠t unstructured naƒç√≠t√°n√≠ v modu \"elements\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0846d3b-4aa9-4bfb-8feb-be7ca63f9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredHTMLLoader(\"source_files\\\\Winter white dwarf hamster - Wikipedia.htm\", mode=\"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81140d58-5790-4d63-99d6-487772f2fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f873617-a9d9-446a-8c34-e4f20e0cf046",
   "metadata": {},
   "source": [
    "V√Ωsledek vypad√° takto:\n",
    "```\n",
    "[Document(page_content='Toggle the table of contents', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'filename': 'Winter white dwarf hamster - Wikipedia.htm', 'file_directory': 'source_files', 'last_modified': '2023-08-22T20:35:12', 'filetype': 'text/html', 'page_number': 1, 'emphasized_text_contents': ['Toggle the table of contents'], 'emphasized_text_tags': ['span'], 'category': 'Title'}),  \n",
    "...  \n",
    " Document(page_content='population density is highly varied.', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'filename': 'Winter white dwarf hamster - Wikipedia.htm', 'file_directory': 'source_files', 'last_modified': '2023-08-22T20:35:12', 'filetype': 'text/html', 'page_number': 3, 'link_urls': ['https://en.wikipedia.org/wiki/Population_density'], 'link_texts': ['population density'], 'category': 'NarrativeText'}),\n",
    " Document(page_content='[23]', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'filename': 'Winter white dwarf hamster - Wikipedia.htm', 'file_directory': 'source_files', 'last_modified': '2023-08-22T20:35:12', 'filetype': 'text/html', 'page_number': 3, 'link_urls': ['#cite_note-J1979:R1998:E-23'], 'link_texts': ['[23]'], 'category': 'UncategorizedText'}),  \n",
    " ...  \n",
    "Document(page_content=\"Articles with 'species' microformats\", metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'filename': 'Winter white dwarf hamster - Wikipedia.htm', 'file_directory': 'source_files', 'last_modified': '2023-08-22T20:35:12', 'filetype': 'text/html', 'page_number': 3, 'link_urls': ['https://en.wikipedia.org/wiki/Category:Articles_with_%27species%27_microformats'], 'link_texts': [\"Articles with 'species' microformats\"], 'category': 'ListItem'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047f941-6317-4bd8-b3e0-97112ad525d5",
   "metadata": {},
   "source": [
    "Pro naƒçten√≠ html souboru lze t√©≈æ pou≈æ√≠t loader vyu≈æ√≠vaj√≠c√≠ BeautifulSoup4. Moje prvn√≠ provol√°n√≠ metody *load* vedlo k chybov√© hl√°≈°ce obsahuj√≠c√≠ mimo jin√©\n",
    "```\n",
    "soup = BeautifulSoup(f, **self.bs_kwargs)\n",
    "```\n",
    "a\n",
    "```\n",
    "FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?\n",
    "```\n",
    "A to i kdy≈æ byl ve virtu√°ln√≠m prost≈ôed√≠ bal√≠ƒçek BeautifulSoup4 nainstalov√°n. Co ale chybƒõlo byl bal√≠ƒçek [lxml](https://pypi.org/project/lxml/). Po jeho nainstalov√°n√≠ se ale (u anglick√©ho!) textu objevila dal≈°√≠ chybov√° hl√°≈°ka:\n",
    "```\n",
    "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 27841: character maps to <undefined>\n",
    "```\n",
    "To kv≈Øli tomu, ≈æe jsem nepou≈æil parametr *open_encoding* a html soubor se tak otev√≠ral s defaultn√≠m k√≥dov√°n√≠m, kter√Ωm je utf-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc2256-b41e-4f68-a934-935fba97b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "loader = BSHTMLLoader(\"source_files\\\\Winter white dwarf hamster - Wikipedia.htm\", open_encoding=\"latin1\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba96dc-63d4-4a0d-ba0b-817372e57f13",
   "metadata": {},
   "source": [
    "Opƒõt z nahran√©ho objektu uk√°≈æeme pouze zaƒç√°tek a konec:\n",
    "```\n",
    "[Document(page_content='\\n\\n\\nWinter white dwarf hamster - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload\n",
    "...\n",
    "\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'source_files\\\\Winter white dwarf hamster - Wikipedia.htm', 'title': 'Winter white dwarf hamster - Wikipedia'})]\n",
    "```\n",
    "Zd√° se, ≈æe pot≈ôeba zaƒçi≈°tƒõn√≠ je tu je≈°tƒõ vƒõt≈°√≠ ne≈æ u bal√≠ƒçku unstructured..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bb12b-99c3-4fc4-b7d7-e3eadf00d680",
   "metadata": {},
   "source": [
    "##### [Naƒçten√≠ webov√© str√°nky](https://python.langchain.com/docs/integrations/document_loaders/web_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0750427f-d1b9-496e-82e8-015233d5a0ae",
   "metadata": {},
   "source": [
    "V praxi bychom up≈ôednost≈àovali, kdybychom vytƒõ≈æovan√© str√°nky nemuseli stahovat a kdyby si Langchain informace natahal p≈ô√≠mo z webu. Na to slou≈æ√≠ *WebBaseLoader*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "85da32b1-83d7-441d-89d5-423a306afbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "647ef698-62bf-4dcc-95d0-696092ed803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fd97daed-2948-46f2-a89e-a976f97011fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b07301-096d-495e-aeb5-973d7d9416f9",
   "metadata": {},
   "source": [
    "Zde vid√≠me p≈ô√≠klad form√°tu, v jak√©m je str√°nka naƒçtena:\n",
    "```\n",
    "[Document(page_content='\\n\\n\\n\\nWinter white dwarf hamster - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\nLanguages\\n\\nLanguage links are at the top of the page across from the title.\n",
    "...\n",
    "\\nContact Wikipedia\\nCode of Conduct\\nMobile view\\nDevelopers\\nStatistics\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster', 'title': 'Winter white dwarf hamster - Wikipedia', 'language': 'en'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ff565-b138-4af7-8910-533ba5444794",
   "metadata": {},
   "source": [
    "V r√°mci jednoho vol√°n√≠ lze naƒç√≠st i v√≠ce str√°nek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "72523577-e118-4df4-bdf7-4cadcf5d8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader([\n",
    "    \"https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster\", \n",
    "    \"https://en.wikipedia.org/wiki/Syrian_hamster\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "67adca37-68f5-4d20-b0c3-3dcd6bef3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000d2d3-e78f-4d37-ab07-0da4c802d7b4",
   "metadata": {},
   "source": [
    "Uk√°zka v√Ωsledku:\n",
    "```\n",
    "[Document(page_content='\\n\\n\\n\\nWinter white dwarf hamster - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\n",
    "...\n",
    "\\nContact Wikipedia\\nCode of Conduct\\nMobile view\\nDevelopers\\nStatistics\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster', 'title': 'Winter white dwarf hamster - Wikipedia', 'language': 'en'}),\n",
    " Document(page_content='\\n\\n\\n\\nGolden hamster - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\n",
    "...\n",
    "\\nCode of Conduct\\nMobile view\\nDevelopers\\nStatistics\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://en.wikipedia.org/wiki/Syrian_hamster', 'title': 'Golden hamster - Wikipedia', 'language': 'en'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a3cdb2-655f-4084-b30c-e4f518bef75d",
   "metadata": {},
   "source": [
    "I pro naƒç√≠t√°n√≠ str√°nek z webu existuje [unstructured loader](https://python.langchain.com/docs/integrations/document_loaders/url)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5d931406-abe4-4a2f-ae86-c2d97d05465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "30f56af1-2736-420e-a1f4-2d8eda02b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster\", \n",
    "    \"https://en.wikipedia.org/wiki/Syrian_hamster\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278a424-b8e8-4177-aa33-0048276f51da",
   "metadata": {},
   "source": [
    "Kdy≈æ ƒçlovƒõk nem√° nainstalovan√Ω bal√≠ƒçek libmagic, objev√≠ se hl√°≈°ky\n",
    "```\n",
    "libmagic is unavailable but assists in filetype detection on file-like objects. Please consider installing libmagic for better results.\n",
    "Error fetching or processing https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster, exception: Invalid file. The FileType.UNK file type is not supported in partition.\n",
    "libmagic is unavailable but assists in filetype detection on file-like objects. Please consider installing libmagic for better results.\n",
    "Error fetching or processing https://en.wikipedia.org/wiki/Syrian_hamster, exception: Invalid file. The FileType.UNK file type is not supported in partition.\n",
    "```\n",
    "Naƒçten√Ω objekt pak bude pr√°zdn√Ωm listem.\n",
    "Probl√©m je, ≈æe existuje v√≠ce libmagic ([zde](https://pypi.org/project/python-libmagic/#description) a [zde](https://pypi.org/project/libmagic/#description)), ty jsou ale relativnƒõ star√© a prakticky od sv√©ho vzniku neudr≈æovan√©...  \n",
    "T√©≈æ existuje bal√≠ƒçek [python-magic](https://pypi.org/project/python-magic/#history). Ten u≈æ vypad√° ≈æivƒõji, nicm√©nƒõ kdy≈æ nainstalujeme jeho nejnovƒõj≈°√≠ verzi, obdr≈æ√≠me errory\n",
    "```\n",
    "Error fetching or processing https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster, exception: module 'magic' has no attribute 'from_buffer'\n",
    "Error fetching or processing https://en.wikipedia.org/wiki/Syrian_hamster, exception: module 'magic' has no attribute 'from_buffer'\n",
    "```\n",
    "Instalace star≈°√≠ verze vede t√©≈æ k chybov√Ωm hl√°≈°k√°m.  \n",
    "Probl√©m lze vy≈ôe≈°it instalac√≠ [python-magic-bin](https://pypi.org/project/python-magic-bin). Nicm√©nƒõ jedn√° se o bin√°rky z repa zapadan√©ho prachem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "31fa2cd8-8851-4337-9678-d0edc164786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845948c4-148d-4061-b304-533c3f46d8c3",
   "metadata": {},
   "source": [
    "Uk√°zka:\n",
    "```\n",
    "[Document(page_content='Toggle the table of contents\\n\\nToggle the table of contents\\n\\nWinter white dwarf hamster\\n\\n43 languages\\n\\nÿßŸÑÿπÿ±ÿ®Ÿäÿ©\\n\\nAsturianu\\n\\n–ë—ä–ª–≥–∞—Ä—Å–∫–∏\\n\\nBrezhoneg\\n\\nCatal√†\\n\\nCebuano\\n\\nƒåe≈°tina\\n\\nDeutsch\\n\\nDin√© bizaad\\n\\nEesti\\n\\nEspa√±ol\\n\\nEuskara\\n\\nŸÅÿßÿ±ÿ≥€å\\n\\nFran√ßais\\n\\nFrysk\\n\\nÌïúÍµ≠Ïñ¥\\n\\n’Ä’°’µ’•÷Ä’•’∂\\n\\nHrvatski\\n\\nBahasa Indonesia\\n\\nItaliano\\n\\n◊¢◊ë◊®◊ô◊™\\n\\n“ö–∞–∑–∞“õ—à–∞\\n\\nKotava\\n\\nLatvie≈°u\\n\\nMagyar\\n\\nŸÖÿµÿ±Ÿâ\\n\\nNederlands\\n\\nÊó•Êú¨Ë™û\\n\\nNorsk bokm√•l\\n\\nNorsk nynorsk\\n\\nPolski\\n\\nPortugu√™s\\n\\nRom√¢nƒÉ\\n  \n",
    "...  \n",
    "Red List least concern species\\n\\nPhodopus\\n\\nRodents of Asia\\n\\nMammals described in 1773\\n\\nMammals of Siberia\\n\\nTaxa named by Peter Simon Pallas\\n\\nHidden categories: \\n\\nArticles with short description\\n\\nShort description is different from Wikidata\\n\\nGood articles\\n\\nArticles with \\'species\\' microformats', metadata={'source': 'https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster'}),\n",
    " Document(page_content='Toggle the table of contents\\n\\nToggle the table of contents\\n\\nGolden hamster\\n\\n49 languages\\n\\nÿßŸÑÿπÿ±ÿ®Ÿäÿ©\\n\\nAragon√©s\\n\\n–ë–µ–ª–∞—Ä—É—Å–∫–∞—è (—Ç–∞—Ä–∞—à–∫–µ–≤—ñ—Ü–∞)\\n\\n–ë—ä–ª–≥–∞—Ä—Å–∫–∏\\n\\nCatal√†\\n\\nCebuano\\n\\nƒåe≈°tina\\n\\nCymraeg\\n\\nDeutsch\\n\\nDin√© bizaad\\n\\nEesti\\n\\nEspa√±ol\\n\\nEsperanto\\n\\nEuskara\\n\\nŸÅÿßÿ±ÿ≥€å\\n\\nFran√ßais\\n\\nFrysk\\n\\nGaeilge\\n\\nÌïúÍµ≠Ïñ¥\\n\\nHrvatski\\n\\nBahasa Indonesia\\n\\nIta  \n",
    " ...  \n",
    " abic-language text\\n\\nAll articles with unsourced statements\\n\\nArticles with unsourced statements from June 2019\\n\\nArticles with unsourced statements from September 2019\\n\\nCommons link is on Wikidata\\n\\nArticles with GND identifiers\\n\\nArticles with J9U identifiers\\n\\nArticles with LCCN identifiers\\n\\nArticles with NKC identifiers\\n\\nArticles containing video clips', metadata={'source': 'https://en.wikipedia.org/wiki/Syrian_hamster'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d8ec45ce-fafb-4027-86d9-4959eb81d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(urls=urls, mode=\"elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e7f3f5a7-4c6f-4ee7-acaa-ee1974576884",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48824f7a-6dbb-4bfa-886d-b29ac45ff956",
   "metadata": {},
   "source": [
    "Uk√°zka:\n",
    "```\n",
    "[Document(page_content='Toggle the table of contents', metadata={'filetype': 'text/html', 'page_number': 1, 'url': 'https://en.wikipedia.org/wiki/Winter_white_dwarf_hamster', 'emphasized_text_contents': ['Toggle the table of contents'], 'emphasized_text_tags': ['span'], 'category': 'Title'}),  \n",
    "...  \n",
    " Document(page_content='A hamster wheel is a common type of environmental enrichment, and it is important that hamsters have a wheel in their cage. TVT recommends wheels should be at least 30\\xa0cm for Syrian hamsters, since smaller diameters lead to permanent spinal curvatures, especially in young animals. They also recommend a solid running surface because rungs or mesh can cause injury.[19] A hamster should be able to run on its wheel without arching its back. A hamster that has to run with an arched back can have back pain and spine problems. A variety of toys and cardboard tubes and boxes can help to provide enrichment, as they are energetic and need space to exercise.[20]', metadata={'filetype': 'text/html', 'page_number': 3, 'url': 'https://en.wikipedia.org/wiki/Syrian_hamster', 'link_urls': ['/wiki/Hamster_wheel', '#cite_note-19', '#cite_note-20'], 'link_texts': ['hamster wheel', '[19]', '[20]'], 'category': 'NarrativeText'}),\n",
    " Document(page_content='Most hamsters in American and British pet stores are golden hamsters. Originally, golden hamsters occurred in just one color ‚Äì the mixture of brown, black, and gold, but they have since developed a variety of color and pattern mutations, including cream, white, blonde, cinnamon, tortoiseshell, black, three different shades of gray, dominant spot, banded, and dilute.[citation needed]', metadata={'filetype': 'text/html', 'page_number': 3, 'url': 'https://en.wikipedia.org/wiki/Syrian_hamster', 'link_urls': ['/wiki/Wikipedia:Citation_needed'], 'link_texts': [None], 'emphasized_text_contents': ['citation needed', 'citation needed'], 'emphasized_text_tags': ['i', 'span'], 'category': 'NarrativeText'}),  \n",
    "...  \n",
    "Document(page_content='Articles containing video clips', metadata={'filetype': 'text/html', 'page_number': 3, 'url': 'https://en.wikipedia.org/wiki/Syrian_hamster', 'link_urls': ['/wiki/Category:Articles_containing_video_clips'], 'link_texts': ['Articles containing video clips'], 'category': 'ListItem'})]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc3413",
   "metadata": {},
   "source": [
    "##### Naƒçten√≠ YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8892bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "69103e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install yt_dlp\n",
    "# ! pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pozor, muze trvat par minut\n",
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151cfd8",
   "metadata": {},
   "source": [
    "##### Notion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c36b22",
   "metadata": {},
   "source": [
    "Follow steps [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/notion) for an example Notion site such as [this one](https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f):\n",
    "\n",
    "* Duplicate the page into your own Notion space and export as `Markdown / CSV`.\n",
    "* Unzip it and save it as a folder that contains the markdown file for the Notion page.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8306cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8605fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49b651-5f00-4eef-a0a9-4acc195dbc64",
   "metadata": {},
   "source": [
    "#### Splittery\n",
    "Obsah str√°nek by zejm√©na pro v√Ω≈æivnƒõj≈°√≠ texty mohl b√Ωt vƒõt≈°√≠, ne≈æ poƒçet token≈Ø, kter√© dok√°≈æe v jeden okam≈æik jazykov√Ω model zpracovat. Proto se dokumenty mus√≠ rozdƒõlit na mal√© kousky.  \n",
    "Z√°kladn√≠m n√°strojem pro takovou √∫lohu je *CharacterTextSplitter*. V jeho konstruktoru mus√≠me do parametru *separator* vlo≈æit separaƒçn√≠ znak (resp. posloupnost znak≈Ø). Bacha - *CharacterTextSplitter* podporuje jen a pouze jeden separ√°tor. Pokud bude splitov√°n√≠ prob√≠hat podle nƒõjak√©ho speci√°ln√≠ho escapovan√©ho znaku (nap≈ô. podle znaku nov√©ho ≈ô√°dku) a nepou≈æ√≠v√°me regul√°rn√≠ v√Ωrazy (tj. parametr *is_separator_regex* nen√≠ polo≈æen√Ω rovn√Ω True), mus√≠me ps√°t jen jedno zpƒõtn√© lom√≠tko! N√°slednƒõ specifikujeme optim√°ln√≠ velikost fragmentu textu (parametr *chunk_size*; ƒç√≠slo je v poƒçtu znak≈Ø podle funkce *len*) a velikost p≈ôekryvu mezi fragmenty (parametr *chunk_overlap*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80a8b4",
   "metadata": {},
   "source": [
    "##### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "166985bf-8997-40a1-8a07-ee258f964622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dbededcb-2687-4cac-8d37-af985f7d1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7bc5b7e0-ea69-4886-8125-7cff221fd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038deb21-0278-4a83-a7fc-34a15163d6b5",
   "metadata": {},
   "source": [
    "Pokud bychom chtƒõli splittovat obyƒçejn√Ω text, pou≈æili bychom metodu *split_text* instance *CharacterTextSplitter*, p≈ôiƒçem≈æ inkriminovan√Ω text by byl p≈ôed√°n metodƒõ jako parametr. Viz nasledujici priklad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "181551ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2ba013b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "15e417de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_text_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7ee85",
   "metadata": {},
   "source": [
    "Pojdme si trochu hrat s parametry, at je vidno, co to vlastne dela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d5de92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45697669",
   "metadata": {},
   "source": [
    "##### Split_Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4ecfa",
   "metadata": {},
   "source": [
    "Nicm√©nƒõ my m√°me list obsahuj√≠c√≠ nav√≠c krom samotn√©ho textu i metadata o str√°nk√°ch p≈Øvodn√≠ho pdfka, s ƒç√≠m≈æ nen√≠ *split_text* oƒçek√°vaj√≠c√≠ string kompatibiln√≠. Proto mus√≠me pou≈æ√≠t metodu *split_documents*.  \n",
    "Jak vlastnƒõ splitov√°n√≠ funguje?\n",
    " - pokud separ√°tor nen√≠ v dokumentu (v na≈°em p≈ô√≠padƒõ dokument = jedna str√°nka) p≈ô√≠tomen, k ≈æ√°dn√©mu rozsek√°n√≠ nedoch√°z√≠. Tj. pokud na vstupu bylo 10 str√°nek, bude stejn√Ω poƒçet i na v√Ωstupu, co≈æ pro praktick√© pou≈æit√≠ optim√°ln√≠ nen√≠.  \n",
    " - pokud je separ√°tor vz√°cn√Ω, tak se nƒõkter√© dokumenty v≈Øbec nerozsekaj√≠ (proto≈æe v nich separ√°tor nen√≠), jin√© se rozdƒõl√≠ t≈ôeba jen podle jedin√©ho v√Ωskytu separ√°toru (i kdy≈æ i pak budou oba vznikl√© fragmenty vƒõt≈°√≠ ne≈æ *chunk_size*)\n",
    " - pokud je separ√°tor p≈ô√≠tomn√Ω ƒçasto, probƒõhne rozsek√°v√°n√≠ tak, aby byla t√©mƒõ≈ô dosa≈æena, ale nikdy p≈ôekroƒçena *chunk_size* (resp. mo≈æn√° se dokument rozsek√° podle v≈°ech v√Ωskyt≈Ø separ√°toru, ale pak se na sebe nƒõkter√© fragmenty znova nalep√≠).\n",
    "\n",
    "Bacha, pokud pou≈æ√≠v√°me regexy (*is_separator_regex* = True) a zvol√≠me nƒõjak√Ω obecn√Ω pattern (t≈ôeba \"\\\\w\"), tak se n√°m t√≠mto patternem nahrad√≠ v≈°echny relevantn√≠ znaky nahrad√≠. Tj. fragment pak t≈ôeba vypad√° takto:\n",
    "```\n",
    "'\\\\w \\\\w \\\\w \\\\w   \\n \\n \\n \\n \\n\\\\w \\\\w \\\\w, \\\\w. \\\\w., \\\\w \\\\w:  \\n\\\\w \\\\w, \\\\w \\\\w \\\\w \\\\w \\\\w. \\\\w, \\\\w \\\\w \\\\w, \\\\w: \\\\w  \\n\\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w, \\\\w \\\\w, \\\\w \\\\w \\\\w \\\\w/\\\\w  \\n\\\\w \\\\w \\\\w.\\\\w \\n \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w \\\\w  \\\\w \\\\w, \\\\w \\\\w \\n\\\\w \\\\w \\\\w  \\\\w \\\\w \\\\w  \\\\w \\\\w'\n",
    "```\n",
    "Takov√©mu chov√°n√≠ zabr√°n√≠me um√≠stƒõn√≠m parametru *keep_separator*=True do konstruktoru *CharacterTextSplitter*u.  \n",
    "N√≠≈æe vid√≠me p≈ô√≠klad v√Ωstupu metody *split_documents*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c8329132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"./source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "febbb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "69906715",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f1eccef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4d4e9e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "aa05e66b-e70d-4c9d-8d72-dc342f9017ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck' metadata={'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf', 'page': 0}\n",
      "973\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])\n",
    "print(len(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44b0a4-0b7f-4bfb-af53-8a828ce25e0f",
   "metadata": {},
   "source": [
    "V√Ω≈°e jsme vidƒõli, ≈æe *CharacterTextSplitter* nen√≠ pro pr√°ci s obyƒçejn√Ωm textem kv≈Øli omezen√≠ na jeden separ√°tor moc praktick√Ω. Proto je vhodnƒõj≈°√≠ pou≈æ√≠t *RecursiveCharacterTextSplitter*. Ten nem√° parametr *separator*, n√Ωbr≈æ *separators*. Do nƒõj se vkl√°d√° list potenci√°ln√≠ch separ√°tor≈Ø. Jeho defaultn√≠ hodnotou je [\"\\n\\n\", \"\\n\", \" \", \"\"]. My≈°lenka za touto volbou je takov√°, ≈æe se spitter sna≈æ√≠ dr≈æet pohromadƒõ odstavce (a potom vƒõty a pak slova) tak dlouho, jak to jen jde, kv≈Øli zachov√°n√≠ informace schovan√© v textu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd2dac",
   "metadata": {},
   "source": [
    "##### RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5a1dc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3387ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "613e319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f94947",
   "metadata": {},
   "source": [
    "Why doesn't this split the string below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "461c77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1a68633b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "283c9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "209aa856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612e0e1",
   "metadata": {},
   "source": [
    "Ok, this splits the string but we have an overlap specified as 5, but it looks like 3? (try an even number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "87684fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e96a8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b78118",
   "metadata": {},
   "source": [
    "Z techhle dvou je `RecursiveCharacterTextSplitter` recommended for generic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "aefc94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fd8f4af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e4fa60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6fffa39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52e607",
   "metadata": {},
   "source": [
    "Let's reduce the chunk size a bit and add a period to our separators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "65b6ce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "89c5810a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5b5ef92c-5897-4028-a28d-866605a5039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1120a99d-e53f-43d2-a5a6-78575f77a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "88f2b93e-b124-4725-9d00-714bcf1c3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_splits = rec_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b6d03f57-a196-46e5-a810-6b3a954f3630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf', 'page': 0}, page_content='MachineLearning-Lecture01  \\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is just spend a little time going over the logistics')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8df8d6",
   "metadata": {},
   "source": [
    "##### Splittovani Programovacich Jazyku - Language()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a51cc3-a01c-403c-b3f5-83a50e00d6b3",
   "metadata": {},
   "source": [
    "V p≈ô√≠padƒõ, ≈æe bychom chtƒõli pracovat nikoli s p≈ôirozen√Ωm jazykem, ale s poƒç√≠taƒçov√Ωm k√≥dem, mohou n√°m pomoci ji≈æ p≈ôedp≈ôipraven√© separ√°tory pro nƒõkolik hlavn√≠ch programovac√≠ch jazyk≈Ø. Ty z√≠sk√°me naimportov√°n√≠m *Language* z *langchain.text_splitter*. Pokud separ√°tory chceme vidƒõt, mus√≠me pou≈æ√≠t *get_separators_for_language*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ed617afb-b579-4af7-be99-2e84b283caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6a0fde4e-6531-4718-b93b-0c1d77c42b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nclass ', '\\ndef ', '\\n\\tdef ', '\\n\\n', '\\n', ' ', '']\n"
     ]
    }
   ],
   "source": [
    "print(RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21661ce-713d-49b9-8ed2-de0ae0e54fab",
   "metadata": {},
   "source": [
    "P≈ôi samotn√©m praktick√©m pou≈æit√≠ vlo≈æ√≠me *Language.PYTHON* do parametru *language* metody *from_language* (viz p≈ô√≠klad p≈ôevzat√Ω z dokumentace):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1cbbdc0c-a420-4121-b9b5-b2e38fa7005c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14e2f6",
   "metadata": {},
   "source": [
    "##### Token Text Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7282d",
   "metadata": {},
   "source": [
    "We can also split on token count explicity, if we want.\n",
    "\n",
    "This can be useful because LLMs often have context windows designated in tokens.\n",
    "\n",
    "Tokens are often ~4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0b148768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "bbb61311",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5edb2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"foo bar bazzyfoo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5081af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b24a7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b2d1fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ef6d3e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf', 'page': 0}, page_content='MachineLearning-Lecture01  \\n')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a966d887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf',\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b6e41",
   "metadata": {},
   "source": [
    "##### Context aware splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e7657",
   "metadata": {},
   "source": [
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "be1a26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7c1fa6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2990d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "36de2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "84c63563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Jim  \\nHi this is Joe')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d3c39de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}, page_content='Hi this is Lance')"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1e760",
   "metadata": {},
   "source": [
    "##### Dalsi Splittery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdddcdb",
   "metadata": {},
   "source": [
    "Viz langchain.text_splitter.\n",
    "* **MarkdownHeaderTextSplitter()**\n",
    "* **TokenTextSplitter()**\n",
    "* **SentenceTransformersTokenTextSplitter()** - Splitting textu podle tokenu\n",
    "* **NLTKTextSplitter()** - implementuje splittovani textu pomoci knihovny NLTK\n",
    "* **SpacyTextSplitter()** - implementuje splitting text pomoci Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777839d-0678-4c62-9ab3-b5774d9ffb22",
   "metadata": {},
   "source": [
    "#### Embeddings, vectorstore\n",
    "P≈ôi hled√°n√≠ odpovƒõdi na urƒçitou ot√°zku de facto hled√°me ot√°zce nejpodobnƒõj≈°√≠ fragmenty dokument≈Ø. Nicm√©nƒõ jak bychom v p≈ôirozen√©m jazyce v≈Øbec podobnost definovali? Nejpraktiƒçtƒõj≈°√≠ ≈ôe≈°en√≠ spoƒç√≠v√° v p≈ôevodu splitov√°n√≠m vyroben√Ωch fragment≈Ø dokument≈Ø na vektory (posloupnosti ƒç√≠sel). S nimi u≈æ m≈Ø≈æeme pro (ne)podobnost aplikovat klasick√Ω matematick√Ω apar√°t ala cosinov√° podobnost. Tyto vektory se ale t√©≈æ mus√≠ nƒõkam ulo≈æit. Proto mluv√≠me obecnƒõ o tzv. vector stores, p≈ôiƒçem≈æ zde budeme konkr√©tnƒõ pou≈æ√≠vat Chromu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "031a4874-ecc8-4a75-9d74-a68740c490af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e6b81c13-c1a9-47bf-b219-90e3d728ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./pomocne_soubory/podminky_debetnich_karet.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()\n",
    "\n",
    "chunk_size = 250\n",
    "chunk_overlap = 50\n",
    "\n",
    "rec_text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")\n",
    "\n",
    "rec_splits = rec_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381eaf05-1f1d-4b7d-947c-3ccd6506597e",
   "metadata": {},
   "source": [
    "Nap≈ôed specifikujeme, jak√Ω model budeme pou≈æ√≠vat pro v√Ωpoƒçet embedding≈Ø. *OpenAIEmbeddings* znamen√°, ≈æe pou≈æijeme model text-embedding-ada-002 od OpenAI. Ten p≈ôi klasick√©m pou≈æ√≠v√°n√≠ ala chatov√°n√≠ ƒçi dopl≈àov√°n√≠ textu nen√≠ tak mocn√Ω jako GPT3.5 nebo aspo≈à DaVinci. Nicm√©nƒõ p≈ôi n√°poƒçtu embedding≈Ø to zas takovou roli nehraje a naopak se hod√≠, ≈æe je tento model ≈ô√°dovƒõ levnƒõj≈°√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6eee558e-2f58-4654-85ed-e8664fe404f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1f58a723-cb3b-48b8-a389-19bf36484192",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e295e",
   "metadata": {},
   "source": [
    "Kdyz uz mame inicializovany embedding, muzeme volat na nase vety embeddingovy model a prevest cele vety na vektor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2935f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "31ff73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22608a6",
   "metadata": {},
   "source": [
    "A pomoci kosinove podobnosti pak hledat nejpodobnejsi vety:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "284753c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "928c3dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631511809630344"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7f856dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.770203137103822"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "533719e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759054062979165"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089a0ee",
   "metadata": {},
   "source": [
    "Nicmene, to by bychom museli provest pro kazdou kombinaci hledaneho vyrazu a predem embeddovanych dokumentu. To by v praxi vedlo k tomu, ze si napiseme funkci, do ktere hodime nami hledany dotaz, ktery se nasledne porovna s nejakou databazi jiz existujicich embeddovanych kusu dokumentu a vrati to $k$ nejvic podobnych dokumentu. Proto v langchain balicku vznikl vectorestore, ktery obsahuje onu databazi embeddovanych dokumentu a taky obsahuje metodu _similarity_search()_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609539d-1bb1-42d8-80c6-0eea6cd372ad",
   "metadata": {},
   "source": [
    "Pozn.: v p≈ô√≠padƒõ pr√°ce s Azure OpenAI pou≈æijeme *AzureOpenAIEmbeddings*. Mus√≠ se specifikovat deployment, ve kter√©m je nasazen√Ω model urƒçen√Ω na embeddingov√°n√≠. Takt√©≈æ je t≈ôeba nastavit *chunk_size* na jedniƒçku (jinak se objev√≠ tu≈°√≠m \"too many inputs\" chybov√° hl√°≈°ka).\n",
    "```python\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(deployment=\"deplyment_name_s_embedding_modelem\", chunk_size=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce2462-d66a-46d5-b34a-949aaa3c547b",
   "metadata": {},
   "source": [
    "Pro pou≈æit√≠ Chromy mus√≠me nap≈ôed nainstalovat odpov√≠daj√≠c√≠ bal√≠ƒçek [chromadb](https://pypi.org/project/chromadb/) (pokud se instalace nezda≈ô√≠, m√°te mo≈æn√° p≈ô√≠li≈° novou verzi Pythonu - v dobƒõ psan√≠ tƒõchto ≈ô√°dk≈Ø byla verze 3.10 ok, ale 3.12 u≈æ ne). N√°slednƒõ je pot≈ôeba prov√©st importov√°n√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8f75edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e3c534d5-abf0-47c9-87a6-14db0d70b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ffe2b-92ff-4e7d-8f4f-5b225ef896a5",
   "metadata": {},
   "source": [
    "Chroma je souborov√° datab√°ze. Mus√≠me tedy specifikovat, kam se budou jej√≠ soubory (fakticky jde o parquety) ukl√°dat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b51e8698-77d7-4ced-ac35-07205982dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_doc_dir = './embeddings/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "09234030",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./embeddings/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2a17710e-554b-4ee7-aeab-01dc689c4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=rec_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=simple_doc_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ceac1-dda0-4924-bdc7-5cf9466e7a81",
   "metadata": {},
   "source": [
    "Na n√°sleduj√≠c√≠ p≈ô√≠kaz nesm√≠me zapomenout, nebo≈• bez nƒõj by se vektory fakticky neulo≈æily na disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f4b53a83-2dcd-4a2a-9f66-0cef265ea6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/3711397106.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e7800-0d04-4ad5-9880-650f6752994b",
   "metadata": {},
   "source": [
    "Pro naƒçten√≠ ulo≈æen√Ωch embedding≈Ø se pou≈æije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "195db05b-d77c-4500-8c25-a59a1b77ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/3379508841.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=simple_doc_dir, \n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720889f2-f41e-44ba-b994-8b3793da0888",
   "metadata": {},
   "source": [
    "V bƒõ≈æn√©m provozu asi nebudeme n√°sleduj√≠c√≠ p≈ô√≠kazy krom obƒçasn√Ωch kontrol pot≈ôebovat. Nicm√©nƒõ ne v≈ædy se ƒçlovƒõk v bƒõ≈æn√©m provozu pohybuje...  \n",
    "Pro poƒçet z√°znam≈Ø v konkr√©tn√≠m vectorstoru pou≈æijeme metodu *\\_collection.count*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a3114732-f64e-4fc7-8534-ff2185b676fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcad8d4-981d-4599-9fa5-f8d8f197b4d4",
   "metadata": {},
   "source": [
    "Metoda *peek* uk√°≈æe nƒõkolik prvn√≠ch z√°znam≈Ø (poƒçet je specifikov√°n parametrem *limit*, p≈ôiƒçem≈æ defaultn√≠ hodnota m√° velikost 10).\n",
    "```\n",
    "vectordb._collection.peek(limit=3)\n",
    "```\n",
    "V√Ωstup metody nen√≠ z nejmen≈°√≠ch, proto ho zde v surov√© podobƒõ neukazujeme. Jedn√° se o slovn√≠k, ve kter√©m jsou postupnƒõ tyto kl√≠ƒçe a hodnoty:\n",
    "- ids s listem idƒçek jednotliv√Ωch fragment≈Ø dokument≈Ø  \n",
    "- embeddings s listem vektor≈Ø (alias list≈Ø float≈Ø), ve kter√©ch jsou fragmenty dokument≈Ø zak√≥dovan√©  \n",
    "- metadatas s listem metadat, kter√° nab√Ωvaj√≠ podoby slovn√≠k≈Ø s kl√≠ƒçi \"page\" a \"source\"\n",
    "- documents s listem samotn√Ωch fragment≈Ø dokument≈Ø v textov√© podobƒõ\n",
    "```\n",
    "{'ids': ['a737d8ec-39ea-11ee-8841-80ce622bc396',\n",
    "  'a73b7183-39ea-11ee-a74a-80ce622bc396',\n",
    "  'a73b7184-39ea-11ee-bd3c-80ce622bc396'],\n",
    " 'embeddings': [[0.0016977092018350959,\n",
    "   -0.013771715573966503,\n",
    "   0.0062872255221009254,\n",
    "   ....\n",
    "   ....\n",
    "   -0.0042107910849153996,\n",
    "   -0.027450013905763626,\n",
    "   -0.02284945175051689,\n",
    "   0.06665701419115067,\n",
    "   ...]],\n",
    " 'metadatas': [{'page': 0,\n",
    "   'source': 'source_files\\\\podminky_debetnich_karet.pdf'},\n",
    "  {'page': 0, 'source': 'source_files\\\\podminky_debetnich_karet.pdf'},\n",
    "  {'page': 0, 'source': 'source_files\\\\podminky_debetnich_karet.pdf'}],\n",
    " 'documents': ['PODM√çNKY D EBETN√çCH KARET   \\n \\n \\n \\n \\nKomerƒçn√≠ bank a, a. s., se s√≠dlem:  \\nPraha 1, Na P≈ô√≠ kopƒõ 33 ƒçp. 969, PSƒå 114 07, IƒåO: 45317054  \\nZAPSAN √Å V OBCHODN√çM REJST≈ò√çKU VEDEN√âM MƒöSTSK√ùM SOUDEM V PRAZE, ODD√çL B, VLO≈ΩKA 1 360 1/10',\n",
    "  'VER DDT_ PODMPKEV.PDF \\n Tyto Podm√≠nky debetn√≠ch karet obsahuj√≠ bli≈æ≈°√≠ √∫pravu pr√°v a povinnost√≠ vypl√Ωvaj√≠c√≠ch z  uzav≈ôen√© smlouvy, na z√°kladƒõ',\n",
    "  'kter√© je poskytnuta  debetn√≠ karta v  souladu s  pravidly p≈ô√≠slu≈°n√© Karetn√≠ spoleƒçnosti.  Seznamte se pros√≠m d≈Økladnƒõ \\ns t√≠mto dokumentem. Va≈°e p ≈ô√≠padn√© dotazy r√°di zodpov√≠me.  \\n \\nƒål√°nek 1. Poskytnut√≠  debetn√≠ karty a jej√≠ obnova']}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2edb80d-5f80-40f5-a92f-c4dc8885f455",
   "metadata": {},
   "source": [
    "Metoda get (v√Ωsledek je stejn√Ω pro *get* i pro *\\_collection.get*) slou≈æ√≠ k z√≠sk√°n√≠ buƒèto nƒõkter√Ωch z√°znam≈Ø (to tehdy, kdy≈æ do parametru ids vlo≈æ√≠me string ƒçi list string≈Ø s idƒçky) anebo v≈°ech z√°znam≈Ø (kdy≈æ idƒçka nespecifikujeme; poƒçet vr√°cen√Ωch fragment≈Ø lze omezit parametrem *limit*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2adb91c1-afc5-4f11-b2cb-8c5bb54d3721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.get(ids=\"a73b7184-39ea-11ee-bd3c-80ce622bc396\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dde3c5-2f3c-4878-83dc-7a7705f98ff8",
   "metadata": {},
   "source": [
    "Defaultnƒõ se v odpovƒõdi neobjev√≠ embeddingy. Toto chov√°n√≠ je ≈ô√≠zen√© parametrem *include*, kter√Ω defaultnƒõ obsahuje [\"metadatas\", \"documents\"]. Tud√≠≈æ pokud chceme embeddingy, mus√≠me je do listu explicitnƒõ p≈ôidat.\n",
    "```\n",
    "vectordb.get(\n",
    "    ids=\"a73b7184-39ea-11ee-bd3c-80ce622bc396\",\n",
    "    include=[\"metadatas\", \"documents\", \"embeddings\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ff5aa-7181-44a3-aece-90e4c5571640",
   "metadata": {},
   "source": [
    "Pokud chceme realizovat filtrov√°n√≠ na z√°kladƒõ metadat, mus√≠me pou≈æ√≠t parametr *where*. Do nƒõj vlo≈æ√≠me slovn√≠k, kde kl√≠ƒçem bude \"page\" nebo \"source\" a hodnotou ƒç√≠slo str√°nky ƒçi zdrojov√Ω soubor>\n",
    "```\n",
    "vectordb.get(where={\"page\": 0})\n",
    "```\n",
    "```\n",
    "vectordb.get(where={\"source\": \"source_files\\\\podminky_debetnich_karet.pdf\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf2b5c-bbb7-46d8-9cdc-69273e745fc0",
   "metadata": {},
   "source": [
    "Pro z√≠sk√°v√°n√≠ nejpodobnƒõj≈°√≠ch dokument≈Ø vstupn√≠mu textu sice slou≈æ√≠ metoda *query* s parametrem *query_texts*, nicm√©nƒõ my v praxi budeme sp√≠≈°e pou≈æ√≠vat langchainovou nadstavbu nad touto metodou."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57deb410-67c5-4716-9d44-4d7158ee0e7c",
   "metadata": {},
   "source": [
    "Co mus√≠me udƒõlat, kdy≈æ chceme nƒõkter√Ω ze z√°znam≈Ø updatovat? Vezmƒõme si n√°hodnƒõ fragment i idƒçkem \"a73b7184-39ea-11ee-bd3c-80ce622bc396\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7f138cd9-75d5-440d-8c91-b8b8805807ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_fragment = vectordb.get(ids=\"a73b7184-39ea-11ee-bd3c-80ce622bc396\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c0a46-5c05-4d3f-b11c-9b0b0c8c27c6",
   "metadata": {},
   "source": [
    "Jeho metadata vypadaj√≠ takto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "16ce3dfd-10c9-42a0-9646-c1037cb997fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_fragment[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000fa92b-730b-46d0-8f44-9f05f38bc207",
   "metadata": {},
   "source": [
    "Nyn√≠ metadata p≈ôep√≠≈°eme - p≈ôid√°me dal≈°√≠ pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8ab5eb26-c33e-4ea7-9994-48e0ffbd9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_fragment[\"metadatas\"] = [{\n",
    "    'page': 0, \n",
    "    'source': 'source_files\\\\podminky_debetnich_karet.pdf',\n",
    "    \"some_info\": \"Terms of use of debit cards\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff86c6-d3e1-4c9e-b59e-afe70c3decf8",
   "metadata": {},
   "source": [
    "Provedeme *update* stejnejmennou metodou (bacha, mus√≠ to b√Ωt v *\\_collection* - *vectordb.update* se vztahuje na objekty typu *Document*). Prvn√≠m parametrem je idƒçko, pot√© zde m√°me parametr *metadatas*, do kter√©ho vlo≈æ√≠me nov√° metadata. Mohl by tu b√Ωt i parametr embeddings (pro update embedding≈Ø) ƒçi documents (pro √∫pravu samotn√Ωch text≈Ø)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a73608c4-42d2-413a-8226-d76dc9293fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Update of nonexisting embedding ID: a73b7184-39ea-11ee-bd3c-80ce622bc396\n"
     ]
    }
   ],
   "source": [
    "vectordb._collection.update(\"a73b7184-39ea-11ee-bd3c-80ce622bc396\", metadatas=some_fragment[\"metadatas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61657c-a501-4a1b-9e46-862a2a3253ad",
   "metadata": {},
   "source": [
    "Update se opravdu provedl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "868233ff-a367-4ae5-bc65-1244ae077340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.get(ids=\"a73b7184-39ea-11ee-bd3c-80ce622bc396\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94577ede-7839-48dd-90f3-31bb0f741a8b",
   "metadata": {},
   "source": [
    "P≈ôiƒçem≈æ zbyl√© z√°znamy z≈Øst√°vaj√≠ touto operac√≠ neposti≈æen√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "96af7661-214f-4aa4-827d-c2332322109d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents']}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.get(ids=\"a73b7183-39ea-11ee-a74a-80ce622bc396\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52dd5b7-492a-446c-a23e-272eab415f90",
   "metadata": {},
   "source": [
    "Nakonec nesm√≠me zapomenout na ulo≈æen√≠ zmƒõn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f0edd5bd-3679-4fcf-9349-65ff8265ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645d59f-4cdf-497d-8039-87aba5babff6",
   "metadata": {},
   "source": [
    "Podobn√Ωm zp≈Øsobem by prob√≠halo i maz√°n√≠ z√°znam≈Ø, kdy bychom pou≈æili metodu *delete*:\n",
    "```\n",
    "vectordb._collection.delete(ids=\"a73b7183-39ea-11ee-a74a-80ce622bc396\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ab4f4",
   "metadata": {},
   "source": [
    "##### VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedf97e",
   "metadata": {},
   "source": [
    "Jiny vector store, ktery stoji za zminku je DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3ef3060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3375050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "file = 'OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f88eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_replacement_model = OpenAI(temperature=0, \n",
    "                               model='gpt-3.5-turbo-instruct')\n",
    "\n",
    "response = index.query(query, \n",
    "                       llm = llm_replacement_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10544d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e51244",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd457f3-ccf6-4113-8562-8292a990334a",
   "metadata": {},
   "source": [
    "#### Similarity search\n",
    "≈òekli jsme si, ≈æe metodu *query* na hled√°n√≠ podobnosti dokument≈Ø pou≈æ√≠vat nebudeme. Co ale m√≠sto n√≠ m√°me k dispozici?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7adf4d78-ad11-4fe3-9ec4-44baf1eb495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Jak dlouho debentn√≠ karta plat√≠?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f61fcd-7387-4b53-9565-cffbafce3139",
   "metadata": {},
   "source": [
    "Metoda *similarity_search* vyhled√°v√° *k* nejpodobnƒõj≈°√≠ch fragment≈Ø dokument≈Ø k dokumentu vlo≈æen√©mu do parametru *query*. Zalo≈æen√° je na poƒç√≠t√°n√≠ cosinov√© podobnosti mezi vektory fragment≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d68b63e5-6073-449e-965f-4d161ba2acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sim_docs = vectordb.similarity_search(query=question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8b030301-9785-4ebd-8853-824e89072203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='1.6 Platnost. Debetn√≠ k artu lze pou≈æ√≠vat do posledn√≠ho dne mƒõs√≠ce a roku doby platnosti na n√≠ uveden√©. \\nPou≈æit√≠m obnoven√© karty dle ƒçl. 1.8 Podm√≠nek konƒç√≠ platnost karty p≈Øvodn√≠ bez ohledu na p≈ôedchoz√≠ vƒõtu.'),\n",
       " Document(metadata={'page': 1, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='3.2 Vr√°cen√≠ roƒçn√≠ ceny.  Z√°nikem debetn√≠ karty p≈ôed uplynut√≠m doby jej√≠ platnosti  v√°m nevznik√° n√°rok na \\nvr√°cen√≠ z√∫ƒçtovan√© roƒçn√≠ ceny za jej√≠ pou≈æ√≠v√°n√≠.'),\n",
       " Document(metadata={'page': 1, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='Sazebn√≠ku. Roƒçn√≠ poplatek plat√≠te p≈ôedem a √∫ƒçtujeme je j nejd≈ô√≠ve 30. kalend√°≈ôn√≠ den  po sjedn√°n√≠ karty. \\nV dal≈°√≠ch letech po dobu platnosti karty je cena splatn√° ka≈ædoroƒçnƒõ ve stejn√Ω den a mƒõs√≠c. Mƒõs√≠ƒçn√≠ poplatek')]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_sim_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2a622f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simple_sim_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0c78720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6 Platnost. Debetn√≠ k artu lze pou≈æ√≠vat do posledn√≠ho dne mƒõs√≠ce a roku doby platnosti na n√≠ uveden√©. \\nPou≈æit√≠m obnoven√© karty dle ƒçl. 1.8 Podm√≠nek konƒç√≠ platnost karty p≈Øvodn√≠ bez ohledu na p≈ôedchoz√≠ vƒõtu.'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_sim_docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7706efa-3e9d-485b-ad58-d2d8e78b3a9a",
   "metadata": {},
   "source": [
    "Lze do n√≠ p≈ôidat i parametr *filter*, kter√Ω se hod√≠ pro omezen√≠ mno≈æiny, ve kter√© se podobn√© framenty hledaj√≠, a to sice na z√°kladƒõ metadat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "4c745af6-7efb-48e7-bbf2-faecf99f1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_sim_docs = vectordb.similarity_search(\n",
    "    query=question,\n",
    "    k=3,\n",
    "    filter={\"page\":0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "da743cf4-25f7-4ecd-a7d5-ba5e6ffa18eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='1.6 Platnost. Debetn√≠ k artu lze pou≈æ√≠vat do posledn√≠ho dne mƒõs√≠ce a roku doby platnosti na n√≠ uveden√©. \\nPou≈æit√≠m obnoven√© karty dle ƒçl. 1.8 Podm√≠nek konƒç√≠ platnost karty p≈Øvodn√≠ bez ohledu na p≈ôedchoz√≠ vƒõtu.'),\n",
       " Document(metadata={'page': 0, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='platnosti pou≈æita, nejsme povinni ji obnovit. \\n1.9 Neposkytnut√≠ nov√© debetn√≠ karty. Nem√°-li Dr≈æitel z√°jem o poskytnut√≠ nov√© debetn√≠ karty dle  ƒçl. 1.8'),\n",
       " Document(metadata={'page': 0, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='1.1 ≈Ω√°dost o debetn√≠ kartu. O poskytnut√≠ debetn√≠ karty m≈Ø≈æete po≈æ√°dat pro sebe nebo pro kteroukoli  t≈ôet√≠ \\nosobu. V  od≈Øvodnƒõn√Ωch p≈ô√≠padech jsme opr√°vnƒõni va≈° i ≈æ√°dost odm√≠t nout a po≈æadovanou kartu')]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_sim_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4323089e",
   "metadata": {},
   "source": [
    "Nebo jiny hypoteticky priklad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "42d99e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are some movies about aliens made in 1980?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e380321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alien_docs = vectordb.similarity_search(\n",
    "    query=question,\n",
    "    k=3,\n",
    "    filter={\"year\":1980}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a78e5-3dc4-4591-97d3-6316c7012d92",
   "metadata": {},
   "source": [
    "Metoda *similarity_search* u vr√°cen√Ωch fragment≈Ø neukazuje, jak moc jsou dokumentu v *query* podobn√©. Tuto informaci m≈Ø≈æeme ale dostat s metodou *similarity_search_with_score* - ta vrac√≠ velikost cosinov√© podobnosti, tj. men≈°√≠ ƒç√≠slo je lep≈°√≠ a nejlep≈°√≠ je 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0b8a6604-34d5-41cd-8d53-1877e8d95fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'page': 6, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='7/10 \\nVER DDT_PODMPKEV.PDF \\n \\nƒål√°nek 8. Ztr√°ta, odcizen√≠, zadr≈æen√≠ debetn√≠ karty v bankomatu \\n \\n8.1 Oznamovac√≠ povinnost Dr≈æitele . V p≈ô√≠padƒõ ztr√°ty, odcizen√≠ nebo zneu≈æ it√≠ debetn√≠ karty nebo mobiln√≠ho'),\n",
       "  0.6371698975563049),\n",
       " (Document(metadata={'page': 4, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='podpisu protokol u o rekl amaci. Reklamace t√Ωkaj√≠c√≠ se tr ansakce platebn√≠ kartou za zbo≈æ√≠ nebo slu≈æby \\nposkytnut√© t≈ôet√≠ stranou prost≈ôednictv√≠m internetu nebo p≈ô√≠mo v obchodn√≠m m√≠stƒõ mus√≠ b√Ωt p≈ôi nespolupr√°ci'),\n",
       "  0.6413229703903198),\n",
       " (Document(metadata={'page': 4, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='neuplatn√≠te reklamaci do 30 Obchodn√≠ch dn≈Ø od doruƒçen√≠ zpr√°v o z√∫ƒçtov√°n√≠ (v√Ωpis≈Ø), ve kter√Ωch byla nebo \\nmƒõla b√Ωt  reklamovan√° transa kce uved ena, ani≈æ by v√°m v tom br√°nily d≈Øvody hodn√© zvl√°≈°tn√≠h o z≈ôetele,'),\n",
       "  0.6418606042861938)]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_score_docs = vectordb.similarity_search_with_score(query=question,k=3)\n",
    "sim_score_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17345ec0-dbe8-422e-9f3d-6193b786da49",
   "metadata": {},
   "source": [
    "Podobnƒõ funguje *similarity_search_with_relevance_scores*, pouze je cosinov√° podobnost p≈ôepoƒç√≠t√°na na relevance score. To se nal√©z√° v uzav≈ôen√©m intervalu mezi 0 a 1, p≈ôiƒçem≈æ 0 jsou zcela nepodobn√© dokumenty, zat√≠mco 1 maj√≠ zcela identick√© dokumenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c5160c03-35de-4d50-b388-6c4f550c7807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'page': 6, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='7/10 \\nVER DDT_PODMPKEV.PDF \\n \\nƒål√°nek 8. Ztr√°ta, odcizen√≠, zadr≈æen√≠ debetn√≠ karty v bankomatu \\n \\n8.1 Oznamovac√≠ povinnost Dr≈æitele . V p≈ô√≠padƒõ ztr√°ty, odcizen√≠ nebo zneu≈æ it√≠ debetn√≠ karty nebo mobiln√≠ho'),\n",
       "  0.549452844669999),\n",
       " (Document(metadata={'page': 4, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='podpisu protokol u o rekl amaci. Reklamace t√Ωkaj√≠c√≠ se tr ansakce platebn√≠ kartou za zbo≈æ√≠ nebo slu≈æby \\nposkytnut√© t≈ôet√≠ stranou prost≈ôednictv√≠m internetu nebo p≈ô√≠mo v obchodn√≠m m√≠stƒõ mus√≠ b√Ωt p≈ôi nespolupr√°ci'),\n",
       "  0.5465161787063055),\n",
       " (Document(metadata={'page': 4, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='neuplatn√≠te reklamaci do 30 Obchodn√≠ch dn≈Ø od doruƒçen√≠ zpr√°v o z√∫ƒçtov√°n√≠ (v√Ωpis≈Ø), ve kter√Ωch byla nebo \\nmƒõla b√Ωt  reklamovan√° transa kce uved ena, ani≈æ by v√°m v tom br√°nily d≈Øvody hodn√© zvl√°≈°tn√≠h o z≈ôetele,'),\n",
       "  0.5461360141327372)]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_rel_score_docs = vectordb.similarity_search_with_relevance_scores(query=question,k=3)\n",
    "sim_rel_score_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad7e48-39c2-4215-a5e8-4b0885bf15c0",
   "metadata": {},
   "source": [
    "Na ponƒõkud odli≈°n√©m principu funguje *max_marginal_relevance_search* (MMR). Tato metoda se sna≈æ√≠ souƒçasnƒõ optimalizovat podobnost a diverzitu dokument≈Ø. To v praxi znamen√°, ≈æe najde na z√°kladƒõ cosinov√© podobnosti *fetch_k* fragment≈Ø (defaultnƒõ 20). Pot√© je ale se≈ôad√≠ tak, ≈æe penalizuje podobn√© ƒçi dokonce identick√© dokumenty a z nov√©ho ≈ôazen√≠ vr√°t√≠ *k* fragment≈Ø (defaultnƒõ 4). Bohu≈æel zd√° se, ≈æe ≈æ√°dn√© ƒç√≠slo kvantifikuj√≠c√≠ podobnost ƒçi kvalitu v√Ωbƒõru nen√≠ ve funkci dostupn√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "cca412e6-7d5b-4706-88c2-04f91432ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 6, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='7/10 \\nVER DDT_PODMPKEV.PDF \\n \\nƒål√°nek 8. Ztr√°ta, odcizen√≠, zadr≈æen√≠ debetn√≠ karty v bankomatu \\n \\n8.1 Oznamovac√≠ povinnost Dr≈æitele . V p≈ô√≠padƒõ ztr√°ty, odcizen√≠ nebo zneu≈æ it√≠ debetn√≠ karty nebo mobiln√≠ho'),\n",
       " Document(metadata={'page': 4, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='neuplatn√≠te reklamaci do 30 Obchodn√≠ch dn≈Ø od doruƒçen√≠ zpr√°v o z√∫ƒçtov√°n√≠ (v√Ωpis≈Ø), ve kter√Ωch byla nebo \\nmƒõla b√Ωt  reklamovan√° transa kce uved ena, ani≈æ by v√°m v tom br√°nily d≈Øvody hodn√© zvl√°≈°tn√≠h o z≈ôetele,'),\n",
       " Document(metadata={'page': 7, 'source': './pomocne_soubory/podminky_debetnich_karet.pdf'}, page_content='Secure hesla ƒçi p≈ôihla≈°ovac√≠ch √∫daj≈Ø v p≈ô√≠padƒõ metody pro vytv√°≈ôen√≠ el ektronick√©ho podpisu, kterou jsme \\nv√°m vydali na z√°kladƒõ Smlou vy o elektronick√©m podpisu, pro √∫ƒçely 3D Secure autorizace jin√© osobƒõ nebo')]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_relev_docs = vectordb.max_marginal_relevance_search(query=question,k=3, fetch_k=20)\n",
    "max_relev_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5330fa64-5b93-4c4f-bf81-853b2855ef49",
   "metadata": {},
   "source": [
    "Specialitou je pou≈æit√≠ komprese na v√Ωstupn√≠ch fragmentech. Fragmenty mohou toti≈æ obsahovat znaƒçn√© mno≈æstv√≠ informac√≠ pro urƒçit√Ω dotaz nerelevantn√≠ch. U≈æiteƒçn√© informace se potom v z√°plavƒõ zbyteƒçnost√≠ snadno ztrat√≠. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b518dd81-b07d-45f6-a75d-da2e0aab1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c2cd69-c087-418c-acfa-0b9d07057ef5",
   "metadata": {},
   "source": [
    "Abychom vidƒõli, co Langchain dƒõl√°, zapneme debugov√°n√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "6341e36f-38bc-4e47-b664-7c26668b4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d682b44-9ba4-445d-89a4-2da035b0508e",
   "metadata": {},
   "source": [
    "Samotnou kompresi (ƒçi p≈ôesnƒõji osek√°v√°n√≠ zbyteƒçn√Ωch slov) realizuje fakticky jazykov√Ω model, mus√≠me tud√≠≈æ vytvo≈ôi jeho instanci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "91e75ed3-91c7-4625-a190-21855878f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4291967-b73b-43d7-bcf6-91d57194f4ce",
   "metadata": {},
   "source": [
    "N√°slednƒõ vytvo≈ô√≠me samotn√Ω kompresor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b5787b6f-8b6b-4019-9e0a-39d915cf79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d44e08-0ac3-4752-8979-957e1189a63e",
   "metadata": {},
   "source": [
    "Na nƒõm provol√°me metodu *get_relevant_documents*. Bohu≈æel jsem nep≈ôi≈°el na to, jak specifikovat poƒçet vr√°cen√Ωch fragment≈Ø (parametr *k* nefunguje), tak≈æe se vrac√≠ defaultn√≠ 4.  \n",
    "\"Kompresi\" zaji≈°≈•uje n√°sleduj√≠c√≠ prompt:\n",
    "```\n",
    "Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: Jak dlouho debentn√≠ karta plat√≠?\\n> Context:\\n>>>\\nplat√≠te  p≈ôedem a  √∫ƒçtujeme  jej nejd≈ô√≠ve 5.  obchodn√≠ den  po sjedn√°n√≠ karty. V dal≈°√≠ch mƒõs√≠c√≠ch  po dobu \\nplatnosti karty  je cena splatn√°  ve stejn√Ω den . Pokud den splatnosti p≈ôipa dne na den, kter√Ω nen√≠ Obchodn√≠m\\n>>>\\nExtracted relevant parts:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ce5ab7b9-177d-42e3-803a-693e9d672963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/2882351278.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  compressed_docs = compression_retriever.get_relevant_documents(query=question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are some movies about aliens made in 1980?\",\n",
      "  \"context\": \"7/10 \\nVER DDT_PODMPKEV.PDF \\n \\nƒål√°nek 8. Ztr√°ta, odcizen√≠, zadr≈æen√≠ debetn√≠ karty v bankomatu \\n \\n8.1 Oznamovac√≠ povinnost Dr≈æitele . V p≈ô√≠padƒõ ztr√°ty, odcizen√≠ nebo zneu≈æ it√≠ debetn√≠ karty nebo mobiln√≠ho\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are some movies about aliens made in 1980?\",\n",
      "  \"context\": \"7/10 \\nVER DDT_PODMPKEV.PDF \\n \\nƒål√°nek 8. Ztr√°ta, odcizen√≠, zadr≈æen√≠ debetn√≠ karty v bankomatu \\n \\n8.1 Oznamovac√≠ povinnost Dr≈æitele . V p≈ô√≠padƒõ ztr√°ty, odcizen√≠ nebo zneu≈æ it√≠ debetn√≠ karty nebo mobiln√≠ho\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: What are some movies about aliens made in 1980?\\n> Context:\\n>>>\\n7/10 \\nVER DDT_PODMPKEV.PDF \\n \\nƒål√°nek 8. Ztr√°ta, odcizen√≠, zadr≈æen√≠ debetn√≠ karty v bankomatu \\n \\n8.1 Oznamovac√≠ povinnost Dr≈æitele . V p≈ô√≠padƒõ ztr√°ty, odcizen√≠ nebo zneu≈æ it√≠ debetn√≠ karty nebo mobiln√≠ho\\n>>>\\nExtracted relevant parts:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > llm:ChatOpenAI] [565ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"NO_OUTPUT\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"NO_OUTPUT\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 181,\n",
      "                \"total_tokens\": 184,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a12cb28b-4576-465f-aeb8-060d6ec8ad21-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 181,\n",
      "              \"output_tokens\": 3,\n",
      "              \"total_tokens\": 184\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 181,\n",
      "      \"total_tokens\": 184,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > parser:NoOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > parser:NoOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence] [567ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are some movies about aliens made in 1980?\",\n",
      "  \"context\": \"podpisu protokol u o rekl amaci. Reklamace t√Ωkaj√≠c√≠ se tr ansakce platebn√≠ kartou za zbo≈æ√≠ nebo slu≈æby \\nposkytnut√© t≈ôet√≠ stranou prost≈ôednictv√≠m internetu nebo p≈ô√≠mo v obchodn√≠m m√≠stƒõ mus√≠ b√Ωt p≈ôi nespolupr√°ci\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are some movies about aliens made in 1980?\",\n",
      "  \"context\": \"podpisu protokol u o rekl amaci. Reklamace t√Ωkaj√≠c√≠ se tr ansakce platebn√≠ kartou za zbo≈æ√≠ nebo slu≈æby \\nposkytnut√© t≈ôet√≠ stranou prost≈ôednictv√≠m internetu nebo p≈ô√≠mo v obchodn√≠m m√≠stƒõ mus√≠ b√Ωt p≈ôi nespolupr√°ci\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: What are some movies about aliens made in 1980?\\n> Context:\\n>>>\\npodpisu protokol u o rekl amaci. Reklamace t√Ωkaj√≠c√≠ se tr ansakce platebn√≠ kartou za zbo≈æ√≠ nebo slu≈æby \\nposkytnut√© t≈ôet√≠ stranou prost≈ôednictv√≠m internetu nebo p≈ô√≠mo v obchodn√≠m m√≠stƒõ mus√≠ b√Ωt p≈ôi nespolupr√°ci\\n>>>\\nExtracted relevant parts:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > llm:ChatOpenAI] [364ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"NO_OUTPUT\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"NO_OUTPUT\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 176,\n",
      "                \"total_tokens\": 179,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bf0c0ad6-8ede-4d7b-8b31-df0d6ce2a2d2-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 176,\n",
      "              \"output_tokens\": 3,\n",
      "              \"total_tokens\": 179\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 176,\n",
      "      \"total_tokens\": 179,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > parser:NoOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > parser:NoOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence] [365ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are some movies about aliens made in 1980?\",\n",
      "  \"context\": \"neuplatn√≠te reklamaci do 30 Obchodn√≠ch dn≈Ø od doruƒçen√≠ zpr√°v o z√∫ƒçtov√°n√≠ (v√Ωpis≈Ø), ve kter√Ωch byla nebo \\nmƒõla b√Ωt  reklamovan√° transa kce uved ena, ani≈æ by v√°m v tom br√°nily d≈Øvody hodn√© zvl√°≈°tn√≠h o z≈ôetele,\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are some movies about aliens made in 1980?\",\n",
      "  \"context\": \"neuplatn√≠te reklamaci do 30 Obchodn√≠ch dn≈Ø od doruƒçen√≠ zpr√°v o z√∫ƒçtov√°n√≠ (v√Ωpis≈Ø), ve kter√Ωch byla nebo \\nmƒõla b√Ωt  reklamovan√° transa kce uved ena, ani≈æ by v√°m v tom br√°nily d≈Øvody hodn√© zvl√°≈°tn√≠h o z≈ôetele,\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: What are some movies about aliens made in 1980?\\n> Context:\\n>>>\\nneuplatn√≠te reklamaci do 30 Obchodn√≠ch dn≈Ø od doruƒçen√≠ zpr√°v o z√∫ƒçtov√°n√≠ (v√Ωpis≈Ø), ve kter√Ωch byla nebo \\nmƒõla b√Ωt  reklamovan√° transa kce uved ena, ani≈æ by v√°m v tom br√°nily d≈Øvody hodn√© zvl√°≈°tn√≠h o z≈ôetele,\\n>>>\\nExtracted relevant parts:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > llm:ChatOpenAI] [403ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"NO_OUTPUT\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"NO_OUTPUT\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 181,\n",
      "                \"total_tokens\": 184,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-0693ee0f-d84b-49f4-970d-a8c80731320b-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 181,\n",
      "              \"output_tokens\": 3,\n",
      "              \"total_tokens\": 184\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 181,\n",
      "      \"total_tokens\": 184,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > parser:NoOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > parser:NoOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence] [405ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are some movies about aliens made in 1980?\",\n",
      "  \"context\": \"9/10 \\nVER DDT_PODMPKEV.PDF \\n \\n10.4 Ochrana mobiln√≠ho za≈ô√≠zen√≠. Pokud vyu≈æ√≠v√°te sv√© mobiln√≠ za≈ô√≠zen√≠ jako Digit√°ln√≠ kartu nebo pro autorizaci\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are some movies about aliens made in 1980?\",\n",
      "  \"context\": \"9/10 \\nVER DDT_PODMPKEV.PDF \\n \\n10.4 Ochrana mobiln√≠ho za≈ô√≠zen√≠. Pokud vyu≈æ√≠v√°te sv√© mobiln√≠ za≈ô√≠zen√≠ jako Digit√°ln√≠ kartu nebo pro autorizaci\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Given the following question and context, extract any part of the context *AS IS* that is relevant to answer the question. If none of the context is relevant return NO_OUTPUT. \\n\\nRemember, *DO NOT* edit the extracted parts of the context.\\n\\n> Question: What are some movies about aliens made in 1980?\\n> Context:\\n>>>\\n9/10 \\nVER DDT_PODMPKEV.PDF \\n \\n10.4 Ochrana mobiln√≠ho za≈ô√≠zen√≠. Pokud vyu≈æ√≠v√°te sv√© mobiln√≠ za≈ô√≠zen√≠ jako Digit√°ln√≠ kartu nebo pro autorizaci\\n>>>\\nExtracted relevant parts:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > llm:ChatOpenAI] [311ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"NO_OUTPUT\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"NO_OUTPUT\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 145,\n",
      "                \"total_tokens\": 148,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ea1ff41f-5385-46a0-b70b-05695e9ad77c-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 145,\n",
      "              \"output_tokens\": 3,\n",
      "              \"total_tokens\": 148\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 145,\n",
      "      \"total_tokens\": 148,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > parser:NoOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence > parser:NoOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[retriever:ContextualCompressionRetriever > chain:RunnableSequence] [312ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "7d6cff82-0c66-4dc5-bcba-636e92f24466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "aef57b7b-085c-4878-92c7-7b266fb5aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898c662",
   "metadata": {},
   "source": [
    "Combinovani metod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0559811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "3e14fa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "print(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a35e21",
   "metadata": {},
   "source": [
    "#### Potencialni problemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b5895",
   "metadata": {},
   "source": [
    "Jeden z problemu, se kterym se muzeme setkat je duplicita informaci. Dejme tomu, ze budeme mit mezi zdroji dat k RAGu jiz existujici zdroj a / nebo velmi podobny zdroj, ktery bude obsahovat vice stejnych kusu informace. Kdybychom pak chteli najit mezi temi chunky $k$ nejvice podobnych fragmentu dokumentu k nami polozenemu dotazu, muze se stat, ze vsech $k$ fragmentu bude totoznych a tudiz je nam takovy vysledek ne uplne uzitecny. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c49d3595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MachineLearning-Lecture01.pdf']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./source_notebooks/langchain/Chat With LLM/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "40d7eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"./source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f69a686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "cef87187",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f5e51663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "9bd1135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './LangChain/Chat With LLM/docs/chroma/'\n",
    "!rm -rf ./LangChain/Chat With LLM/docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d3bd0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e5f2b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8f51af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e957d8f",
   "metadata": {},
   "source": [
    "Je to dano tim, ze na tenhle dotaz bylo nalezeno $k$ super podobnych fragmentu dokumentu v ruznych souborech. A protoze similarity search nevynucuje diverzitu, vrati je vsechny. Proto existuje metoda _max_marginal_relevance_search()_ o ktere jsme mluvili pred chvili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "10a52736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 8, 'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of ‚Äî I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also ‚Äî [inaudible] \\nwrite that down [inaudible] MATLAB ‚Äî there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d0bcd8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 8, 'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of ‚Äî I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also ‚Äî [inaudible] \\nwrite that down [inaudible] MATLAB ‚Äî there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d6c78",
   "metadata": {},
   "source": [
    "Jiny problem je vynucovani pouzivani metadat. Nasledujici dotaz se pta na treti lekci, ale odpoved bude i z jinych fragmentu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c5998fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3e39eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ea264e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 8, 'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': './source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1a627a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.  \n",
      "Later in this quarter, we'll also use the discussion sections to go over extensions for the \n",
      "material that I'm teaching in the main lectures. So machine learning is a huge field, and \n",
      "there are a few extensions that we really want to teach but didn't have time in the main \n",
      "lectures for.\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460e582",
   "metadata": {},
   "source": [
    "#### Jine typy retrievalu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eacf0b",
   "metadata": {},
   "source": [
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b859c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ec6dd358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"./source_notebooks/langchain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "fa71f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "601e8fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"Testing, testing. Okay, cool. Thanks.   So all right, online resources. The class has a home page, so it's in on the handouts. I \\nwon't write on the chalkboard ‚Äî http:// cs229.stanford.edu. And so when there are \\nhomework assignments or things like that, we usually won't sort of ‚Äî in the mission of \\nsaving trees, we will usually not give out many handouts in class. So homework \\nassignments, homework solutions will be posted online at the course home page.  \\nAs far as this class, I've also written, and I guess I've also revised every year a set of \\nfairly detailed lecture notes that cover the technical content of this class. And so if you \\nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \\nall the math and equations and so on that I'll be doing in class.  \\nThere's also a newsgroup, su.class.cs229, also written on the handout. This is a \\nnewsgroup that's sort of a forum for people in the class to get to know each other and \\nhave whatever discussions you want to have amongst yourselves. So the class newsgroup \\nwill not be monitored by the TAs and me. But this is a place for you to form study groups \\nor find project partners or discuss homework problems and so on, and it's not monitored \\nby the TAs and me. So feel free to talk trash about this class there.  \\nIf you want to contact the teaching staff, please use the email address written down here, \\ncs229-qa@cs.stanford.edu. This goes to an account that's read by all the TAs and me. So\")"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "070cd0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"yourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \\nwith us.  \\nOkay. So one more organizational question. I'm curious, how many of you know \\nMATLAB? Wow, cool, quite a lot. Okay. So as part of the ‚Äî act ually how many of you \\nknow Octave or have used Octave? Oh, okay, much smaller number.  \\nSo as part of this class, especially in the homeworks, we'll ask you to implement a few \\nprograms, a few machine learning algorithms as part of the homeworks. And most of  those homeworks will be done in either MATLAB or in Octave, which is sort of ‚Äî I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn't.  \\nSo I guess for those of you that haven't seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon't have a MATLAB license, for the purposes of this class, there's also ‚Äî [inaudible] \\nwrite that down [inaudible] MATLAB ‚Äî there' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it's free, and for the purposes of this class, it will work for just about \\neverything.\")"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc9fdd-8a90-42f9-bbae-7d3d25876e73",
   "metadata": {},
   "source": [
    "#### Question answering\n",
    "U≈æivatel asi nebude cht√≠t, aby mu stroj na jeho ot√°zku vyplivl v√≠ce ƒçi m√©nƒõ souvisl√© fragmenty dokument≈Ø. Bude si sp√≠≈°e p≈ô√°t odpovƒõƒè v p≈ôirozen√©m jazyce. T√©to √∫loze se budeme vƒõnovat nyn√≠.  \n",
    "Nejprve si p≈ôipravme vƒõci, se kter√Ωmi jsme se sezn√°mili ji≈æ v p≈ôedchoz√≠k podkapitol√°ch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "7a0c7bb9-85e6-456e-b298-39db8f76a3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_28553/2729103167.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5fba1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_model_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "8f363936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "31eff410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32b339-d9ee-4352-94df-9baa80f793bf",
   "metadata": {},
   "source": [
    "N√°slednƒõ si vytvo≈ô√≠me chain pro question answering - [RetrievalQA](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "d7a5213a-0764-4d27-8538-d0fcc62721d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "cf74b26d-268f-470a-b3b1-05d5c4d16bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa5454-81ea-48f8-9f40-c9eefac5fa72",
   "metadata": {},
   "source": [
    "Ot√°zku do nƒõj vlo≈æ√≠me takto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "5a88d39b-7905-4bdc-8c65-c69fae9aeba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765196c-8eb2-4ccb-b769-81d37d215b13",
   "metadata": {},
   "source": [
    "A obdr≈æ√≠me n√°sleduj√≠c√≠ slovn√≠k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "29f117e8-735a-47e0-8372-24b13b63b0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are major topics for this class?', 'result': \"I don't know.\"}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2cb11",
   "metadata": {},
   "source": [
    "**Prompt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd09b547-0428-4dcd-ac0d-bbc450fd9f20",
   "metadata": {},
   "source": [
    "Ok, odpovƒõƒè v p≈ôirozen√©m jazyce jsme dostali. Co kdy≈æ bychom ale chtƒõli upravit syst√©mov√Ω prompt? A jak si zobraz√≠me fragmenty, ze kter√Ωch jazykov√Ω model skl√°dal odpovƒõƒè?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f7626304-d182-4fb2-a013-b9e92865da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "qa_chain_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cefe70-d47b-4cac-b706-3d911e5450ef",
   "metadata": {},
   "source": [
    "Zdrojov√© fragmenty dostaneme d√≠ky parametru *return_source_documents* rovn√©mu True. ≈†ablonu se sv√©ho druhu syst√©mov√Ωm promptem pak do chainu vlo≈æ√≠me skrze parametr *chain_type_kwargs*. Ten obsahuje slovn√≠k, ve kter√©m mus√≠ b√Ωt pro kl√≠ƒç \"prompt\" vlo≈æena n√°mi specifikovan√° ≈°ablona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d03cd7c5-5d8a-44a7-ba72-8bdd0364e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "2535390a-6a15-46c2-b709-0f97225fb256",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "f6439491-e36d-423e-bcf6-5842071ff5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are major topics for this class?',\n",
       " 'result': 'The major topics for this class include human anatomy, physiology, and medical terminology. We will also cover common diseases and treatments related to the human body. Thanks for asking!',\n",
       " 'source_documents': []}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6f291bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"source_documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20891b",
   "metadata": {},
   "source": [
    "##### RetrievalQA chain types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd114c",
   "metadata": {},
   "source": [
    "V obecnosti je princip nasledujici: \n",
    "* Polozi se otazka\n",
    "* Podivame se do \"storu\" s chunkama a vybereme ty nejvic potrebny\n",
    "* Spolecne s otazkou vlozime tyhle chunky do LLM, aby nam vygeneroval smysluplnou odpoved.\n",
    "\n",
    "Tomuhle _chain_type_ se rika **stuff**, protoze se takrikajic vsechno nastuffuje do LLMka, at si s tim poradi. To ma samozrejme obvious nevyhody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    ...,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8a9be",
   "metadata": {},
   "source": [
    "Proto existuji alternativni metody.\n",
    "1. **map_reduce** \n",
    "   1. kazdy dokument zvlast posle do LLMka, spolecne s otazkou, aby se pokusil odpovedet na otazku. Hacek je v tom, ze pokud se odpoved naleza rozkrocena mezi nekolik dokumentu, tak tu odpoved retrieval nenajde. Ale vyhoda je, ze do LLMka jsme schopni takhle poslat libovolny pocet dokumentu.\n",
    "2. **refine** \n",
    "   1. taky se nekolikrat vola LLMko, ale: vezme se prvni dokument, spolecne s otazkou. Pak se vezme druhy dokument a prompt (vnitrne) se upravi, o nasledujici text: \"Mas moznost vylepsit nasledujici odpoved (pokud mozno) s nasledujicim kontextem.\". A to se dale opakuje o vsechny dokumenty v rade. \n",
    "3. **map_rerank**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d3a66",
   "metadata": {},
   "source": [
    "![chain_type](./pomocne_soubory/chain_type.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118968e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_reduce\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f90be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_rerank\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac2260",
   "metadata": {},
   "source": [
    "##### RetrievalQA limitations\n",
    " \n",
    "QA fails to preserve conversational history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23840e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907416f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883c3c2",
   "metadata": {},
   "source": [
    "Note, The LLM response varies. Some responses **do** include a reference to probability which might be gleaned from referenced documents. The point is simply that the model does not have access to past questions or answers, this will be covered in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b79d9-1eb1-4a9c-868b-73ce24c78980",
   "metadata": {},
   "source": [
    "Urƒçit√© parametry m≈Ø≈æeme vlo≈æit i do *vectordb.as_retriever()*. Nap≈ô√≠klad pokud bychom chtƒõli p≈ôej√≠t od defaultn√≠ho similarity searche na max marginal relevance search, p≈ôid√°me tam parametr *search_type* s hodnotou \"mmr\". Dal≈°√≠ paramtery u≈æ nejsou samostatn√©, n√Ωbr≈æ se nal√©zaj√≠ ve slovn√≠ku v parametru *search_kwargs*. M≈Ø≈æe j√≠t o poƒçet vr√°cen√Ωch fragment≈Ø (parametr *k*), *fetch_k* pro MMR, *score_threshold* pro similarity search na vr√°cen√≠ dostateƒçnƒõ kvalit√≠ch fragment≈Ø ƒçi v p≈ô√≠padƒõ filtrov√°n√≠ dle metadat parametr filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce977a-a183-43da-903e-6b7baf85161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={'k': 5, 'fetch_k': 20}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6ea01",
   "metadata": {},
   "source": [
    "#### Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce3183-cf64-4490-a107-c3728cd6a2bc",
   "metadata": {},
   "source": [
    "Pokud chceme m√≠t chatbota, se kter√Ωm lze diskutovat d√©le ne≈æ jednu dialogovou v√Ωmƒõnu, mus√≠me si vytvo≈ôit pamƒõ≈•ov√Ω objekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780c702-288f-4924-ba70-4607e4fc48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "conv_buff_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88fe7d-06ca-488c-85c7-f6a544437f14",
   "metadata": {},
   "source": [
    "Je t≈ôeba t√©≈æ pou≈æ√≠t jin√Ω chain - *ConversationalRetrievalChain*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e645ba2-4cb0-44c9-afd3-b168b4a2848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915bda8-1de3-4e82-ba0e-60d0877d165b",
   "metadata": {},
   "source": [
    "Parametry jsou (krom p≈ôid√°n√≠ pamƒõti) stejn√© jako v p≈ôedchoz√≠m chainu. Nicm√©nƒõ v pozad√≠ p≈ôibyl dal≈°√≠ krok, ve kter√©m chain vezme historii i novou u≈æivatelovu ot√°zku a zkondenzuje je do ot√°zky p≈ôe≈æv√Ωkan√©. Tento krok m√° n√°sleduj√≠c√≠ podobu: \n",
    "```\n",
    "[llm/start] [1:chain:ConversationalRetrievalChain > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
    "{\n",
    "  \"prompts\": [\n",
    "    \"Human: Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n\\nHuman: Jak dlouho debentn√≠ karta plat√≠?\\nAssistant: Debetn√≠ karta plat√≠ do posledn√≠ho dne mƒõs√≠ce a roku doby platnosti, kter√° je uvedena na kartƒõ.\\nFollow Up Input: Jak se to li≈°√≠ v p≈ô√≠padƒõ, kdy m√°me kreditn√≠ kartu?\\nStandalone question:\"\n",
    "  ]\n",
    "}\n",
    "```\n",
    "d√≠ky ƒçemu≈æ vznikne ot√°zka\n",
    "```\n",
    "\"Jak dlouho plat√≠ kreditn√≠ karta?\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f424f86-d6a5-452d-bb71-91c24b669106",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    memory=conv_buff_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813aed2-9869-41e3-bae0-679c3f0d54f9",
   "metadata": {},
   "source": [
    "Pozn.: bacha, slovn√≠k vstupuj√≠c√≠ do provol√°v√°n√≠ chainu mus√≠ m√≠t kl√≠ƒç \"question\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d205400-d889-4038-b542-80b329772604",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = memory_chain({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f2688-b584-4215-9085-f43cc68b61c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077423e-498f-4000-b3a5-37e9c8b656d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"why are those prerequesites needed?\"\n",
    "result = memory_chain({\"question\": question_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a2301-42c9-4fb4-adc0-7ebcbe511c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd31842-ec17-4272-a881-263566598c6c",
   "metadata": {},
   "source": [
    "BTW odpovƒõƒè je asi spr√°vnƒõ, ale v cel√©m dokumentu o kreditn√≠ch kart√°ch nebyla ani zm√≠nka.  \n",
    "Pozn.: pokud chceme vidƒõt zdrojov√© dokumenty, mus√≠me vlo≈æit do konstruktoru *ConversationalRetrievalChain* parametr *verbose* s hodnotou True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2607c-0549-4ef7-b464-5cdd50d6cf2d",
   "metadata": {},
   "source": [
    "#### Automatick√© pou≈æ√≠v√°n√≠ metadat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2463fd85",
   "metadata": {},
   "source": [
    "##### Vitkuv Priklad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abbfca-a627-4f9a-b25e-32ae71d7b255",
   "metadata": {},
   "source": [
    "Naƒçtƒõme si nejprve krom pdfka o debentn√≠ch kart√°ch i pdfko o kart√°ch kreditn√≠ch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2e897-1d12-4944-a495-cd513cd395fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_list = [\n",
    "    PyPDFLoader(\"source_files\\\\podminky_debetnich_karet.pdf\"),\n",
    "    PyPDFLoader(\"source_files\\\\Podminky-osobnich-kreditnich-karet.pdf\")\n",
    "]\n",
    "\n",
    "pages = []\n",
    "for loader in loaders_list:\n",
    "    pages = pages + loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c56975-6629-400f-bc1d-2b2dba6df38a",
   "metadata": {},
   "source": [
    "Nyn√≠ postupujme obvykl√Ωm zp≈Øsobem (bez metadat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d827c-4107-4bb1-892a-387afb48cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 50\n",
    "\n",
    "rec_text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")\n",
    "\n",
    "rec_splits = rec_text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd928eb9-122b-4568-be95-90725a71ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "simple_doc_dir = \"embeddings\\\\two_cards\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84cf2e6-699b-4fd5-abed-5e69a425ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=rec_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=simple_doc_dir\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883dc72-275c-4c24-9abb-9a6774989b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=simple_doc_dir, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482996c-7c97-410f-8697-09d67950ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=llm_model_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5f300-21b4-4321-aa55-7736b97759a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Answer in Czech language. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "qa_chain_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191d642-ca77-4a30-a019-4b6f1d51c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Jak je to s aktivov√°n√≠m debentn√≠ karty?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a0759-653a-4a76-a932-985347923052",
   "metadata": {},
   "source": [
    "Pozn.: pros√≠m o ignorov√°n√≠ pole \"topic\" a \"product\" v metadatech - jedn√° se o produkt n√°sleduj√≠c√≠ch krok≈Ø. zde jsou irrelevantn√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f326d8-c143-4677-a8f9-292d203cb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593283c-1e98-4514-ae4e-455574fd2444",
   "metadata": {},
   "source": [
    "V≈°imnƒõte si, ≈æe i kdy≈æ byla odpovƒõƒè asi spr√°vn√°, dostal se mezi nejvhodnƒõj≈°√≠ fragmenty i jeden fragment z pdfka o kart√°ch kreditn√≠ch.  \n",
    "Jak√© je ≈ôe≈°en√≠? Inu, lze pou≈æ√≠t metadata. Pokud ƒçlovƒõk pracuje s dokumenty s lehce zpracovateln√Ωm n√°zvem (typu \"podminky_produkt_1.pdf\", \"podminky_produkt_2.pdf\") a m√° ≈°tƒõst√≠, nemus√≠ p≈ôid√°vat ≈æ√°dn√° nov√° metadata. I v na≈°em pomƒõrnƒõ primitivn√≠m p≈ô√≠padƒõ to ale moc nefungovalo. \n",
    "Mus√≠me tedy data ve vektorov√© datab√°zi obohatit o nov√© metadatov√© pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fd36c-8aef-4299-8b88-c2b2dc09b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "debit_cards_ids = vectordb.get(where={\"source\": \"source_files\\\\podminky_debetnich_karet.pdf\"})[\"ids\"]\n",
    "debit_cards_metadatas = vectordb.get(where={\"source\": \"source_files\\\\podminky_debetnich_karet.pdf\"})[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4755e9-5140-4b63-9f3e-929e37324927",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_cards_ids = vectordb.get(where={\"source\": \"source_files\\\\Podminky-osobnich-kreditnich-karet.pdf\"})[\"ids\"]\n",
    "credit_cards_metadatas = vectordb.get(where={\"source\": \"source_files\\\\Podminky-osobnich-kreditnich-karet.pdf\"})[\"metadatas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af31e7-48cc-4a9b-bba6-e8c64d70ede1",
   "metadata": {},
   "source": [
    "Hned tady m≈Ø≈æe b√Ωt z√°drhel, kdy≈æ do metadat vlo≈æ√≠me slova ve tvaru, kter√© pozdƒõji jazykov√Ω model nevygeneruje. Metadatov√© filtrov√°n√≠ toti≈æ nen√≠ fuzzy, ale p≈ôesn√©. Tud√≠≈æ kdy≈æ modle vyvod√≠, ≈æe se v ot√°zce \"Co mus√≠m udƒõlat pro blokaci produktu debentn√≠ karty?\" pt√°me na produkt \"debentn√≠ karta\", nem≈Ø≈æeme m√≠t v metadatech \"debentn√≠ kart**y**\". Podobnƒõ bacha na case sensitivitu - model (p≈ôesnƒõji vl√°ƒçek modelu a datab√°zov√©ho enginu) zaƒçne pro ot√°zku \"Co mus√≠m udƒõlat pro blokaci produktu Debentn√≠ karta?\" hledat produkt \"Debentn√≠ karta\" a t√©≈æ nic nenajde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97baedf9-b99d-492e-b5bb-1f01152e7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_metadata in debit_cards_metadatas:\n",
    "    one_metadata[\"product\"] = \"debentn√≠ karta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91350a2-bf2f-4914-b523-f812978631c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_metadata in credit_cards_metadatas:\n",
    "    one_metadata[\"product\"] = \"kreditn√≠ karta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a209740-e2ff-4894-b6c1-aa068c2bd85a",
   "metadata": {},
   "source": [
    "Provedeme update a zmƒõny datab√°ze ulo≈æ√≠me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e7b0e-1708-4624-9fea-668018bf4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb._collection.update(ids=debit_cards_ids, metadatas=debit_cards_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1e14f-e9dc-45f1-91d8-e7961da476a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb._collection.update(ids=credit_cards_ids, metadatas=credit_cards_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6895e-82fa-40b2-94bb-4eaacf6b8369",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4b3c3-3c2b-46ed-8efa-a36726509bfc",
   "metadata": {},
   "source": [
    "Pro z√≠sk√°n√≠ fragment≈Ø dokument≈Ø, u kter√Ωch u≈æ budou hr√°t roli metadata, mus√≠me pou≈æ√≠t *SelfQueryRetriever*. Ten vy≈æaduje m√≠t nainstalovan√Ω bal√≠ƒçek [lark](https://pypi.org/project/lark/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1eee2a-68e9-47ad-a71d-0465e89a301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eecc10-ff24-4628-adac-8d7c8a7ba822",
   "metadata": {},
   "source": [
    "Mus√≠me mu mimo jin√© podhodit popis metadat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df768a-b7b3-4acc-9472-4e52cc054b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"product\",\n",
    "        description=\"Product name\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The document source\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the document\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b156c6-50a2-4201-9bc5-ba8bb1ad36a8",
   "metadata": {},
   "source": [
    "T√©≈æ do *SelfQueryRetriever* vlo≈æ√≠me parametr *document_contents*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c759823-ea14-40ed-bc05-10ae212138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Bank products\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=chat,\n",
    "    vectorstore=vectordb,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a7b13-911b-4928-8721-fbc0b068442f",
   "metadata": {},
   "source": [
    "No a kdy≈æ jsem tohle v≈°echno udƒõlal, tak... to stejnƒõ nefungovalo :D. Mo≈æn√° jsem se ≈°patnƒõ dotazoval, mo≈æn√° tenhle typ √∫lohy funguje sn√°ze v angliƒçtinƒõ. Zkusil jsem tak editovat soubor {jm√©no_va≈°eho_environmentu}\\Lib\\site-packages\\langchain\\chains\\query_constructor\\prompt.py, ve kter√©m je ≈°ablona za tvo≈ôen√≠ queriny do Chromy zodpovƒõdn√°. No, snad jsem p≈ôitom nic nerozbil...   \n",
    "Zmƒõnƒõn√© byly tyto ƒç√°sti souboru:\n",
    "```\n",
    "BANK_DATA_SOURCE = \"\"\"\\\n",
    "```json\n",
    "{\n",
    "    \"content\": \"Informace k bankovn√≠mu produktu\",\n",
    "    \"attributes\": {\n",
    "        \"produkt\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"N√°zev produktu\"\n",
    "        },\n",
    "        \"zamereni\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Zamƒõ≈ôen√≠ dokumentu, jedna z mo≈ænost√≠ \\\"cen√≠k\\\", \\\"v≈°eobecn√© informace\\\"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\\\n",
    "\"\"\".replace(\n",
    "    \"{\", \"{{\"\n",
    ").replace(\n",
    "    \"}\", \"}}\"\n",
    ")\n",
    "\n",
    "FULL_ANSWER = \"\"\"\\\n",
    "```json\n",
    "{{\n",
    "    \"query\": \"cena spot≈ôebitelsk√Ω √∫vƒõr\",\n",
    "    \"filter\": \"and(eq(\\\\\"produkt\\\\\", \\\\\"spot≈ôebitelsk√Ω √∫vƒõr\\\\\"), \\\n",
    "eq(\\\\\"zamereni\\\\\", \\\\\"cen√≠k\\\\\"))\"\n",
    "}}\n",
    "```\\\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_EXAMPLES = [\n",
    "    {\n",
    "        \"i\": 1,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"Kolik stoj√≠ vy≈ô√≠zen√≠ spot≈ôebitelsk√©ho √∫vƒõru\",\n",
    "        \"structured_request\": FULL_ANSWER,\n",
    "    },\n",
    "    {\n",
    "        \"i\": 2,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"V kolik jede vlak?\",\n",
    "        \"structured_request\": NO_FILTER_ANSWER,\n",
    "    },\n",
    "]\n",
    "\n",
    "EXAMPLES_WITH_LIMIT = [\n",
    "    {\n",
    "        \"i\": 1,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"Kolik stoj√≠ vy≈ô√≠zen√≠ spot≈ôebitelsk√©ho √∫vƒõru\",\n",
    "        \"structured_request\": FULL_ANSWER,\n",
    "    },\n",
    "    {\n",
    "        \"i\": 2,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"V kolik jede vlak\",\n",
    "        \"structured_request\": NO_FILTER_ANSWER,\n",
    "    },\n",
    "    {\n",
    "        \"i\": 3,\n",
    "        \"data_source\": BANK_DATA_SOURCE,\n",
    "        \"user_query\": \"What are three songs about love\",\n",
    "        \"structured_request\": WITH_LIMIT_ANSWER,\n",
    "    },\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008aeaf2-9a92-45f9-b532-b7aa899d36d6",
   "metadata": {},
   "source": [
    "Pro dotaz \"Co mus√≠m udƒõlat pro blokaci debentn√≠ karty?\" (pop≈ô. \"Co mus√≠m udƒõlat pro blokaci debentn√≠ karty od KB?\") se vygeneruje\n",
    "```\n",
    "\"```json\\n{\\n    \\\"query\\\": \\\"blokace debentn√≠ karta\\\",\\n    \\\"filter\\\": \\\"NO_FILTER\\\"\\n}\\n```\"\n",
    "```\n",
    "Tj. querina spr√°vn√°, ale filtr se neuplatnil.\n",
    "P≈ôi dotazu \"Co mus√≠m udƒõlat pro blokaci produktu debentn√≠ karta?\" je u≈æ filtr spr√°vn√Ω\n",
    "```\n",
    "\"```json\\n{\\n    \\\"query\\\": \\\"blokace debentn√≠ karta\\\",\\n    \\\"filter\\\": \\\"eq(\\\\\\\"product\\\\\\\", \\\\\\\"debentn√≠ karta\\\\\\\")\\\"\\n}\\n```\"\n",
    "```\n",
    "Ale popravdƒõ nedok√°≈æu si p≈ôedstavit, ≈æe by v praxi u≈æivatel pou≈æ√≠val takto pro model n√°povƒõdn√Ω dotaz.  \n",
    "Pro zaj√≠mavost - na dotaz \"Kolik budu platit u poji≈°tƒõn√≠ Merlin od KB?\" by vznikl filtr\n",
    "```\n",
    "\"```json\\n{\\n    \\\"query\\\": \\\"platit poji≈°tƒõn√≠ Merlin KB\\\",\\n    \\\"filter\\\": \\\"and(eq(\\\\\\\"product\\\\\\\", \\\\\\\"Merlin\\\\\\\"), eq(\\\\\\\"source\\\\\\\", \\\\\\\"KB\\\\\\\"))\\\"\\n}\\n```\"\n",
    "```\n",
    "Asi by to chtƒõlo ten ≈°ablonov√Ω prompt ze souboru trochu vylep≈°it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa99d2e-b609-4d9b-aef3-a50224001f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Co mus√≠m udƒõlat pro blokaci produktu debentn√≠ karta?\"\n",
    "result = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1095a-fa7d-4b3d-967a-9c0d74238ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af23c5",
   "metadata": {},
   "source": [
    "##### Originalni prikald z Coursery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b44144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"./LangChain/Chat With LLM/docs/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './LangChain/Chat With LLM/docs/chroma/'\n",
    "!rm -rf ./LangChain/Chat With LLM/docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aed2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a764ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47175c",
   "metadata": {},
   "source": [
    "**Note:** The default model for `OpenAI` (\"from langchain.llms import OpenAI\") is `text-davinci-003`. Due to the deprication of OpenAI's model `text-davinci-003` on 4 January 2024, you'll be using OpenAI's recommended replacement model `gpt-3.5-turbo-instruct` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f16373",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feccadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece11042",
   "metadata": {},
   "source": [
    "**You will receive a warning** about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2634be3-73c0-4007-8739-037d275a0c6a",
   "metadata": {},
   "source": [
    "#### Prefix p≈ôed fragmenty\n",
    "Co se t√Ωƒçe probl√©mu nalezen√≠ fragmentu ke spr√°vn√© problematice, lze na internetu nal√©zt doporuƒçen√≠, aby se jm√©no problematiky vlo≈æilo na zaƒç√°tek ka≈æd√©ho fragmentu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5f7d0-6a5f-4c80-ac7e-1becf9764493",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "chunk_overlap = 50\n",
    "\n",
    "rec_text_splitter = RecursiveCharacterTextSplitter(        \n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    ")\n",
    "\n",
    "loader_1 = PyPDFLoader(\"source_files\\\\podminky_debetnich_karet.pdf\")\n",
    "pages_1 = loader_1.load()\n",
    "rec_splits_1 = rec_text_splitter.split_documents(pages_1)\n",
    "for one_doc in rec_splits_1:\n",
    "    one_doc.page_content = \"debentn√≠ karta \\t \" + one_doc.page_content\n",
    "\n",
    "\n",
    "loader_2 = PyPDFLoader(\"source_files\\\\Podminky-osobnich-kreditnich-karet.pdf\")\n",
    "pages_2 = loader_2.load()\n",
    "rec_splits_2 = rec_text_splitter.split_documents(pages_2)\n",
    "for one_doc in rec_splits_2:\n",
    "    one_doc.page_content = \"kreditn√≠ karta \\t \" + one_doc.page_content\n",
    "\n",
    "all_splits = rec_splits_1 + rec_splits_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715121f-a854-4b93-9a61-cf7d4b9a8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "doc_dir = \"embeddings\\\\fragment_prefix\\\\\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=doc_dir\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b780c816-81f6-43c3-8ba1-20a5b36b113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=llm_model_name, temperature=0)\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Answer in Czech language. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "qa_chain_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a79a28d-f268-4308-8770-abeca9ff593f",
   "metadata": {},
   "source": [
    "Zd√° se, ≈æe funkƒçnost takov√©ho p≈ô√≠stupu je omezen√°, nicm√©nƒõ pro √∫pln√© zatracen√≠ ƒçi naopak vychv√°len√≠ do nebes by to chtƒõlo vƒõt≈°√≠ otestov√°n√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94e76f-65a1-4b67-8955-836ccfb29932",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Co mus√≠m udƒõlat pro blokaci debentn√≠ karty?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e34f32-0887-4d4f-b43f-6d02c9703ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Co dƒõlat s kreditkou zaseklou v bankomatu?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342d226-193d-4774-a81b-8ea9f3cf012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": \"Co dƒõlat s debetn√≠ kartou zaseklou v bankomatu?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716801b-ac9f-411f-9271-01e9051e7137",
   "metadata": {},
   "source": [
    "### Kompletn√≠ uk√°zky\n",
    "V textu v√Ω≈°e jsem se sna≈æil komentovat v≈°echny mo≈æn√© vƒõci, kter√© je t≈ôeba p≈ôi vytvo≈ôen√≠ langchainov√© aplikace vz√≠t v √∫vahu. M≈Ø≈æe b√Ωt ale u≈æiteƒçn√© vidƒõt v≈°e pohromadƒõ a pr√°vƒõ proto existuje tato kapitola.\n",
    "#### Obyƒçejn√Ω chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d82a1c-366f-42fa-8986-e8b590792b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory \n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.7, model_name=llm_model_name)\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are Sauron from 'Lord of the Ring' novel.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "window_memory = ConversationBufferWindowMemory(k=5, memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=window_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588050e0-3f77-44dc-aff4-f8cda2ac37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"Hi, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c1838-809b-4db5-ab3c-e5f699f4531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input=\"I have One ring, but I will never give it to you!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5fa55d-95e3-492a-b0ec-ab700f8a9fa4",
   "metadata": {},
   "source": [
    "#### Q&A chatbot\n",
    "Skript naƒç√≠tac√≠ z√°znamy do datab√°ze se nach√°z√≠ n√≠≈æe. Mo≈æn√° nƒõkoho zaraz√≠ metoda listu *extend*. Ta na konec sv√©ho mate≈ôsk√©ho listu vlo≈æ√≠ v≈°echny elementy iterable objektu (nap≈ô. listu) ze sv√©ho argumentu. Tj. nap≈ô√≠klad pro mate≈ôsk√Ω list [1, 2, 3] a dodateƒçn√Ω list [4, 5] vede extend na [1, 2, 3, 4, 5], zat√≠mco append by skonƒçil s [1, 2, 3, [4, 5]]. No a toto je chtƒõn√≠ chov√°n√≠, kdy≈æ si uvƒõdom√≠me, ≈æe *loader.load()* n√°m d√° list Document objekt≈Ø, kter√© odpov√≠daj√≠ jednotliv√Ωm str√°nk√°m jednoho pdfka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41736efe-e512-4de2-a023-b1d4a793ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "loaders = [\n",
    "    PyPDFLoader(\"source_files\\\\penzijni-plan-1-1-16.pdf\"),\n",
    "    PyPDFLoader(\"source_files\\\\penzijni-plan-3-1-16.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\"ƒåL√ÅNEK\", \"\\n\\n\", \"\\n\", \".\"]\n",
    ")\n",
    "\n",
    "splits = r_splitter.split_documents(docs)\n",
    "\n",
    "persist_directory = \"embeddings\\\\chroma_persist_dir\\\\\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc91b1-4822-4982-8517-c2c21d57ca83",
   "metadata": {},
   "source": [
    "Skript realizuj√≠c√≠ dotazov√°n√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd61480-0f12-418b-88d8-d7f7aa2fd67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "persist_directory = \"embeddings\\\\chroma_persist_dir\\\\\"\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum. Keep the answer as concise as possible. Answer in Czech language.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful answer:\"\"\"\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0, model_name=llm_model_name) \n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_message=True,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "qa_chain_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": qa_chain_prompt}\n",
    ")\n",
    "\n",
    "while True:\n",
    "    question = input(\"Napi≈° ot√°zku (exit pro opu≈°tƒõn√≠ chatu):\\n\")\n",
    "    if question == \"exit\":\n",
    "        break \n",
    "    result = qa_chain.invoke({\"query\":question})\n",
    "    print(result[\"result\"])\n",
    "    print()\n",
    "    print(\"Zdrojov√© dokumenty:\")\n",
    "    for one_source_doc in result[\"source_documents\"]:\n",
    "        print(\"--------------------------\")\n",
    "        print(\"    \", one_source_doc)\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a91fab",
   "metadata": {},
   "source": [
    "#### Coursera Chatbot vcetne GUIcka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a62f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1da441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    # load documents\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # define embedding\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    return qa \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self,  **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.loaded_file = \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"\n",
    "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
    "    \n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:  # init or no file specified :\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # local copy\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style=\"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style=\"solid\"\n",
    "        self.clr_history()\n",
    "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(query, result[\"answer\"])])\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result['answer'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, style={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        inp.value = ''  #clears loading indicator when cleared\n",
    "        return pn.WidgetBox(*self.panels,scroll=True)\n",
    "\n",
    "    @param.depends('db_query ', )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query :\n",
    "            return pn.Column(\n",
    "                pn.Row(pn.pane.Markdown(f\"Last question to DB:\", styles={'background-color': '#F6F6F6'})),\n",
    "                pn.Row(pn.pane.Str(\"no DB accesses so far\"))\n",
    "            )\n",
    "        return pn.Column(\n",
    "            pn.Row(pn.pane.Markdown(f\"DB query:\", styles={'background-color': '#F6F6F6'})),\n",
    "            pn.pane.Str(self.db_query )\n",
    "        )\n",
    "\n",
    "    @param.depends('db_response', )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return \n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Result of DB lookup:\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    @param.depends('convchain', 'clr_history') \n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return pn.WidgetBox(pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True)\n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Current Chat History variable\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept='.pdf')\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning')\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here‚Ä¶')\n",
    "\n",
    "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "jpg_pane = pn.pane.Image( './img/convchain.jpg')\n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=300),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab2= pn.Column(\n",
    "    pn.panel(cb.get_lquest),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(cb.get_sources ),\n",
    ")\n",
    "tab3= pn.Column(\n",
    "    pn.panel(cb.get_chats),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab4=pn.Column(\n",
    "    pn.Row( file_input, button_load, bound_button_load),\n",
    "    pn.Row( button_clearhistory, pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\" )),\n",
    "    pn.layout.Divider(),\n",
    "    pn.Row(jpg_pane.clone(width=400))\n",
    ")\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ChatWithYourData_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1), ('Database', tab2), ('Chat History', tab3),('Configure', tab4))\n",
    ")\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b6d92",
   "metadata": {},
   "source": [
    "## Evaluace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0bffe",
   "metadata": {},
   "source": [
    "LangChain platfroma obsahuje i nastroje pro debugging a evaluaci. Nicmene, jeden z benefitu LLM je, ze se da pouzit i pro evaluaci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce250221",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./pomocne_soubory/OutdoorClothingCatalog_1000.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccdc005",
   "metadata": {},
   "source": [
    "### Create our QandA application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27f6d5",
   "metadata": {},
   "source": [
    "Zacneme tim, ze si vytvorime RAG aplikaci pro dotazovani nad csv dokumentem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cac472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=file)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ac6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model_name)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde0bbb",
   "metadata": {},
   "source": [
    "### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d1a40",
   "metadata": {},
   "source": [
    "### Hard-coded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
    "        have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty \\\n",
    "        850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154c2e1",
   "metadata": {},
   "source": [
    "### LLM-Generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bfa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the warning below can be safely ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74628dab",
   "metadata": {},
   "source": [
    "Zajimava metoda .apply_and_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e61669",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b22459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8912a",
   "metadata": {},
   "source": [
    "### Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples += new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b6109",
   "metadata": {},
   "source": [
    "### Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc610f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a31ce43",
   "metadata": {},
   "source": [
    "### LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3fd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850174a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4967a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model_name)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ce492",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7764abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3b63c",
   "metadata": {},
   "source": [
    "### LangChain evaluation platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ea6e1",
   "metadata": {},
   "source": [
    "The LangChain evaluation platform, LangChain Plus, can be accessed here https://www.langchain.plus/.  \n",
    "Use the invite code `lang_learners_2023`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21ff6c",
   "metadata": {},
   "source": [
    "## LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36feb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad78fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e1822",
   "metadata": {},
   "source": [
    "Temperature nastavujeme na 0, protoze to chceme pouzit jako reasoning agenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e20907",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185fc8e",
   "metadata": {},
   "source": [
    "Dva tooly, ktery loadujeme jsou pro pouziti kalkulacky v ramci jazykoveho modelu a druhy je Wikipedia, coz nam umoznuje volat Wikipedii primo z jazykoveho modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f796d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2bbf7",
   "metadata": {},
   "source": [
    "Je dobre se podivat do dokumentace, protoze agenti jsou pomerne nova zalezitost a nektere veci se mohou zmenit. Navic, tady treba volame agenta \"CHAT_ZERO_SHOT_REACT_DESCRIPTION\", coz znamena, ze je optimalizovany pro chatovani a reagovani na popis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67530b",
   "metadata": {},
   "source": [
    "#### Math Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d692fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82f12b",
   "metadata": {},
   "source": [
    "Tenhle priklad zavola action \"calculator\" a posle mu dve cisla, na ktere ma provest operaci."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460ee00",
   "metadata": {},
   "source": [
    "#### Wikipedia example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cca944",
   "metadata": {},
   "source": [
    "Naopak, tenhle priklad zavola action \"wikipedia\" a posle mu dotaz, na ktery ma odpovedet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "result = agent(question) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c0fb6",
   "metadata": {},
   "source": [
    "#### Python Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bb369",
   "metadata": {},
   "source": [
    "\"PythonREPLTool\" je takovy jupyter notebook, ktery bezi v jazykovem modelu. Tady se muze hodit, kdyz chceme nejaky kod spustit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de47407",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93718c15",
   "metadata": {},
   "source": [
    "#### View detailed outputs of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03dae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug=True\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") \n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221b0d6",
   "metadata": {},
   "source": [
    "### Define your own tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39faf5c0",
   "metadata": {},
   "source": [
    "Pro psani vlastnich toolu je dulezity, aby obsahovali podrobou dokumentaci. Tady je priklad, jak by takova dokumentace mohla vypadat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ded274",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "\n",
    "The agent will sometimes come to the wrong conclusion (agents are a work in progress!). \n",
    "\n",
    "If it does, please try running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e916b",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb033e5d",
   "metadata": {},
   "source": [
    "# Function, Tools and Agents with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db396f",
   "metadata": {},
   "source": [
    "## Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe71c30",
   "metadata": {},
   "source": [
    "Nova functionalita LangChainu, ktera umoznuje predavat LLM modelu nejen text, ale i nejake funkce, ktere ma vykonat. Tady se podivame na nekolik prikladu, jak toho dosahnout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d453e5",
   "metadata": {},
   "source": [
    "Zadefinujeme si novou vlastni funkci, ktera bude vracet pocasi. OpenAI pridala novou API, _functions_, ktera umoznuje volat nejake funkce primo z LLM modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "247e5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ec8d7",
   "metadata": {},
   "source": [
    "Description v obou pripadech definice nize je velmi velmi dulezita. Ta totiz umoznuje LLM rozhodnout, zda a kdy volat nasi funkci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfd7f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47c5b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c373ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=llm_model_name,\n",
    "    functions=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c8f97e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Au61QjuKqYwK3i2GjJeSOvZmZUJyA', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather'), tool_calls=None))], created=1737932880, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_72ed7ab54c', usage=CompletionUsage(completion_tokens=18, prompt_tokens=79, total_tokens=97, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05bf7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6c84637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather'), tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d87c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db3558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather')\n"
     ]
    }
   ],
   "source": [
    "print(response_message.function_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1274bb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Boston, MA'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5036909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efbcf99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Boston, MA\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4f89a",
   "metadata": {},
   "source": [
    "Je treba rict, ze LLM za nas tu funkci volat nebude. To musime udelat my. Ale LLM nam pomuze s tim, ze nam rekne, zda (a pripadne kterou, v pripade vice funkci) bychom ji mohli volat. A s jakyma parametrama. Nicmene, je treba dodat, ze popisy funkci se pocitaji do context limitu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "def7151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfedaedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=llm_model_name,\n",
    "    functions=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f26ec36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Au622wQlTKGiVEa2d9KkIXkl9gMwo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737932918, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_72ed7ab54c', usage=CompletionUsage(completion_tokens=11, prompt_tokens=74, total_tokens=85, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220deb1b",
   "metadata": {},
   "source": [
    "Jak vidno, kdyz do LLM vlozime vetu, ktera nevyzaduje pocasi, tak LLM nevraci parametr _fuction_call_. Tohle lze osetrit parametrem, ktery bud nakaze nebo zakaze volani funkci.\n",
    "\n",
    "Jedna se o parametr **function_call**, jehoz defaultni hodnota je \"auto\". Naopak, pokud chceme, aby LLM nevolal funkci, musime tento parametr nastavit na \"none\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b90e2910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Au62G4DTSNboYk6bRcM0Tne5lfLHk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737932932, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_72ed7ab54c', usage=CompletionUsage(completion_tokens=11, prompt_tokens=74, total_tokens=85, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=llm_model_name,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f943453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Au62HmPVClJnr3eTRvJStde7XzmJq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737932933, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=10, prompt_tokens=75, total_tokens=85, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=llm_model_name,\n",
    "    functions=functions,\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cea24d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Au62JqISHQNbOn4c2YAHZscMdtQUw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Which unit of temperature would you like the weather to be reported in: Celsius or Fahrenheit?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737932935, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=19, prompt_tokens=79, total_tokens=98, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather in Boston?\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=llm_model_name,\n",
    "    functions=functions,\n",
    "    function_call=\"none\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b451d",
   "metadata": {},
   "source": [
    "Pokud chceme LLM donuti, aby volal funkci, musime tento parametr nastavit na dictionary se jmenem funkce, kterou ma volat.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ab98254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Au62LqcHABBMF9N2HEjLwYWsvr6vz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"New York, NY\"}', name='get_current_weather'), tool_calls=None))], created=1737932937, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_72ed7ab54c', usage=CompletionUsage(completion_tokens=9, prompt_tokens=84, total_tokens=93, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=llm_model_name,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde1c8e",
   "metadata": {},
   "source": [
    "Nasledujici priklad ukazuje, jak se to da pouzit v praxi. Zavolame LLM, to nam vrati parametry, ktery vlozime do funkce a vysledek opet vracime do LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66ecfeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Au62MIpWm9z0eExG9u5LLbFcxfhXU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather'), tool_calls=None))], created=1737932938, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=8, prompt_tokens=89, total_tokens=97, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=llm_model_name,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e871ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b310334b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChatCompletionMessage(content=None, refusal=None, role=\\'assistant\\', audio=None, function_call=FunctionCall(arguments=\\'{\"location\":\"Boston, MA\"}\\', name=\\'get_current_weather\\'), tool_calls=None)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db115cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6643167",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response_message.function_call.arguments)\n",
    "observation = get_current_weather(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f17e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "193aa4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Au62PBRvCzkd4B7e51n7q6kPhDzdI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The weather in Boston is currently 72¬∞F and sunny, with some windy conditions. Enjoy your day!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737932941, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=22, prompt_tokens=76, total_tokens=98, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=llm_model_name\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f9293d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Boston is currently 72¬∞F and sunny, with some windy conditions. Enjoy your day!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa7d09",
   "metadata": {},
   "source": [
    "## LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8950f2b",
   "metadata": {},
   "source": [
    "LangChain zavadi novou jazykovou konstrukci, ktera ma zjednodusit volani dilcich casti langchainu. Dokonce to pokrocilo tak, ze predchozi kapitoly nahore jsou jiz deprecated. Tahle konstrukce se jmenuje _runnable_. Pouziva se pomoci pipy. "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "55880a29",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3751949",
   "metadata": {},
   "source": [
    "Vsechny runnables by meli obsahovat standardni metody jako je _invoke_ nebo _stream_. Viz obrazek nize:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7a39d",
   "metadata": {},
   "source": [
    "LCEL se pouziva proto, ze zjednodusuje nektery procesy a pridava na efektivite. Jmenovite:\n",
    "* asynchroni beh jobu\n",
    "* Fallback, kdyz selze nejaky chain\n",
    "* Paralellism\n",
    "* Loggin, ale ten za paywallem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a937be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydantic==1.10.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca33c65",
   "metadata": {},
   "source": [
    "Nasledujici import je zakladni kamen LCEL, resp. chainu.\n",
    "* ChatPromptTemplate - jasny\n",
    "* ChatOpenAI - jasny\n",
    "* StrOutputParser - predela odpoved z modelu na string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fdad121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f00f0d",
   "metadata": {},
   "source": [
    "### Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a79881a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\"\n",
    ")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f954d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb12215e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the bear break up with his girlfriend? \\n\\nBecause she was unbearable!'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e704a4",
   "metadata": {},
   "source": [
    "### More complex chain\n",
    "\n",
    "And Runnable Map to supply user-provided inputs to the prompt.\n",
    "Nyni si k tomu jeste pridame RAG, tj. hledani casti dokumentu ze kterych chceme najit odpoved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b926b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adfe46c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmateju/miniconda3/envs/langchain/lib/python3.10/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e450f56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_66226/3310280720.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever.get_relevant_documents(\"where did harrison work?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='harrison worked at kensho'),\n",
       " Document(metadata={}, page_content='bears like to eat honey')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf90cc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='bears like to eat honey'),\n",
       " Document(metadata={}, page_content='harrison worked at kensho')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fd3c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e643a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2847962",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09504ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66bc7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c0482ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='harrison worked at kensho'),\n",
       "  Document(metadata={}, page_content='bears like to eat honey')],\n",
       " 'question': 'where did harrison work?'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391184c",
   "metadata": {},
   "source": [
    "### Bind\n",
    "\n",
    "an OpenAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "09baa3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3ed175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "# normalne bysme zavolali jen ChatOpenAI(), ale protoze chceme pouzit funkce, pridame jeste .bind() metodu\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d68d7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6b1c7227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'weather_search'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 64, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-42cfbeda-b281-4eaf-b979-7f07faf4df7f-0', usage_metadata={'input_tokens': 64, 'output_tokens': 17, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3732a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    },\n",
    "        {\n",
    "      \"name\": \"sports_search\",\n",
    "      \"description\": \"Search for news of recent sport events\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"team_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The sports team to search for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"team_name\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "38d50d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30edf1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "161533fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"patriots\"}', 'name': 'sports_search'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 99, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-f314778f-ac35-4756-8ead-6020ddd7a0c4-0', usage_metadata={'input_tokens': 99, 'output_tokens': 19, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4adf4",
   "metadata": {},
   "source": [
    "### Fallbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f243f9",
   "metadata": {},
   "source": [
    "Tenhle model je starsi a ne moc funkcni. Proto ho pouzijeme jako ten, ktery \"selze\", abychom mohli demonstrovat fallback na lepsi model. V praxi to nebude \"lepsi\" model, ale model, ktery bude zachytavat problemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ebd6ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b2ef8",
   "metadata": {},
   "source": [
    "**Note**: Due to the deprecation of OpenAI's model `text-davinci-001` on 4 January 2024, you'll be using OpenAI's recommended replacement model `gpt-3.5-turbo-instruct` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aff8d7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_66226/2498289737.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  simple_model = OpenAI(\n"
     ]
    }
   ],
   "source": [
    "simple_model = OpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=1000, \n",
    "    model=\"gpt-3.5-turbo-instruct\"\n",
    ")\n",
    "simple_chain = simple_model | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4dde1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f93bd7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n{\\n    \"title\": \"Autumn Leaves\",\\n    \"author\": \"Emily Dickinson\",\\n    \"first_line\": \"The leaves are falling, one by one\"\\n}\\n\\n{\\n    \"title\": \"The Ocean\\'s Song\",\\n    \"author\": \"Pablo Neruda\",\\n    \"first_line\": \"I hear the ocean\\'s song, a symphony of waves\"\\n}\\n\\n{\\n    \"title\": \"A Winter\\'s Night\",\\n    \"author\": \"Robert Frost\",\\n    \"first_line\": \"The snow falls softly, covering the ground\"\\n}'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9782a",
   "metadata": {},
   "source": [
    "**Note**: The next line is expected to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "59d83e96",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 9 column 1 (char 125)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimple_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchallenge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3021\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4711\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4697\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[1;32m   4698\u001b[0m \n\u001b[1;32m   4699\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4708\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4712\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4714\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4715\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4716\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4718\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4719\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4720\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4721\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1925\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1922\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1923\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1924\u001b[0m         Output,\n\u001b[0;32m-> 1925\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1933\u001b[0m     )\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1935\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4565\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4563\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   4564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4565\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4566\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   4567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4568\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[1;32m   4569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 9 column 1 (char 125)"
     ]
    }
   ],
   "source": [
    "simple_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d0dfe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "chain = model | StrOutputParser() | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99cd8e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet.'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood,'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers'}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1abfd486",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = simple_chain.with_fallbacks([chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d43910c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af836674",
   "metadata": {},
   "source": [
    "### Interface\n",
    "Jiny metody nez _invoke_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f90d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3a6f9811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the bear bring a flashlight to the party?\\nBecause he heard it was going to be a \"beary\" good time!'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "62f8596a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why did the bear join the band? \\n\\nBecause he had the best bearitone voice!',\n",
       " 'Why did the frog take the bus to work? Because his car got toad away!']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "684654b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " did\n",
      " the\n",
      " bear\n",
      " wear\n",
      " a\n",
      " fur\n",
      " coat\n",
      " to\n",
      " the\n",
      " party\n",
      "?\n",
      "\n",
      "\n",
      "Because\n",
      " he\n",
      " didn\n",
      "'t\n",
      " want\n",
      " to\n",
      " be\n",
      " under\n",
      "d\n",
      "ressed\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b9c2e265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the bear break up with his girlfriend? \\n\\nBecause she couldn't bear his bad puns!\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8403d89",
   "metadata": {},
   "source": [
    "## Kompletace znalosti z predchozich kapitol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7a8fd",
   "metadata": {},
   "source": [
    "### Pydantic Syntax\n",
    "\n",
    "Pydantic je velmi podobna standardni Pythonovske knihovne dataclasses, ale pridava na validaci dat = tim se mysli, ze se kontroluje datovy typ, ktery do classy vkladame. Viz priklady nize. \n",
    "\n",
    "Dokumentace k Pydantic je [zde](https://docs.pydantic.dev/latest/concepts/models/)\n",
    "\n",
    "Dokumentace k Python Dataclasses je [zde](https://realpython.com/python-data-classes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35b49ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, name: str, age: int, email: str):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.email = email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b34f7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = User(name=\"Joe\",age=32, email=\"joe@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "59ab402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Joe'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "92f23b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = User(name=\"Joe\",age=\"bar\", email=\"joe@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c23b1abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bar'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "695eee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pUser(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    email: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bc06f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_p = pUser(name=\"Jane\", age=32, email=\"jane@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4911064e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jane'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo_p.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594bc413",
   "metadata": {},
   "source": [
    "**Note**: The next cell is expected to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75f01509",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for pUser\nage\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bar', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m foo_p \u001b[38;5;241m=\u001b[39m \u001b[43mpUser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJane\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjane@gmail.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.10/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for pUser\nage\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bar', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing"
     ]
    }
   ],
   "source": [
    "foo_p = pUser(name=\"Jane\", age=\"bar\", email=\"jane@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c96b5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Class(BaseModel):\n",
    "    students: List[pUser]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1205ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Class(\n",
    "    students=[pUser(name=\"Jane\", age=32, email=\"jane@gmail.com\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5309e384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class(students=[pUser(name='Jane', age=32, email='jane@gmail.com')])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f2243",
   "metadata": {},
   "source": [
    "### Pydantic to OpenAI function definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "37debf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherSearch(BaseModel):\n",
    "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
    "    airport_code: str = Field(description=\"airport code to get weather for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d202ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f0227bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_function = convert_pydantic_to_openai_function(WeatherSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "06d9bbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'WeatherSearch',\n",
       " 'description': 'Call this with an airport code to get the weather at that airport',\n",
       " 'parameters': {'properties': {'airport_code': {'description': 'airport code to get weather for',\n",
       "    'type': 'string'}},\n",
       "  'required': ['airport_code'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "001f3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherSearch1(BaseModel):\n",
    "    airport_code: str = Field(description=\"airport code to get weather for\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91bbf8",
   "metadata": {},
   "source": [
    "**Note**: The next cell is expected to generate an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30fefa1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'WeatherSearch1',\n",
       " 'description': '',\n",
       " 'parameters': {'properties': {'airport_code': {'description': 'airport code to get weather for',\n",
       "    'type': 'string'}},\n",
       "  'required': ['airport_code'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(WeatherSearch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e97a1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherSearch2(BaseModel):\n",
    "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
    "    airport_code: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "661c3f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'WeatherSearch2',\n",
       " 'description': 'Call this with an airport code to get the weather at that airport',\n",
       " 'parameters': {'properties': {'airport_code': {'type': 'string'}},\n",
       "  'required': ['airport_code'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(WeatherSearch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a85e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "635bc75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 70, 'total_tokens': 88, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-8da0a364-e26c-4b77-a995-545ed1ec4a86-0', usage_metadata={'input_tokens': 70, 'output_tokens': 18, 'total_tokens': 88, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the weather in SF today?\", functions=[weather_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e88e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_function = model.bind(functions=[weather_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "423fd73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 69, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-afa2f864-5aa3-4901-83af-6aa30c7c89c6-0', usage_metadata={'input_tokens': 69, 'output_tokens': 18, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_function.invoke(\"what is the weather in sf?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ce85e",
   "metadata": {},
   "source": [
    "### Forcing it to use a function\n",
    "\n",
    "We can force the model to use a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1319e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_forced_function = model.bind(functions=[weather_function], function_call={\"name\":\"WeatherSearch\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9c7b2585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 79, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-17151073-6b6c-46f0-9350-854f00cb41fb-0', usage_metadata={'input_tokens': 79, 'output_tokens': 8, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_forced_function.invoke(\"what is the weather in sf?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ca8a90e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 74, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2138c535-cee7-4069-9d43-66d12076423e-0', usage_metadata={'input_tokens': 74, 'output_tokens': 8, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_forced_function.invoke(\"hi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9940a9",
   "metadata": {},
   "source": [
    "### Using in a chain\n",
    "\n",
    "We can use this model bound to function in a chain as we normally would"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76c60426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9009a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9d0927e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model_with_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "19410e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 75, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-d16ea0c5-263e-4152-a5e5-8cead4e806be-0', usage_metadata={'input_tokens': 75, 'output_tokens': 18, 'total_tokens': 93, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05087a32",
   "metadata": {},
   "source": [
    "### Using multiple functions\n",
    "\n",
    "Even better, we can pass a set of function and let the LLM decide which to use based on the question context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "207e0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtistSearch(BaseModel):\n",
    "    \"\"\"Call this to get the names of songs by a particular artist\"\"\"\n",
    "    artist_name: str = Field(description=\"name of artist to look up\")\n",
    "    n: int = Field(description=\"number of results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d963501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    convert_pydantic_to_openai_function(WeatherSearch),\n",
    "    convert_pydantic_to_openai_function(ArtistSearch),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8639b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "430a99a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'WeatherSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 116, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-d8927dfb-01d2-4cd6-a82a-86db214a3685-0', usage_metadata={'input_tokens': 116, 'output_tokens': 18, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_functions.invoke(\"what is the weather in sf?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fd950f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"artist_name\":\"Taylor Swift\",\"n\":3}', 'name': 'ArtistSearch'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 118, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-2f1d351d-0097-4056-8b9b-987adc80e04c-0', usage_metadata={'input_tokens': 118, 'output_tokens': 22, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_functions.invoke(\"what are three songs by taylor swift?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4175ab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 111, 'total_tokens': 122, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-772e5ad4-b9fe-4e1a-b768-4d9f2745b9ad-0', usage_metadata={'input_tokens': 111, 'output_tokens': 11, 'total_tokens': 122, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_functions.invoke(\"hi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f7fbbf",
   "metadata": {},
   "source": [
    "## Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78360081",
   "metadata": {},
   "source": [
    "### Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e29ce",
   "metadata": {},
   "source": [
    "Ackoli jsme si rekli, ze LLM nevola funkce, ktere mu zadame, je tu urcita trida funkci, ktere to dela za nas. Specificky jde o funkce delajici Tagging a Extraction. Tyhle funkce nemusime definovat, staci LLM zadat jen strkturu, jakou chceme, a on je za nas zavola. Neplati to samozrejme o jinych funkcich, napriklad funkce na pocasi, kterou jsme definovali vyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0aad831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7cde0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fb126f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': 'Tag the piece of text with particular info.',\n",
       " 'parameters': {'properties': {'sentiment': {'description': 'sentiment of text, should be `pos`, `neg`, or `neutral`',\n",
       "    'type': 'string'},\n",
       "   'language': {'description': 'language of text (should be ISO 639-1 code)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71fa9d1",
   "metadata": {},
   "source": [
    "Tak si to ukazeme na celem prikladu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ac44426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "34d75391",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b3884fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "acfa5ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532f0fa",
   "metadata": {},
   "source": [
    "Pridame k tomu funkci na Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "04dfab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d4978a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3ed13c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"sentiment\":\"pos\",\"language\":\"en\"}', 'name': 'Tagging'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 108, 'total_tokens': 119, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-fd32cd96-a4b6-4e45-a82c-72115252681b-0', usage_metadata={'input_tokens': 108, 'output_tokens': 11, 'total_tokens': 119, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"I love langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5185924d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"sentiment\":\"neg\",\"language\":\"it\"}', 'name': 'Tagging'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 111, 'total_tokens': 122, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2d7bdb69-be07-45d5-ab52-d9afb563f6a2-0', usage_metadata={'input_tokens': 111, 'output_tokens': 11, 'total_tokens': 122, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "93022d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4316a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7fd051f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neg', 'language': 'it'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647681f",
   "metadata": {},
   "source": [
    "### Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ea7fbefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "97066e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f64c213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Information',\n",
       " 'description': 'Information to extract.',\n",
       " 'parameters': {'properties': {'people': {'description': 'List of info about people',\n",
       "    'items': {'description': 'Information about a person.',\n",
       "     'properties': {'name': {'description': \"person's name\", 'type': 'string'},\n",
       "      'age': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "       'description': \"person's age\"}},\n",
       "     'required': ['name', 'age'],\n",
       "     'type': 'object'},\n",
       "    'type': 'array'}},\n",
       "  'required': ['people'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1b761710",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f6e1a8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"people\":[{\"name\":\"Joe\",\"age\":30},{\"name\":\"Martha\",\"age\":null}]}', 'name': 'Information'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 95, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0d2abb8d-dc09-45ce-9e34-cfbe2b80f95f-0', usage_metadata={'input_tokens': 95, 'output_tokens': 22, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model.invoke(\"Joe is 30, his mom is Martha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a72dc",
   "metadata": {},
   "source": [
    "Protoze v odpovedi byl vek u Marty uveden jako 0, protoze v textu neni, tak si LLM domyslelo hodnotu. Proti tomu se da bojovat vhodnym promptem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c93eb724",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e97ec856",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5df2b3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"people\":[{\"name\":\"Joe\",\"age\":30},{\"name\":\"Martha\",\"age\":null}]}', 'name': 'Information'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 112, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3b5f973e-a241-4a4b-9def-c2349f5cadd0-0', usage_metadata={'input_tokens': 112, 'output_tokens': 22, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e72a8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ab4cf922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3bb47b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "223db312",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0d3c17c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Joe', 'age': 30}, {'name': 'Martha', 'age': None}]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78e1fa",
   "metadata": {},
   "source": [
    "### Doing it for real\n",
    "\n",
    "We can apply tagging to a larger body of text.\n",
    "\n",
    "For example, let's load this blog post and extract tag information from a sub-set of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d81e083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "af00f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f8168f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = doc.page_content[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "95167fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "emojisearch.app\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "Agent System Overview\n",
      "\n",
      "Component One: Planning\n",
      "\n",
      "Task Decomposition\n",
      "\n",
      "Self-Reflection\n",
      "\n",
      "\n",
      "Component Two: Memory\n",
      "\n",
      "Types of Memory\n",
      "\n",
      "Maximum Inner Product Search (MIPS)\n",
      "\n",
      "\n",
      "Component Three: Tool Use\n",
      "\n",
      "Case Studies\n",
      "\n",
      "Scientific Discovery Agent\n",
      "\n",
      "Generative Agents Simulation\n",
      "\n",
      "Proof-of-Concept Examples\n",
      "\n",
      "\n",
      "Challenges\n",
      "\n",
      "Citation\n",
      "\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful gene\n"
     ]
    }
   ],
   "source": [
    "print(page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "93b8a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\")\n",
    "    language: str = Field(description=\"Provide the language that the content is written in.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "db4dddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9c7ac209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'The article discusses building autonomous agents powered by LLM (large language model) as the core controller, with components like planning, memory, and tool use. It explores task decomposition, self-reflection, and challenges in implementing LLM-powered agents.',\n",
       " 'language': 'English',\n",
       " 'keywords': 'LLM, autonomous agents, planning, memory, tool use, task decomposition, self-reflection, challenges'}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7f0706ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "40d211c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_extraction_function = [\n",
    "    convert_pydantic_to_openai_function(Info)\n",
    "]\n",
    "extraction_model = model.bind(\n",
    "    functions=paper_extraction_function, \n",
    "    function_call={\"name\":\"Info\"}\n",
    ")\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ed4197e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LLM Powered Autonomous Agents', 'author': 'Lilian Weng'}]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ea1e03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b28bcbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f2e1c2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chain of thought (CoT; Wei et al. 2022)', 'author': None},\n",
       " {'title': 'Tree of Thoughts (Yao et al. 2023)', 'author': None},\n",
       " {'title': 'LLM+P (Liu et al. 2023)', 'author': None},\n",
       " {'title': 'ReAct (Yao et al. 2023)', 'author': None},\n",
       " {'title': 'Reflexion (Shinn & Labash 2023)', 'author': None},\n",
       " {'title': 'Chain of Hindsight (CoH; Liu et al. 2023)', 'author': None},\n",
       " {'title': 'Algorithm Distillation (AD; Laskin et al. 2023)', 'author': None}]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b12a4703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "263f788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5c766e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "efdff324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d88a5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "66524b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1574be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "emojisearch.app\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "Agent System Overview\n",
      "\n",
      "Component One: Planning\n",
      "\n",
      "Task Decomposition\n",
      "\n",
      "Self-Reflection\n",
      "\n",
      "\n",
      "Component Two: Memory\n",
      "\n",
      "Types of Memory\n",
      "\n",
      "Maximum Inner Product Search (MIPS)\n",
      "\n",
      "\n",
      "Component Three: Tool Use\n",
      "\n",
      "Case Studies\n",
      "\n",
      "Scientific Discovery Agent\n",
      "\n",
      "Generative Agents Simulation\n",
      "\n",
      "Proof-of-Concept Examples\n",
      "\n",
      "\n",
      "Challenges\n",
      "\n",
      "Citation\n",
      "\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent‚Äôs brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n"
     ]
    }
   ],
   "source": [
    "print(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5fe0ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2e72640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = RunnableLambda(\n",
    "    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cef1cb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'hi'}]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ae8a5",
   "metadata": {},
   "source": [
    "A to delame proto, ze chceme vypustit model na list of documents. Proto na vstupu bude list dokumentu, ktere chceme zpracovat, pustime na ne extraction_chain, ale musime pridat metodu .map(), aby se aplikovala na kazdy dokument zvlast. A pomoci funkce flatten() z listu listu udelame list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "68d09cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prep | extraction_chain.map() | flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e62df4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'AutoGPT', 'author': None},\n",
       " {'title': 'GPT-Engineer', 'author': None},\n",
       " {'title': 'BabyAGI', 'author': None},\n",
       " {'title': 'Chain of thought', 'author': 'Wei et al. 2022'},\n",
       " {'title': 'Tree of Thoughts', 'author': 'Yao et al. 2023'},\n",
       " {'title': 'LLM+P', 'author': 'Liu et al. 2023'},\n",
       " {'title': 'ReAct', 'author': 'Yao et al. 2023'},\n",
       " {'title': 'Reflexion', 'author': 'Shinn & Labash 2023'},\n",
       " {'title': 'Chain of Hindsight', 'author': 'Liu et al. 2023'},\n",
       " {'title': 'Algorithm Distillation', 'author': 'Laskin et al. 2023'},\n",
       " {'title': 'Laskin et al. 2023', 'author': None},\n",
       " {'title': 'Miller 1956', 'author': None},\n",
       " {'title': 'Duan et al. 2017', 'author': None},\n",
       " {'title': 'Google Blog', 'author': None},\n",
       " {'title': 'MRKL (Karpas et al. 2022)', 'author': None},\n",
       " {'title': 'TALM (Tool Augmented Language Models; Parisi et al. 2022)',\n",
       "  'author': None},\n",
       " {'title': 'Toolformer (Schick et al. 2023)', 'author': None},\n",
       " {'title': 'HuggingGPT (Shen et al. 2023)', 'author': None},\n",
       " {'title': 'API-Bank', 'author': 'Li et al. 2023'},\n",
       " {'title': 'ChemCrow', 'author': 'Bran et al. 2023'},\n",
       " {'title': 'Boiko et al. (2023)', 'author': None},\n",
       " {'title': 'Generative Agents Simulation', 'author': 'Park, et al. 2023'},\n",
       " {'title': 'Park et al. 2023', 'author': None},\n",
       " {'title': 'Super Mario: The Platformer Revolution', 'author': 'John Smith'},\n",
       " {'title': 'Model-View-Controller in Python', 'author': None},\n",
       " {'title': 'Paper A', 'author': 'Author A'},\n",
       " {'title': 'Paper B', 'author': 'Author B'},\n",
       " {'title': 'Chain of thought prompting elicits reasoning in large language models.',\n",
       "  'author': 'Wei et al.'},\n",
       " {'title': 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models',\n",
       "  'author': 'Yao et al.'},\n",
       " {'title': 'Chain of Hindsight Aligns Language Models with Feedback',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'ReAct: Synergizing reasoning and acting in language models',\n",
       "  'author': 'Yao et al.'},\n",
       " {'title': 'Reflexion: an autonomous agent with dynamic memory and self-reflection',\n",
       "  'author': 'Shinn & Labash'},\n",
       " {'title': 'In-context Reinforcement Learning with Algorithm Distillation',\n",
       "  'author': 'Laskin et al.'},\n",
       " {'title': 'MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning',\n",
       "  'author': 'Karpas et al.'},\n",
       " {'title': 'Webgpt: Browser-assisted question-answering with human feedback',\n",
       "  'author': 'Nakano et al.'},\n",
       " {'title': 'TALM: Tool Augmented Language Models', 'author': 'Parisi et al.'},\n",
       " {'title': 'Toolformer: Language Models Can Teach Themselves to Use Tools',\n",
       "  'author': 'Schick et al.'},\n",
       " {'title': 'API-Bank: A Benchmark for Tool-Augmented LLMs',\n",
       "  'author': 'Li et al.'},\n",
       " {'title': 'HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace',\n",
       "  'author': 'Shen et al.'},\n",
       " {'title': 'ChemCrow: Augmenting large-language models with chemistry tools',\n",
       "  'author': 'Bran et al.'},\n",
       " {'title': 'Emergent autonomous scientific research capabilities of large language models',\n",
       "  'author': 'Boiko et al.'},\n",
       " {'title': 'Generative Agents: Interactive Simulacra of Human Behavior',\n",
       "  'author': 'Joon Sung Park, et al.'}]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570c6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "776d0128",
   "metadata": {},
   "source": [
    "## Tools and Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f149760",
   "metadata": {},
   "source": [
    "Nektery funkce umi LLM volat samo. Ne vsechny, a in general LLM vraci jen function_call a argumenty, ale uz nevola samotnou funkci. To musi zajistit clovek. Nektery funkce ovsem jsou jiz implementovany v LLM a tak je umi pouzit. \n",
    "Mezi takove funkce patri:\n",
    "* Search Tools\n",
    "* Math Tools\n",
    "* SQL Tools\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e114c385",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eac54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6f014",
   "metadata": {},
   "source": [
    "Tool dekorator udela z funkce objekt, ktery danou funkci prevede na langchain callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "855121f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for weather online\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cacef87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f6c223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Search for weather online'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad2f2742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4bc67",
   "metadata": {},
   "source": [
    "Za pouziti pydantic modelu si muzeme pripravit rovnou celou strukturu do jsonu, jako v predchozim pripade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cfbd543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Thing to search for\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9bfdb",
   "metadata": {},
   "source": [
    "A tohle schema pak vstupuje do toolu jako argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03234190",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(args_schema=SearchInput)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for the weather online.\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2e2694c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'Thing to search for',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb37e07",
   "metadata": {},
   "source": [
    "A porad je to langchain callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7409b325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42f'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"sf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacfb6e",
   "metadata": {},
   "source": [
    "Udelame si takovy vetsi priklad, ktery bude vracet teplotu v zavislosti na zadane zemepisne delce a sirce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375ff0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}¬∞C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15579b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66449dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fetch current temperature for given coordinates.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "254c1bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "  'title': 'Latitude',\n",
       "  'type': 'number'},\n",
       " 'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "  'title': 'Longitude',\n",
       "  'type': 'number'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fac7885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97ae764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_4857/540789164.py:1: LangChainDeprecationWarning: The function `_format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  format_tool_to_openai_function(get_current_temperature)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_temperature',\n",
       " 'description': 'Fetch current temperature for given coordinates.',\n",
       " 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "    'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_tool_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db975131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_4857/2143878976.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  get_current_temperature({\"latitude\": 13, \"longitude\": 14})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current temperature is 18.7¬∞C'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature({\"latitude\": 13, \"longitude\": 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3e385",
   "metadata": {},
   "source": [
    "A druhy takovy tool bude vyhledavani na Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e11b3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5b2e821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_wikipedia'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b1ae84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Run Wikipedia search and get page summaries.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c070076c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_wikipedia',\n",
       " 'description': 'Run Wikipedia search and get page summaries.',\n",
       " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_tool_to_openai_function(search_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f6703f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Milvus (vector database)\\nSummary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\\nMilvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\\n\\n\\n\\nPage: Retrieval-augmented generation\\nSummary: Retrieval-Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \\nUse cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.\\n\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia({\"query\": \"langchain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ded30d",
   "metadata": {},
   "source": [
    "Casto jsou funkce, ktere chceme pouzivat za nejakym API. Existuje snadna cesta jak takovy api definition prevest na openai spec. V nasledujicim prikladu mame funkci zadanou jako api, vcetne vsech volani. A prevedeme ji na langchain object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0126590",
   "metadata": {},
   "source": [
    "Pozor, tady dochazi k verzi mismatch pro balicek pydantic and langchain.utilities.openai. Je potreba mit bud pydantic <2 nebo nainstalovat balicek: \"openapi-pydantic==0.3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac606255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
    "from langchain.utilities.openapi import OpenAPISpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a9be6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "{\n",
    "  \"openapi\": \"3.0.0\",\n",
    "  \"info\": {\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"title\": \"Swagger Petstore\",\n",
    "    \"license\": {\n",
    "      \"name\": \"MIT\"\n",
    "    }\n",
    "  },\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"url\": \"http://petstore.swagger.io/v1\"\n",
    "    }\n",
    "  ],\n",
    "  \"paths\": {\n",
    "    \"/pets\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"List all pets\",\n",
    "        \"operationId\": \"listPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"limit\",\n",
    "            \"in\": \"query\",\n",
    "            \"description\": \"How many items to return at one time (max 100)\",\n",
    "            \"required\": false,\n",
    "            \"schema\": {\n",
    "              \"type\": \"integer\",\n",
    "              \"maximum\": 100,\n",
    "              \"format\": \"int32\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"A paged array of pets\",\n",
    "            \"headers\": {\n",
    "              \"x-next\": {\n",
    "                \"description\": \"A link to the next page of responses\",\n",
    "                \"schema\": {\n",
    "                  \"type\": \"string\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pets\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"post\": {\n",
    "        \"summary\": \"Create a pet\",\n",
    "        \"operationId\": \"createPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"201\": {\n",
    "            \"description\": \"Null response\"\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"/pets/{petId}\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"Info for a specific pet\",\n",
    "        \"operationId\": \"showPetById\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"petId\",\n",
    "            \"in\": \"path\",\n",
    "            \"required\": true,\n",
    "            \"description\": \"The id of the pet to retrieve\",\n",
    "            \"schema\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"Expected response to a valid request\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pet\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"schemas\": {\n",
    "      \"Pet\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"id\",\n",
    "          \"name\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"id\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int64\"\n",
    "          },\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"tag\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Pets\": {\n",
    "        \"type\": \"array\",\n",
    "        \"maxItems\": 100,\n",
    "        \"items\": {\n",
    "          \"$ref\": \"#/components/schemas/Pet\"\n",
    "        }\n",
    "      },\n",
    "      \"Error\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"code\",\n",
    "          \"message\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"code\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int32\"\n",
    "          },\n",
    "          \"message\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b4e2194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    }
   ],
   "source": [
    "spec = OpenAPISpec.from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "323f3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaeb5144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'listPets',\n",
       "  'description': 'List all pets',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'params': {'type': 'object',\n",
       "     'properties': {'limit': {'type': 'integer',\n",
       "       'maximum': 100.0,\n",
       "       'schema_format': 'int32',\n",
       "       'description': 'How many items to return at one time (max 100)'}},\n",
       "     'required': []}}}},\n",
       " {'name': 'createPets',\n",
       "  'description': 'Create a pet',\n",
       "  'parameters': {'type': 'object', 'properties': {}}},\n",
       " {'name': 'showPetById',\n",
       "  'description': 'Info for a specific pet',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'path_params': {'type': 'object',\n",
       "     'properties': {'petId': {'type': 'string',\n",
       "       'description': 'The id of the pet to retrieve'}},\n",
       "     'required': ['petId']}}}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_openai_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "358287f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ce315ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e98e409f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"params\":{\"limit\":3}}', 'name': 'listPets'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 123, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-d3f18532-bb0d-4034-9d8e-79034ae1ae3a-0', usage_metadata={'input_tokens': 123, 'output_tokens': 17, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what are three pets names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "680ccdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"path_params\":{\"petId\":\"42\"}}', 'name': 'showPetById'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 126, 'total_tokens': 146, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-72f079b2-d3df-40fd-bd87-40a3f50c9e41-0', usage_metadata={'input_tokens': 126, 'output_tokens': 20, 'total_tokens': 146, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"tell me about pet with id 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5513f9",
   "metadata": {},
   "source": [
    "### Routing\n",
    "\n",
    "In lesson 3, we show an example of function calling deciding between two candidate functions.\n",
    "\n",
    "Given our tools above, let's format these as OpenAI functions and show this same behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f19ca1",
   "metadata": {},
   "source": [
    "Vsimnete si, ze tyto funkce taky LLM nevola, ale vraci _function_call_ a argumenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "108b07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    format_tool_to_openai_function(f) for f in [\n",
    "        search_wikipedia, get_current_temperature\n",
    "    ]\n",
    "]\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98e5bfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 105, 'total_tokens': 131, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-048471fb-c2e3-4244-aadb-95a8c36b8114-0', usage_metadata={'input_tokens': 105, 'output_tokens': 26, 'total_tokens': 131, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the weather in sf right now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ff517d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 101, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-02224ce0-6d6a-41e4-aea0-4405c33796bd-0', usage_metadata={'input_tokens': 101, 'output_tokens': 17, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2393c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb3b044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 113, 'total_tokens': 139, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-2191352c-2123-4f3e-b467-f56e5b29f6e5-0', usage_metadata={'input_tokens': 113, 'output_tokens': 26, 'total_tokens': 139, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf6c56",
   "metadata": {},
   "source": [
    "Tahle langchain callable funkce nam umoznuje rozhodnout, ktera z funkci se ma zavolat a jestli vubec. Abychom nemuseli rucne nacitat, jestli to vraci content='' a tedy jesti to vraci function_call nebo jestli to vraci nejaky content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92c4b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95ccfcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3fc4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed689719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentActionMessageLog"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "928a3552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6529aa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d654af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 15.1¬∞C'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f775d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1750fc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentFinish"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfdfcaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'Well, hello there! How can I assist you today?'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.return_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f92991",
   "metadata": {},
   "source": [
    "Tady udelame routing: podivame se, jestli type je AgentFinish, tj. nevola zadnou funkci. A pokud neni, najde volanou funkci a zavola ji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4af9ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67b28d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "295743dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07856db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 15.1¬∞C'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80cbdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"What is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a38ab83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Milvus (vector database)\\nSummary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\\nMilvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\\n\\n\\n\\nPage: Retrieval-augmented generation\\nSummary: Retrieval-Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \\nUse cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.\\n\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6635b4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4a707",
   "metadata": {},
   "source": [
    "## Conversational agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa88561",
   "metadata": {},
   "source": [
    "Ted to dame vsechno dohromady. Zkombinuje tools a chat memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32a822",
   "metadata": {},
   "source": [
    "Op√°ƒçko:\n",
    "* agents: \n",
    "  * kombinace llm a code\n",
    "  * llm rozhodne, jakou cast kodu zavolat\n",
    "* agent loop:\n",
    "  * rozhodne, ktery tool zavolat\n",
    "  * sleduje vysledek volani toolu\n",
    "  * opakuje, dokud neni splneno stopping criterea\n",
    "* Stopping condition muze byt:\n",
    "  * llm se rozhodne, ze staci\n",
    "  * hard-coded\n",
    "\n",
    "V tehle casti:\n",
    "* si pripravime nekolik toolu\n",
    "* napiseme agenta s pomoci LCEL\n",
    "* pouzijeme agent_executor, ktery\n",
    "  * vytvori agent loop\n",
    "  * prida overhead jako jsou logy, error handling, early stopping, tracing, ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36f5605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3007c3",
   "metadata": {},
   "source": [
    "Tady si vytvorime jiz znamou funkci na hledani teploty na zaklade polohy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00e82b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}¬∞C'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754570ce",
   "metadata": {},
   "source": [
    "Tady si vytvorime jiz znamy tool na hledani wikipedie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d4c416c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a077deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_current_temperature, search_wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "31c4e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0f2b6",
   "metadata": {},
   "source": [
    "Vytvorime si klasicky chain, ktery zname uz z predchozi kapitoly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83ad704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_4857/390516792.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(temperature=0).bind(functions=functions)\n"
     ]
    }
   ],
   "source": [
    "functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2bcaaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"what is the weather is sf?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af7a01ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "343ceac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562136a4",
   "metadata": {},
   "source": [
    "Abychom mohli do LLM zaznamenavat vysledek volani toolu, musime pridat novou promennou \"agent_scratchpad\". Tato promenna je _MessagesPlaceholder_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d187761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4499c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef29de4",
   "metadata": {},
   "source": [
    "Tady zavolame chain a do _agent_scratchpad_ vkladame prazdny list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a28084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = chain.invoke({\n",
    "    \"input\": \"what is the weather is sf?\",\n",
    "    \"agent_scratchpad\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c700c541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "02d7cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = get_current_temperature(result1.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90f14516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 15.1¬∞C'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a4f6310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentActionMessageLog"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1b0a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "89a9616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 112, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-f3085b87-c572-4177-b7d3-bfd85e1840df-0')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.message_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457021f",
   "metadata": {},
   "source": [
    "Pomoci funkce _format_to_openai_functions()_ si ulozime vysledek, resp. tuple volani a vysledek, do promenne _agent_scratchpad_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b66431d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 112, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-f3085b87-c572-4177-b7d3-bfd85e1840df-0'),\n",
       " FunctionMessage(content='The current temperature is 15.1¬∞C', additional_kwargs={}, response_metadata={}, name='get_current_temperature')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_to_openai_functions([(result1, observation), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "738e8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = chain.invoke({\n",
    "    \"input\": \"what is the weather is sf?\", \n",
    "    \"agent_scratchpad\": format_to_openai_functions([(result1, observation)])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b0f0415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'The current temperature in San Francisco is 15.1¬∞C.'}, log='The current temperature in San Francisco is 15.1¬∞C.')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ec7f1",
   "metadata": {},
   "source": [
    "Ted to cele zabalime do agent loopu, ktery se bude volat tak dlouho dokud nenarazi na _AgentFinish_ type, ktery znamena, ze uz neni treba volat zadnou dalsi funkci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "449578b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "def run_agent(user_input):\n",
    "    intermediate_steps = []\n",
    "    while True:\n",
    "        result = chain.invoke({\n",
    "            \"input\": user_input, \n",
    "            \"agent_scratchpad\": format_to_openai_functions(intermediate_steps)\n",
    "        })\n",
    "        if isinstance(result, AgentFinish):\n",
    "            return result\n",
    "        tool = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }[result.tool]\n",
    "        observation = tool.run(result.tool_input)\n",
    "        intermediate_steps.append((result, observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d025d",
   "metadata": {},
   "source": [
    "Funkce _RunnablePassthrough_ vytvori dictionary, ktery umi langchain pouzivat. Takze abychom nemeli neznamou funkci v nasem _run_agent_, tak budeme mit chain, do kteryho vstupuje dictionary tvoreny promennoou _agent_scratchpad_ a ten se preda chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df6dfb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "agent_chain = RunnablePassthrough.assign(\n",
    "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    ") | chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08015b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(user_input):\n",
    "    intermediate_steps = []\n",
    "    while True:\n",
    "        result = agent_chain.invoke({\n",
    "            \"input\": user_input, \n",
    "            \"intermediate_steps\": intermediate_steps\n",
    "        })\n",
    "        if isinstance(result, AgentFinish):\n",
    "            return result\n",
    "        tool = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }[result.tool]\n",
    "        observation = tool.run(result.tool_input)\n",
    "        intermediate_steps.append((result, observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "225437ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'The current temperature in San Francisco is 13.6¬∞C.'}, log='The current temperature in San Francisco is 13.6¬∞C.')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(\"what is the weather is sf?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d748c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. It is used for tasks such as document analysis and summarization, chatbots, and code analysis.'}, log='LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. It is used for tasks such as document analysis and summarization, chatbots, and code analysis.')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(\"what is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af34837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'Well, hello there! How can I assist you today?'}, log='Well, hello there! How can I assist you today?')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(\"hi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30625c9",
   "metadata": {},
   "source": [
    "A celou tuhle funkci umime zabalit do funkce _AgentExecutor_, ktera dela presne to, co je nahore, plus pridava nekolik dalsich veci, jako je lepsi error handling, error handling toolu, logging, early stopping, tracing, ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c6175f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3ad35cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_wikipedia` with `{'query': 'Langchain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Milvus (vector database)\n",
      "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\n",
      "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\n",
      "\n",
      "\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \n",
      "Use cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. It is used for tasks such as document analysis and summarization, chatbots, and code analysis.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is langchain?',\n",
       " 'output': 'LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. It is used for tasks such as document analysis and summarization, chatbots, and code analysis.'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dd15165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'my name is bob',\n",
       " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"my name is bob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "68823d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm sorry, I don't have access to your personal information like your name. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is my name',\n",
       " 'output': \"I'm sorry, I don't have access to your personal information like your name. How can I assist you today?\"}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is my name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348787f",
   "metadata": {},
   "source": [
    "Nicmene, tenhle chain nema pamet. Abychom mohli udrzovat konverzaci, musime pridat pamet. Tedy _ChatMemory_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef119ed0",
   "metadata": {},
   "source": [
    "Musime pridat novou promennou _chat_memory_, ktera bude obsahovat chatovaci historii. Opet pouzijeme _MessagesPlaceholder_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45ff6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c6c38505",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = RunnablePassthrough.assign(\n",
    "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    ") | prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b556982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/tzhjhrlj1_x14gcsq_wsn4580000gn/T/ipykernel_4857/4052124774.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e9496c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent_chain, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f44364c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'my name is bob',\n",
       " 'chat_history': [HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Nice to meet you, Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"my name is bob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a2126e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYou just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats my name',\n",
       " 'chat_history': [HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='whats my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='You just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'You just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats my name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "83668b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe current temperature is 13.6¬∞C\u001b[0m\u001b[32;1m\u001b[1;3mThe current temperature in San Francisco is 13.6¬∞C. Is there anything else you would like to know?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'chat_history': [HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='whats my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='You just told me your name is Bob! So, your name is Bob. How can I assist you, Bob?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='whats the weather in sf?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The current temperature in San Francisco is 13.6¬∞C. Is there anything else you would like to know?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The current temperature in San Francisco is 13.6¬∞C. Is there anything else you would like to know?'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43068e20",
   "metadata": {},
   "source": [
    "### Create a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e8685",
   "metadata": {},
   "source": [
    "Zaverecni priklad s dashboardem a chatbotem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "32c54783",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_your_own(query: str) -> str:\n",
    "    \"\"\"This function can do whatever you would like once you fill it in \"\"\"\n",
    "    print(type(query))\n",
    "    return query[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f17cb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_current_temperature, search_wikipedia, create_your_own]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "719db6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.0/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.6.0/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='4bcfebef-85de-432e-be77-48743c317414'>\n",
       "  <div id=\"d346a1b0-903d-4f9c-8745-096a4ab15d84\" data-root-id=\"4bcfebef-85de-432e-be77-48743c317414\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"e18e8655-7547-4e62-ab01-100327b225ec\":{\"version\":\"3.6.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"4bcfebef-85de-432e-be77-48743c317414\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"82a763e4-3405-4aad-8b98-b08ef3e240a5\",\"attributes\":{\"plot_id\":\"4bcfebef-85de-432e-be77-48743c317414\",\"comm_id\":\"dab7dcc1284e45b4b28b6bb4cb63f6b6\",\"client_comm_id\":\"092a597d8bb94efaaa9282cf8dfb96b4\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"e18e8655-7547-4e62-ab01-100327b225ec\",\"roots\":{\"4bcfebef-85de-432e-be77-48743c317414\":\"d346a1b0-903d-4f9c-8745-096a4ab15d84\"},\"root_ids\":[\"4bcfebef-85de-432e-be77-48743c317414\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "4bcfebef-85de-432e-be77-48743c317414"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    \n",
    "    def __init__(self, tools, **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "        self.model = ChatOpenAI(temperature=0).bind(functions=self.functions)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are helpful but sassy assistant\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])\n",
    "        self.chain = RunnablePassthrough.assign(\n",
    "            agent_scratchpad = lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "        ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n",
    "        self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n",
    "    \n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return\n",
    "        inp.value = ''\n",
    "        result = self.qa.invoke({\"input\": query})\n",
    "        self.answer = result['output'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1044b5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286bd7678d1d41f68f61d7d87e25a16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'15548565-85f6-4f6a-b216-860526a763cc': {'version‚Ä¶"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = cbfs(tools)\n",
    "\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here‚Ä¶')\n",
    "\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=400),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# QnA_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1))\n",
    ")\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23293c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a61eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792729fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09b3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7ed2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3907603b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce51b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5a5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8333e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2191a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e540cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c82056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c854a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb98ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af0754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc5bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc72261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a213d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3776bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6765c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34a8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b01ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add98648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fb040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3d9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e66fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a20b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742de21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719eadf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9133e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace4433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfeeb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bafdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c981e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f72409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b5fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd70bb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7a203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
